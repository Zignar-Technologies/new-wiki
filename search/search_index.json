{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"IOTA-NECTAR/","text":"IOTA 2.0 Research Specifications \u00b6 These are the research specifications of the IOTA 2.0 protocol. To put these in context, consult the Preface. Table of Contents \u00b6 0. Front Matter 0.0 Preface 1. Control Files 1.1 Introduction 1.2 Table of Contents 1.3 Terminology 1.4 Index of parameters 1.5 References 2 - Structure 2.1 Data Types 2.2 Message Layout 2.3 Payloads Layout 2.4 Data Flow 3. Network Layer 3.1 Communication Models 3.2 Bootstrapping 3.3 Peer Discovery 3.4 Neighbor Selection 3.5 Manual Peering 4. Communication Layer 4.1 The Tangle 4.2 Timestamps 4.3 Tip Selection Algorithm 4.4 Solidification 4.5 Rate Control 4.6 Congestion Control 4.7 Markers 4.8 Message Creation 5. Value Transfer Application 5.1 UTXO 5.2 Ledger State 5.3 Mana 6. Consensus Applications 6.1 Object of Consensus 6.2 Opinion Setting 6.3 FPC 6.4 Finalization 6.5 dRNG Appendix A.1 Snapshots","title":"IOTA 2.0 Research Specifications"},{"location":"IOTA-NECTAR/#iota-20-research-specifications","text":"These are the research specifications of the IOTA 2.0 protocol. To put these in context, consult the Preface.","title":"IOTA 2.0 Research Specifications"},{"location":"IOTA-NECTAR/#table-of-contents","text":"0. Front Matter 0.0 Preface 1. Control Files 1.1 Introduction 1.2 Table of Contents 1.3 Terminology 1.4 Index of parameters 1.5 References 2 - Structure 2.1 Data Types 2.2 Message Layout 2.3 Payloads Layout 2.4 Data Flow 3. Network Layer 3.1 Communication Models 3.2 Bootstrapping 3.3 Peer Discovery 3.4 Neighbor Selection 3.5 Manual Peering 4. Communication Layer 4.1 The Tangle 4.2 Timestamps 4.3 Tip Selection Algorithm 4.4 Solidification 4.5 Rate Control 4.6 Congestion Control 4.7 Markers 4.8 Message Creation 5. Value Transfer Application 5.1 UTXO 5.2 Ledger State 5.3 Mana 6. Consensus Applications 6.1 Object of Consensus 6.2 Opinion Setting 6.3 FPC 6.4 Finalization 6.5 dRNG Appendix A.1 Snapshots","title":"Table of Contents"},{"location":"IOTA-NECTAR/0.0%20Preface/","text":"Written on 2 June 2021 IOTA 2.0 Research Specifications \u00b6 This document contains the research specifications of the IOTA 2.0 Protocol. Their purpose is to carefully explain the current state of the IOTA 2.0 protocol to developers, both internal and external, who wish to build on or test Nectar, to academics who want to analyze, model and optimize the protocol and need rigorous description of each module, and to community members and anybody who just want to learn more about the protocol. We hope this document is a useful guide to the IOTA 2.0 research specifications, and we hope that you dive into them to learn as much as you can about how the IOTA 2.0 DevNet works! However, before reading the specifications, we would like to explain a few points to the reader. What are research specifications? \u00b6 This collection includes specifications on each key experimental component of Coordicide. However, there are two important caveats regarding these documents. First, none of the parameters are finalized. Although our previous studies give certain ranges for each of these parameters, tuning each parameter to its optimum value requires a lot of testing and research. Luckily, we can conduct this research while the software is being developed since the parameters we are fine tuning are very easy to change in the code. In these specifications, each parameter is set to an educated estimate. Second, several non-experimental components of the protocol are omitted from this document. For example, snapshotting (the module which manages the pruning of old messages in perma-nodes) and a description of the gossip protocol are omitted. Both of these components are well understood parts of the current Chrysalis mainnet, and thus we felt including them was not worth delaying the specifications release. In the table of contents on the readme file, you can find the missing specifications that we will add over the summer. A final point to note is that these specifications are not stable nor are they subject to a strict versioning system. Nectar is a research prototype. As such, it will be used to conduct research and refine the specifications as necessary to optimize the protocol. Over the coming months we will be collecting data and performing experiments on the IOTA 2.0 DevNet. We learned a great deal about the protocol just by building it, and the information gained from testing at this stage will further improve the protocol and future implementations. Specifically, we will: - Optimize parameters - Improve the software implementations of the protocol in conjunction with developing the Bee and Hornet nodes - Identify and remove any potential performance bottlenecks - Optimize the performance of each module - Simplify the protocol by eliminating any elements which are found to be unnecessary. As we make these improvements to the protocol, these specifications will change. Any protocol which reaches adoption continuously evolves and improves, and the IOTA protocol will be no different. The IOTA Research Department will always strive to make new discoveries to perfect the protocol, and we will also always maintain some sort of research specifications to track the proposed changes. Nectar Documentation vs Research Specifications \u00b6 The reader may notice the GoShimmer repository on GitHub contains its own documentation describing the protocol. How does that documentation relate to these specifications? What is the relationship between Nectar and these specifications? The Nectar documentation describes how the protocol works on the IOTA 2.0 DevNet, whereas the IOTA 2.0 research specifications describe what the IOTA 2.0 protocol should look like. In theory these should be the same (and someday they will be), but currently there are some differences. The Nectar documentation was developed for two purposes. First, it was to help our research engineers figure out how to code certain modules, since parts of the prototype were written before the specs. Second, the documentation helps others, both internally and externally, to navigate the code base. As a result, the Nectar documentation is not complete, only covering the core portions of the protocol. Also, since Nectar is a prototype, a few shortcuts were taken in the implementation. For example, the dRNG committee is fixed, rather than rotating based on consensus mana. This simplifies the implementation while allowing us to conduct the requisite research. The research specifications tell how the committee is supposed to be selected. Protocol vs Implementation Specifications \u00b6 A protocol is an agreement between several nodes on how to exchange and interpret data. The implementation of the protocol is the software that performs the actual operations dictated by the protocol. The protocol is unique and fixed, while the implementation varies. For example, HTTP (HyperText Transfer Protocol) dictates how your browser should communicate with internet servers. There are several browsers (Firefox, Chrome, Safari, etc.) which run this protocol. Internally, these browsers work very differently from each other, having different features and designs, but they all communicate with a server in the same way. IOTA 2.0 is a standardized protocol, and thus will have special protocol specifications dictating how IOTA nodes must behave. The IOTA Foundation will create two software implementations of this protocol: Bee and Hornet, written in rust and go respectively. However, each of these implementations will have implementation specifications which describe exactly how the software works. Using the protocol specifications, anybody can (and hopefully eventually will) write their own software implementations with their own implementation specifications. These research specifications are a mix of both the protocol specifications and the implementation specifications. Why is this the case? Because all of our ideas must be tested in code, we have to develop the protocol and an implementation of the protocol at the same time. Any ideas which cannot be efficiently implemented have to be rejected. Now that we have a working prototype, we can begin separating the protocol from these specifications while the engineering department works on the implementation.","title":"0.0 Preface"},{"location":"IOTA-NECTAR/0.0%20Preface/#iota-20-research-specifications","text":"This document contains the research specifications of the IOTA 2.0 Protocol. Their purpose is to carefully explain the current state of the IOTA 2.0 protocol to developers, both internal and external, who wish to build on or test Nectar, to academics who want to analyze, model and optimize the protocol and need rigorous description of each module, and to community members and anybody who just want to learn more about the protocol. We hope this document is a useful guide to the IOTA 2.0 research specifications, and we hope that you dive into them to learn as much as you can about how the IOTA 2.0 DevNet works! However, before reading the specifications, we would like to explain a few points to the reader.","title":"IOTA 2.0 Research Specifications"},{"location":"IOTA-NECTAR/0.0%20Preface/#what-are-research-specifications","text":"This collection includes specifications on each key experimental component of Coordicide. However, there are two important caveats regarding these documents. First, none of the parameters are finalized. Although our previous studies give certain ranges for each of these parameters, tuning each parameter to its optimum value requires a lot of testing and research. Luckily, we can conduct this research while the software is being developed since the parameters we are fine tuning are very easy to change in the code. In these specifications, each parameter is set to an educated estimate. Second, several non-experimental components of the protocol are omitted from this document. For example, snapshotting (the module which manages the pruning of old messages in perma-nodes) and a description of the gossip protocol are omitted. Both of these components are well understood parts of the current Chrysalis mainnet, and thus we felt including them was not worth delaying the specifications release. In the table of contents on the readme file, you can find the missing specifications that we will add over the summer. A final point to note is that these specifications are not stable nor are they subject to a strict versioning system. Nectar is a research prototype. As such, it will be used to conduct research and refine the specifications as necessary to optimize the protocol. Over the coming months we will be collecting data and performing experiments on the IOTA 2.0 DevNet. We learned a great deal about the protocol just by building it, and the information gained from testing at this stage will further improve the protocol and future implementations. Specifically, we will: - Optimize parameters - Improve the software implementations of the protocol in conjunction with developing the Bee and Hornet nodes - Identify and remove any potential performance bottlenecks - Optimize the performance of each module - Simplify the protocol by eliminating any elements which are found to be unnecessary. As we make these improvements to the protocol, these specifications will change. Any protocol which reaches adoption continuously evolves and improves, and the IOTA protocol will be no different. The IOTA Research Department will always strive to make new discoveries to perfect the protocol, and we will also always maintain some sort of research specifications to track the proposed changes.","title":"What are research specifications?"},{"location":"IOTA-NECTAR/0.0%20Preface/#nectar-documentation-vs-research-specifications","text":"The reader may notice the GoShimmer repository on GitHub contains its own documentation describing the protocol. How does that documentation relate to these specifications? What is the relationship between Nectar and these specifications? The Nectar documentation describes how the protocol works on the IOTA 2.0 DevNet, whereas the IOTA 2.0 research specifications describe what the IOTA 2.0 protocol should look like. In theory these should be the same (and someday they will be), but currently there are some differences. The Nectar documentation was developed for two purposes. First, it was to help our research engineers figure out how to code certain modules, since parts of the prototype were written before the specs. Second, the documentation helps others, both internally and externally, to navigate the code base. As a result, the Nectar documentation is not complete, only covering the core portions of the protocol. Also, since Nectar is a prototype, a few shortcuts were taken in the implementation. For example, the dRNG committee is fixed, rather than rotating based on consensus mana. This simplifies the implementation while allowing us to conduct the requisite research. The research specifications tell how the committee is supposed to be selected.","title":"Nectar Documentation vs Research Specifications"},{"location":"IOTA-NECTAR/0.0%20Preface/#protocol-vs-implementation-specifications","text":"A protocol is an agreement between several nodes on how to exchange and interpret data. The implementation of the protocol is the software that performs the actual operations dictated by the protocol. The protocol is unique and fixed, while the implementation varies. For example, HTTP (HyperText Transfer Protocol) dictates how your browser should communicate with internet servers. There are several browsers (Firefox, Chrome, Safari, etc.) which run this protocol. Internally, these browsers work very differently from each other, having different features and designs, but they all communicate with a server in the same way. IOTA 2.0 is a standardized protocol, and thus will have special protocol specifications dictating how IOTA nodes must behave. The IOTA Foundation will create two software implementations of this protocol: Bee and Hornet, written in rust and go respectively. However, each of these implementations will have implementation specifications which describe exactly how the software works. Using the protocol specifications, anybody can (and hopefully eventually will) write their own software implementations with their own implementation specifications. These research specifications are a mix of both the protocol specifications and the implementation specifications. Why is this the case? Because all of our ideas must be tested in code, we have to develop the protocol and an implementation of the protocol at the same time. Any ideas which cannot be efficiently implemented have to be rejected. Now that we have a working prototype, we can begin separating the protocol from these specifications while the engineering department works on the implementation.","title":"Protocol vs Implementation Specifications"},{"location":"IOTA-NECTAR/1.1%20Introduction/","text":"Warning These specifications are for a research prototype and are a work in progress, thus they may change. Please refer to the preface for a description of their exact status. Introduction \u00b6 These are the research specifications for the IOTA 2.0 protocol. To orientate the reader, we provide a brief summary of their contents along with an overview of the protocol. The first chapter of these specifications contains control files to help the reader navigate these pages. The second chapter of these specifications outlines the general structure of the protocol, including the layouts of messages and their payloads and how messages are processed. Chapter 3 discusses the networking layer. This layer maintains the underlying IOTA network and includes the gossip protocol, managing connections with peers, and bootstrapping while joining the network. The networking layer largely functions independently from the rest of the protocol, allowing the other modules to abstract these components to sending and receiving messages in gossip. Chapters 4, 5, and 6 include the bulk of the protocol. Chapter 4 describes the communication layer, which manages the information transmitted through the networking layer. Running on top of the communication layer, the application layer provides actual services to clients. Anybody can develop applications, and nodes can choose which applications to run. Of course, these applications can also be dependent on each other. While third-party applications are clearly out of the realm of this document, there are several core applications which must be run by all nodes. The core applications are split into two groups: the value transfer application and the consensus applications, which are discussed in Chapters 5 and 6 respectively. The communication layer \u00b6 The communication layer manages the information communicated through the network layer, including processing information received from the gossip, storing information, checking various validity conditions, and deciding what information to send to neighbors. All the data and transactions exchanged in IOTA 2.0 protocol is contained in objects called messages. All messages are stored in a data structure called the Tangle. Since each message contains the hash of at least two other messages, the Tangle has a DAG structure which secures all the data, making the history of each message immutable. We refer to these references as \"approval\" since a message should only reference another if it approves of its history. Each message contains a timestamp, and the protocol enforces various objective and subjective rules regarding them. When nodes create new messages, they must decide which messages their new message should reference. To do this, the node uses the tip selection algorithm to select tips, messages which are not yet referenced. Since references denote approval, tip selection algorithm ultimately decides which transactions and data will be included into the ledger. The node uses flags managed by the consensus applications to maintain a pool of tips with a \"correct\" history. The tip selection algorithm just randomly selects tips from this pool. To prevent the network from being overloaded, the rate control uses adaptive PoW to coarsely limit the messages created during a spam attack while keeping the network usable for honest nodes. The congestion control module manages fine grained access, using a deficit round robin scheduler to decide which messages are added to the ledger and gossiped. The scheduler is designed to have the following properties: 1. Consistency: all honest nodes will schedule the same messages 2. Fair access: the nodes' messages will be scheduled at a fair rate according to their access mana (explained below) 3. Utilisation: when there is demand, the entire throughput will be used 4. Bounded latency: network delay of all messages will be bounded 5. Security: these properties hold even in the presence of an attacker Lastly, the congestion control module includes a rate setter for honest nodes to use which allows them to determine the proper rate they can issue messages. The Value Transfer Application \u00b6 The Value Transfer Application maintains the ledger state and a quantity called mana which is held by each node. Changes to the ledger are made through objects called transactions submitted to the Tangle via messages. Transactions are dependent on each other, and these dependencies are tracked in the UTXO DAG. By monitoring the UTXO DAG, a node can easily detect when two transactions intend to make conflicting changes to the ledger. Once conflicts are detected, they are tracked in a sophisticated data structure called the Branch DAG. Each branch represents a valid and monotonic choice of conflicts. These choices, and hence the branches, are naturally partially ordered by inclusion, and thus the branches have a DAG structure. Each message and transaction is flagged with a branch, indicating the conflicts that each transaction or message depends upon. Since each message and transaction must have a valid history, these dependencies always form a branch. The consensus applications choose which branches are correct, resolving the conflicts, and which transactions are finalised, deciding how to mutate the balances of the ledger. The value transfer application also manages the mana state, which is the IOTA 2.0 Sybil protection mechanism. Every node has holds two quantities: access mana and consensus mana. Every time a transaction moves funds, a roughly equal amount of consensus mana and access mana are pledged to two nodes. Thus mana is an extension of the ledger state. The amount of mana a node has determines how it can interact with certain modules. For example, the congestion control algorithm schedules messages according to access mana. The consensus applications dRNG, FPC, approval weight and autopeering all use consensus mana. The consensus applications \u00b6 The consensus applications allow the network to come to consensus on which messages have accurate timestamps and which conflicts should be accepted and which rejected. These questions are decided through the binary voting protocol Fast Probabilistic Consensus, or FPC for short. This binary voting protocol exchanges opinions with randomly selected nodes to come to consensus on a bit. To prevent an attacker from maintaining a metastable state, FPC effectively breaks \"ties\" of opinions using a random number generated by the dRNG module. Using the outcomes of FPC, nodes come to consensus on which branches new messages should be attached. The approval weight essentially tracks how many nodes have issued a message in a future cone of a message, weighted by their consensus mana. After the approval weight of a message (or a branch) becomes large enough, the branch is considered finalised. Some nodes may miss certain instances of FPC voting, because they are either new or they temporarily lost connectivity. These nodes may come to the wrong conclusions using FPC voting. However, such nodes will always compute the approval weight correctly. Thus, if a conflict approved by FPC conflicts with a branch finalised by approval weight, the node will always default to the approval weight. In this way, FPC provides an initial round of consensus for nodes which are active in the network, and then the approval weight provides the final consensus.","title":"1.1 Introduction"},{"location":"IOTA-NECTAR/1.1%20Introduction/#introduction","text":"These are the research specifications for the IOTA 2.0 protocol. To orientate the reader, we provide a brief summary of their contents along with an overview of the protocol. The first chapter of these specifications contains control files to help the reader navigate these pages. The second chapter of these specifications outlines the general structure of the protocol, including the layouts of messages and their payloads and how messages are processed. Chapter 3 discusses the networking layer. This layer maintains the underlying IOTA network and includes the gossip protocol, managing connections with peers, and bootstrapping while joining the network. The networking layer largely functions independently from the rest of the protocol, allowing the other modules to abstract these components to sending and receiving messages in gossip. Chapters 4, 5, and 6 include the bulk of the protocol. Chapter 4 describes the communication layer, which manages the information transmitted through the networking layer. Running on top of the communication layer, the application layer provides actual services to clients. Anybody can develop applications, and nodes can choose which applications to run. Of course, these applications can also be dependent on each other. While third-party applications are clearly out of the realm of this document, there are several core applications which must be run by all nodes. The core applications are split into two groups: the value transfer application and the consensus applications, which are discussed in Chapters 5 and 6 respectively.","title":"Introduction"},{"location":"IOTA-NECTAR/1.1%20Introduction/#the-communication-layer","text":"The communication layer manages the information communicated through the network layer, including processing information received from the gossip, storing information, checking various validity conditions, and deciding what information to send to neighbors. All the data and transactions exchanged in IOTA 2.0 protocol is contained in objects called messages. All messages are stored in a data structure called the Tangle. Since each message contains the hash of at least two other messages, the Tangle has a DAG structure which secures all the data, making the history of each message immutable. We refer to these references as \"approval\" since a message should only reference another if it approves of its history. Each message contains a timestamp, and the protocol enforces various objective and subjective rules regarding them. When nodes create new messages, they must decide which messages their new message should reference. To do this, the node uses the tip selection algorithm to select tips, messages which are not yet referenced. Since references denote approval, tip selection algorithm ultimately decides which transactions and data will be included into the ledger. The node uses flags managed by the consensus applications to maintain a pool of tips with a \"correct\" history. The tip selection algorithm just randomly selects tips from this pool. To prevent the network from being overloaded, the rate control uses adaptive PoW to coarsely limit the messages created during a spam attack while keeping the network usable for honest nodes. The congestion control module manages fine grained access, using a deficit round robin scheduler to decide which messages are added to the ledger and gossiped. The scheduler is designed to have the following properties: 1. Consistency: all honest nodes will schedule the same messages 2. Fair access: the nodes' messages will be scheduled at a fair rate according to their access mana (explained below) 3. Utilisation: when there is demand, the entire throughput will be used 4. Bounded latency: network delay of all messages will be bounded 5. Security: these properties hold even in the presence of an attacker Lastly, the congestion control module includes a rate setter for honest nodes to use which allows them to determine the proper rate they can issue messages.","title":"The communication layer"},{"location":"IOTA-NECTAR/1.1%20Introduction/#the-value-transfer-application","text":"The Value Transfer Application maintains the ledger state and a quantity called mana which is held by each node. Changes to the ledger are made through objects called transactions submitted to the Tangle via messages. Transactions are dependent on each other, and these dependencies are tracked in the UTXO DAG. By monitoring the UTXO DAG, a node can easily detect when two transactions intend to make conflicting changes to the ledger. Once conflicts are detected, they are tracked in a sophisticated data structure called the Branch DAG. Each branch represents a valid and monotonic choice of conflicts. These choices, and hence the branches, are naturally partially ordered by inclusion, and thus the branches have a DAG structure. Each message and transaction is flagged with a branch, indicating the conflicts that each transaction or message depends upon. Since each message and transaction must have a valid history, these dependencies always form a branch. The consensus applications choose which branches are correct, resolving the conflicts, and which transactions are finalised, deciding how to mutate the balances of the ledger. The value transfer application also manages the mana state, which is the IOTA 2.0 Sybil protection mechanism. Every node has holds two quantities: access mana and consensus mana. Every time a transaction moves funds, a roughly equal amount of consensus mana and access mana are pledged to two nodes. Thus mana is an extension of the ledger state. The amount of mana a node has determines how it can interact with certain modules. For example, the congestion control algorithm schedules messages according to access mana. The consensus applications dRNG, FPC, approval weight and autopeering all use consensus mana.","title":"The Value Transfer Application"},{"location":"IOTA-NECTAR/1.1%20Introduction/#the-consensus-applications","text":"The consensus applications allow the network to come to consensus on which messages have accurate timestamps and which conflicts should be accepted and which rejected. These questions are decided through the binary voting protocol Fast Probabilistic Consensus, or FPC for short. This binary voting protocol exchanges opinions with randomly selected nodes to come to consensus on a bit. To prevent an attacker from maintaining a metastable state, FPC effectively breaks \"ties\" of opinions using a random number generated by the dRNG module. Using the outcomes of FPC, nodes come to consensus on which branches new messages should be attached. The approval weight essentially tracks how many nodes have issued a message in a future cone of a message, weighted by their consensus mana. After the approval weight of a message (or a branch) becomes large enough, the branch is considered finalised. Some nodes may miss certain instances of FPC voting, because they are either new or they temporarily lost connectivity. These nodes may come to the wrong conclusions using FPC voting. However, such nodes will always compute the approval weight correctly. Thus, if a conflict approved by FPC conflicts with a branch finalised by approval weight, the node will always default to the approval weight. In this way, FPC provides an initial round of consensus for nodes which are active in the network, and then the approval weight provides the final consensus.","title":"The consensus applications"},{"location":"IOTA-NECTAR/2.2%20Message%20Layout/","text":"2.2 Message Layout \u00b6 This section describes the Message Layout , its syntactical validation and additional metadata that may be stored by a node for a message. Parameters \u00b6 MAX_MESSAGE_SIZE The maximum allowed message size. MIN_STRONG_PARENTS The minimum amount of strong parents a message must reference. Parameter Default Values \u00b6 The following values shall be set as the default for the above parameters on initiation of the node application: MAX_MESSAGE_SIZE = 64KB MIN_STRONG_PARENTS = 1 Message Structure \u00b6 The structure of a Tangle message is defined in Table 2.2-1 below. Table 2.2-1: Message Structure Name Type Description Version uint8 The message version. The schema specified in this specification is for version 1 only. Parents count uint8 The amount of parents preceding the current message. Parents type uint8 Bitwise encoding of parent type matching the order of preceding parents starting at least significant bit . 1 indicates a strong parent, while 0 signals a weak parent. At least MIN_STRONG_PARENTS parent type must be strong. Parents between(1,8) Parents, ordered by hash ASC Name Type Description Parent ByteArray[32] The Message ID of the parent Message . Issuer public key (Ed25519) ByteArray[32] The public key of the node issuing the message. Issuing timestamp time A value that shall represent the issuance time of the message. Payload length uint32 The length of the Payload in bytes. Since its type may be unknown to the node, it must be declared in advance. 0 length means no payload will be attached. Payload Generic Payload An outline of a general payload Name Type Description Payload Type uint32 The type of the payload. It will instruct the node how to parse the fields that follow. Types in the range of 0-127 are \"core types\", that all nodes are expected to know. Data Fields ANY A sequence of fields, where the structure depends on Payload Type . Nonce uint64 The nonce which lets this message fulfill the Rate Control requirement. Signature (Ed25519) ByteArray[64] Signature of the issuing node's private key signing the BLAKE2b-256 hash of the entire message bytes. Message ID \u00b6 BLAKE2b-256 hash of the byte contents of the message. It shall be used by the nodes to index the messages and by external APIs. Syntactical Validation \u00b6 Messages that do not pass the Syntactical Validation shall be discarded. Only syntactically valid messages continue in the data flow, i.e., shall be allowed to pass to the Semantic Validation step. A message is syntactically valid if: 1. The message length does not exceed MAX_MESSAGE_SIZE bytes. 2. When the message parsing is complete, there are not any trailing bytes left that were not parsed. 3. At least 1 and at most 8 distinct parents are given, ordered ASC and at least MIN_STRONG_PARENTS are strong parents. Semantic Validation \u00b6 Messages that do not pass the Semantic Validation shall be discarded. Only semantically valid messages shall be allowed to continue in the data flow. A message is semantically valid if: 1. The Message PoW Hash contains at least the number of leading 0 defined as required by the Rate Control module (see Section 4.5 - Rate Control . 2. The signature of the issuing node is valid. 3. It passes the parents age checks (see Section 4.2 - Timestamps ). Metadata \u00b6 In addition to a message itself, a node may store additional data that describes its local perception of a message which is not part of the Tangle ('Message metadata'). Where such metadata is defined, the metadata element names and types defined in Table 2.2-2 below shall be used. Table 2.2-2: Message Metadata Name Type Description receivedTime time The local time the message was received by the node. solid bool Denotes whether a message is solid, i.e., its past cone is known. solidificationTime time The local time the message got solid. branchID ByteArray[32] The branch ID of the message, i.e., the part of the Tangle where the message is located. scheduled bool Denotes whether a message was scheduled by the scheduler. booked bool Denotes whether a message was booked and therefore is part of the local Tangle. eligible bool Denotes whether a message is eligible, i.e., it's timestamp is good. invalid bool Denotes whether a message has been deemed invalid, i.e., it or its parents do not pass all checks from filters to message booker. opinion Opinion Contains the node's opinion on the issuing timestamp of a message.","title":"2.2 Message Layout"},{"location":"IOTA-NECTAR/2.2%20Message%20Layout/#22-message-layout","text":"This section describes the Message Layout , its syntactical validation and additional metadata that may be stored by a node for a message.","title":"2.2 Message Layout"},{"location":"IOTA-NECTAR/2.2%20Message%20Layout/#parameters","text":"MAX_MESSAGE_SIZE The maximum allowed message size. MIN_STRONG_PARENTS The minimum amount of strong parents a message must reference.","title":"Parameters"},{"location":"IOTA-NECTAR/2.2%20Message%20Layout/#parameter-default-values","text":"The following values shall be set as the default for the above parameters on initiation of the node application: MAX_MESSAGE_SIZE = 64KB MIN_STRONG_PARENTS = 1","title":"Parameter Default Values"},{"location":"IOTA-NECTAR/2.2%20Message%20Layout/#message-structure","text":"The structure of a Tangle message is defined in Table 2.2-1 below. Table 2.2-1: Message Structure Name Type Description Version uint8 The message version. The schema specified in this specification is for version 1 only. Parents count uint8 The amount of parents preceding the current message. Parents type uint8 Bitwise encoding of parent type matching the order of preceding parents starting at least significant bit . 1 indicates a strong parent, while 0 signals a weak parent. At least MIN_STRONG_PARENTS parent type must be strong. Parents between(1,8) Parents, ordered by hash ASC Name Type Description Parent ByteArray[32] The Message ID of the parent Message . Issuer public key (Ed25519) ByteArray[32] The public key of the node issuing the message. Issuing timestamp time A value that shall represent the issuance time of the message. Payload length uint32 The length of the Payload in bytes. Since its type may be unknown to the node, it must be declared in advance. 0 length means no payload will be attached. Payload Generic Payload An outline of a general payload Name Type Description Payload Type uint32 The type of the payload. It will instruct the node how to parse the fields that follow. Types in the range of 0-127 are \"core types\", that all nodes are expected to know. Data Fields ANY A sequence of fields, where the structure depends on Payload Type . Nonce uint64 The nonce which lets this message fulfill the Rate Control requirement. Signature (Ed25519) ByteArray[64] Signature of the issuing node's private key signing the BLAKE2b-256 hash of the entire message bytes.","title":"Message Structure"},{"location":"IOTA-NECTAR/2.2%20Message%20Layout/#message-id","text":"BLAKE2b-256 hash of the byte contents of the message. It shall be used by the nodes to index the messages and by external APIs.","title":"Message ID"},{"location":"IOTA-NECTAR/2.2%20Message%20Layout/#syntactical-validation","text":"Messages that do not pass the Syntactical Validation shall be discarded. Only syntactically valid messages continue in the data flow, i.e., shall be allowed to pass to the Semantic Validation step. A message is syntactically valid if: 1. The message length does not exceed MAX_MESSAGE_SIZE bytes. 2. When the message parsing is complete, there are not any trailing bytes left that were not parsed. 3. At least 1 and at most 8 distinct parents are given, ordered ASC and at least MIN_STRONG_PARENTS are strong parents.","title":"Syntactical Validation"},{"location":"IOTA-NECTAR/2.2%20Message%20Layout/#semantic-validation","text":"Messages that do not pass the Semantic Validation shall be discarded. Only semantically valid messages shall be allowed to continue in the data flow. A message is semantically valid if: 1. The Message PoW Hash contains at least the number of leading 0 defined as required by the Rate Control module (see Section 4.5 - Rate Control . 2. The signature of the issuing node is valid. 3. It passes the parents age checks (see Section 4.2 - Timestamps ).","title":"Semantic Validation"},{"location":"IOTA-NECTAR/2.2%20Message%20Layout/#metadata","text":"In addition to a message itself, a node may store additional data that describes its local perception of a message which is not part of the Tangle ('Message metadata'). Where such metadata is defined, the metadata element names and types defined in Table 2.2-2 below shall be used. Table 2.2-2: Message Metadata Name Type Description receivedTime time The local time the message was received by the node. solid bool Denotes whether a message is solid, i.e., its past cone is known. solidificationTime time The local time the message got solid. branchID ByteArray[32] The branch ID of the message, i.e., the part of the Tangle where the message is located. scheduled bool Denotes whether a message was scheduled by the scheduler. booked bool Denotes whether a message was booked and therefore is part of the local Tangle. eligible bool Denotes whether a message is eligible, i.e., it's timestamp is good. invalid bool Denotes whether a message has been deemed invalid, i.e., it or its parents do not pass all checks from filters to message booker. opinion Opinion Contains the node's opinion on the issuing timestamp of a message.","title":"Metadata"},{"location":"IOTA-NECTAR/2.3%20Standard%20Payloads%20Layout/","text":"2.3 Standard Payloads Layout \u00b6 Payloads may contain arbitrary data up to MAX_PAYLOAD_SIZE , which allows building additional protocols on top of the base protocol in the same way as TCP/IP allows to define additional protocols on top of its generic data segment. Payloads may recursively contain other payloads, that enables the creation of higher-level protocols based on the same concepts of layers, as in traditional software and network architecture. Payloads other than transactions are, by definition, always liked with a level of knowledge 3. Payload definition guideline \u00b6 Each payload shall be described by the uint32 payload type field. To separate user-defined payloads from essential core payloads and allow future extension of the protocol, the first four places (types 0-255) are reserved for core payload definitions, and all user-defined payloads that do not restrict this rule shall be discarded. Additionally, all payloads shall start with the following fields, in the presented order: Name Type Description Size uint32 The size of the payload. Payload Type uint32 The type of the payload. Version uint8 The version of the payload. Parameters \u00b6 Name Description Value MAX_PAYLOAD_SIZE The maximum allowed payload size in bytes. Determined by the difference between MAX_MESSAGE_SIZE (defined in Section 2.2 - Message Layout ) and the total size of the remaining message fields. 65157 User-defined payloads \u00b6 A node may choose to interpret user-defined payloads by listening to its specific payload type (possibly via third-party code/software). If a node does not know a certain payload type , it simply treats it as arbitrary data. Core payloads \u00b6 The core protocol defines several payloads that every node needs to interpret and process in order to participate in the network. All core payloads, along with their types, are listed in the following table. Payload Name Payload Type Pure data value 1 Transaction value 0 FPC statement value 2 dRNG Application Message value 3 dRNG DKG value 4 dRNG Beacon value 5 dRNG Collective Beacon value 6 Salt Declaration value 7 Indexation value 8 Pure data payload \u00b6 Pure data payloads allow to send unsigned messages. Name Type Description Size uint32 The size of the payload. Payload Type uint32 Set to value 1 to denote a Data Payload . Version uint8 The version of the payload. Data ByteArray The raw data payload. Transaction payload \u00b6 The ledger state is changed through transactions payloads or value transfers. More details on transactions could be found in Section 5.1 - UTXO specification. The detailed description of transaction payload's serialized form is presented in the table below. Name Type Description Size uint32 The size of the payload. Payload Type uint32 Set to value 0 to denote a Transaction Payload . Version uint8 The version of the payload. Essence oneOf Transaction Essence Describes the essence data making up a transaction. Name Type Description Version uint8 The version number of the Transaction Essence . Timestamp time The timestamp of the Transaction creation. Access Mana Pledge nodeID ByteArray[32] The nodeID to which access mana of the Transaction is pledged. Consensus Mana Pledge nodeID ByteArray32] The nodeID to which consensus mana of the Transaction is pledged. Inputs Count uint16 The amount of inputs proceeding. Inputs anyOf UTXO Input Describes an input which references an unspent transaction output to consume. Name Type Description Input Type uint8 Set to value 0 to denote an UTXO Input . Transaction ID ByteArray[32] The BLAKE2b-256 hash of the transaction from which the UTXO comes from. Transaction Output Index uint16 The index of the output on the referenced transaction to consume. Outputs Count uint16 The amount of outputs proceeding. Outputs anyOf SigLockedSingleOutput Describes a deposit to a single address which is unlocked via a signature. Name Type Description Output Type uint8 Set to value 0 to denote a SigLockedSingleOutput . Address oneOf Ed25519 Address Name Type Description Address Type uint8 Set to value 0 to denote an Ed25519 Address . Address ByteArray[32] The raw bytes of the Ed25519 address which is a BLAKE2b-256 hash of the Ed25519 public key. BLS Address Name Type Description Address Type uint8 Set to value 1 to denote a BLS Address . Address ByteArray[49] The raw bytes of the BLS address which is a BLAKE2b-256 hash of the BLS public key. Amount uint64 The amount of tokens to deposit with this SigLockedSingleOutput output. Payload Length uint32 The length in bytes of the optional payload. Payload optOneOf Indexation Payload Unlock Blocks Count uint16 The count of unlock blocks proceeding. Must match count of specified inputs. Unlock Blocks anyOf Signature Unlock Block Defines an unlock block containing signature(s) unlocking input(s). Name Type Description Unlock Type uint8 Set to value 0 to denote a Signature Unlock Block . Signature oneOf Ed25519 Signature Name Type Description Signature Type uint8 Set to value 1 to denote an Ed25519 Signature . Public key ByteArray[32] The public key of the Ed25519 keypair which is used to verify the signature. Signature ByteArray[64] The signature signing the serialized Transaction Essence . BLS Signature Name Type Description Signature Type uint8 Set to value 1 to denote a BLS Signature . Signature ByteArray The signature signing the serialized Transaction Essence . Reference Unlock Block References a previous unlock block in order to substitute the duplication of the same unlock block data for inputs which unlock through the same data. Name Type Description Unlock Type uint8 Set to value 1 to denote a Reference Unlock Block . Reference uint16 Represents the index of a previous unlock block. FPC statement \u00b6 Opinions on conflicts of transactions and timestamps of the messages, mainly issued by high mana nodes. Details regarding FPC see Section 6.3 - Fast Probabilistic Consensus specification. The following table describes the entirety of a FPC statement 's serialized form: Name Type Description Size uint32 The size of the FPC statement payload. Payload Type uint32 Set to 2 to denote a FPC statement Payload . Version uint8 The version of the FPC statement payload. Conflicts Count uint32 The number of conflicts proceeding. Conflicts optOneOf Conflict Describes a voting details in a given round for a transaction conflict. Name Type Description TransactionID ByteArray[32] The ID of the conflicting transaction. Opinion Represents the node's opinion value over the conflict in a given round. Name Type Description Value uint8 The node's opinion value in a given round. Round uint8 The round number. Timestamps Count uint32 The number of timestamp voting proceeding. Timestamps optOneOf Timestamp Describes the voting details over the timestamp for a given message and round. Name Type Description MessageID ByteArray[32] The ID of the message that contains the timestamp. Opinion Represents the node's opinion value over the conflict in a given round. Name Type Description Value uint8 The node's opinion value in a given round. Round uint8 The round number. dRNG beacon payloads \u00b6 Messages that contain randomness (issued by the dRNG committee nodes). A single Beacon message is not sufficient to reveal the random number. Instead, sigThreshold or more Beacon messages are needed for the random number to be revealed. To recover the random number from the individual Beacon messages, all nodes in the network would need to perform Lagrange interpolation. To avoid that, the committee nodes produce a CollectiveBeacon , which contains a pre-computed random number (meaning that the committee nodes perform the Lagrange interpolation on their own). More information in Section 6.5 - Distributed Random Number Generator . The following table describes the dRNG Beacon and CollectiveBeacon payload's serialized form: Name Type Description Size uint32 The size of the payload. Payload Type uint32 Set to 6 to denote a Collective Beacon payload or to 5 for Beacon payload. Version uint8 The version of the payload. InstanceID uint32 The identifier of the dRNG instance. dRNG subpayload oneOf TypeBeacon Defines payload data for Beacon payload type. Name Type Description Round uint64 The round of the current beacon. PartialPK ByteArray[96] The public key of the issuer. PartialSignature ByteArray[96] The collective signature of the current beacon. TypeCollectiveBeacon Defines payload data for CollectiveBeacon payload type. Name Type Description Round uint64 The round of the current beacon. PrevSignature ByteArray[96] The collective signature of the previous beacon. Signature ByteArray[96] The collective signature of the current beacon. DistributedPK ByteArray[48] The distributed public key. dRNG application message \u00b6 A message used by a node to declare its willingness to participate in the Committee Selection process. Any node can issue an application message. However, low mana nodes are unlikely to be selected; hence, they can decide to not take part in sending application messages. Name Type Description Size uint32 The size of the payload. Payload Type uint32 Set to 3 to denote a Application Message payload. Version uint8 The version of the payload. InstanceID uint32 The identifier of the dRNG instance. dRNG DKG payload \u00b6 The Deal messages exchanged to produce a public/private collective key during the DKG phase. The Deal messages are issued by the nodes that qualified for the dRNG committee participation (see Section 6.5 - Distributed Random Number Generator ). Name Type Description Size uint32 The size of the payload. Payload Type uint32 Set to 4 to denote a Deal Message payload. Version uint8 The version of the payload. InstanceID uint32 The identifier of the dRNG instance. FromIndex uint32 The index of the dealer. ToIndex uint32 The index of the verifier. Deal oneOf EncryptedDeal An encrypted share struct. Name Type Description Dhkey ByteArray An ephemeral Diffie-Hellman key. Nonce ByteArray The nonce used in AES-GCM. EncryptedShare ByteArray The ciphertext of the share. Threshold uint32 The threshold of the secret sharing protocol (decided during committee selection). Commitments ByteArray The commitments of the polynomial used to derive the share. Salt declaration payload \u00b6 The salt declaration payload is used by nodes to declare their initial salt. In a salt declaration message, the declaring node includes the following fields: Name Type Description Size uint32 The size of the payload. Payload Type uint32 Set to 7 to denote a Salt declaration . Version uint8 The version of the payload. NodeID uint32 The declaring node ID (which may be different from the node ID of the issuer of the message). Salt oneOf Salt The public salt of the requester defined. Name Type Description Bytes ByteArray The value of the salt. ExpTime time The expiration time of the salt. Timestamp time The timestamp of the payload, which shall be close to the timestamp of its containing message. Signature The node signature, that ensures all 'redeclarations' would be malicious. Indexations payload \u00b6 Allows the addition of an index to the encapsulating message, as well as some arbitrary data. Nodes will expose an API that will enable the querying of messages by the index. Adding those capabilities may open nodes to DOS attack vectors: 1. Proliferation of index keys that may blow up the node's DB 2. Proliferation of messages associated with the same index Node implementations may provide weak guarantees regarding the completion of indexes to address the above scenarios. Besides the index, the payload will also have a data field. A message that has been attached to the Tangle has several useful properties: verifying that the content of the data did not change and determining the approximate time it was published by checking timestamps. If the payload will be incorporated under the signed transaction payload , the content will be signed as well. The structure of the payload is simple: Name Type Description Size uint32 The size of the payload. Payload Type uint32 Set to 8 to denote an Indexation payload . Version uint8 The version of the payload. Index ByteArray The index key of the message. Data ByteArray Data we are attaching. Note that index field should be 1 to 64 bytes long for the payload to be valid. The data may have a length of 0.","title":"2.3 Standard Payloads Layout"},{"location":"IOTA-NECTAR/2.3%20Standard%20Payloads%20Layout/#23-standard-payloads-layout","text":"Payloads may contain arbitrary data up to MAX_PAYLOAD_SIZE , which allows building additional protocols on top of the base protocol in the same way as TCP/IP allows to define additional protocols on top of its generic data segment. Payloads may recursively contain other payloads, that enables the creation of higher-level protocols based on the same concepts of layers, as in traditional software and network architecture. Payloads other than transactions are, by definition, always liked with a level of knowledge 3.","title":"2.3 Standard Payloads Layout"},{"location":"IOTA-NECTAR/2.3%20Standard%20Payloads%20Layout/#payload-definition-guideline","text":"Each payload shall be described by the uint32 payload type field. To separate user-defined payloads from essential core payloads and allow future extension of the protocol, the first four places (types 0-255) are reserved for core payload definitions, and all user-defined payloads that do not restrict this rule shall be discarded. Additionally, all payloads shall start with the following fields, in the presented order: Name Type Description Size uint32 The size of the payload. Payload Type uint32 The type of the payload. Version uint8 The version of the payload.","title":"Payload definition guideline"},{"location":"IOTA-NECTAR/2.3%20Standard%20Payloads%20Layout/#parameters","text":"Name Description Value MAX_PAYLOAD_SIZE The maximum allowed payload size in bytes. Determined by the difference between MAX_MESSAGE_SIZE (defined in Section 2.2 - Message Layout ) and the total size of the remaining message fields. 65157","title":"Parameters"},{"location":"IOTA-NECTAR/2.3%20Standard%20Payloads%20Layout/#user-defined-payloads","text":"A node may choose to interpret user-defined payloads by listening to its specific payload type (possibly via third-party code/software). If a node does not know a certain payload type , it simply treats it as arbitrary data.","title":"User-defined payloads"},{"location":"IOTA-NECTAR/2.3%20Standard%20Payloads%20Layout/#core-payloads","text":"The core protocol defines several payloads that every node needs to interpret and process in order to participate in the network. All core payloads, along with their types, are listed in the following table. Payload Name Payload Type Pure data value 1 Transaction value 0 FPC statement value 2 dRNG Application Message value 3 dRNG DKG value 4 dRNG Beacon value 5 dRNG Collective Beacon value 6 Salt Declaration value 7 Indexation value 8","title":"Core payloads"},{"location":"IOTA-NECTAR/2.3%20Standard%20Payloads%20Layout/#pure-data-payload","text":"Pure data payloads allow to send unsigned messages. Name Type Description Size uint32 The size of the payload. Payload Type uint32 Set to value 1 to denote a Data Payload . Version uint8 The version of the payload. Data ByteArray The raw data payload.","title":"Pure data payload"},{"location":"IOTA-NECTAR/2.3%20Standard%20Payloads%20Layout/#transaction-payload","text":"The ledger state is changed through transactions payloads or value transfers. More details on transactions could be found in Section 5.1 - UTXO specification. The detailed description of transaction payload's serialized form is presented in the table below. Name Type Description Size uint32 The size of the payload. Payload Type uint32 Set to value 0 to denote a Transaction Payload . Version uint8 The version of the payload. Essence oneOf Transaction Essence Describes the essence data making up a transaction. Name Type Description Version uint8 The version number of the Transaction Essence . Timestamp time The timestamp of the Transaction creation. Access Mana Pledge nodeID ByteArray[32] The nodeID to which access mana of the Transaction is pledged. Consensus Mana Pledge nodeID ByteArray32] The nodeID to which consensus mana of the Transaction is pledged. Inputs Count uint16 The amount of inputs proceeding. Inputs anyOf UTXO Input Describes an input which references an unspent transaction output to consume. Name Type Description Input Type uint8 Set to value 0 to denote an UTXO Input . Transaction ID ByteArray[32] The BLAKE2b-256 hash of the transaction from which the UTXO comes from. Transaction Output Index uint16 The index of the output on the referenced transaction to consume. Outputs Count uint16 The amount of outputs proceeding. Outputs anyOf SigLockedSingleOutput Describes a deposit to a single address which is unlocked via a signature. Name Type Description Output Type uint8 Set to value 0 to denote a SigLockedSingleOutput . Address oneOf Ed25519 Address Name Type Description Address Type uint8 Set to value 0 to denote an Ed25519 Address . Address ByteArray[32] The raw bytes of the Ed25519 address which is a BLAKE2b-256 hash of the Ed25519 public key. BLS Address Name Type Description Address Type uint8 Set to value 1 to denote a BLS Address . Address ByteArray[49] The raw bytes of the BLS address which is a BLAKE2b-256 hash of the BLS public key. Amount uint64 The amount of tokens to deposit with this SigLockedSingleOutput output. Payload Length uint32 The length in bytes of the optional payload. Payload optOneOf Indexation Payload Unlock Blocks Count uint16 The count of unlock blocks proceeding. Must match count of specified inputs. Unlock Blocks anyOf Signature Unlock Block Defines an unlock block containing signature(s) unlocking input(s). Name Type Description Unlock Type uint8 Set to value 0 to denote a Signature Unlock Block . Signature oneOf Ed25519 Signature Name Type Description Signature Type uint8 Set to value 1 to denote an Ed25519 Signature . Public key ByteArray[32] The public key of the Ed25519 keypair which is used to verify the signature. Signature ByteArray[64] The signature signing the serialized Transaction Essence . BLS Signature Name Type Description Signature Type uint8 Set to value 1 to denote a BLS Signature . Signature ByteArray The signature signing the serialized Transaction Essence . Reference Unlock Block References a previous unlock block in order to substitute the duplication of the same unlock block data for inputs which unlock through the same data. Name Type Description Unlock Type uint8 Set to value 1 to denote a Reference Unlock Block . Reference uint16 Represents the index of a previous unlock block.","title":"Transaction payload"},{"location":"IOTA-NECTAR/2.3%20Standard%20Payloads%20Layout/#fpc-statement","text":"Opinions on conflicts of transactions and timestamps of the messages, mainly issued by high mana nodes. Details regarding FPC see Section 6.3 - Fast Probabilistic Consensus specification. The following table describes the entirety of a FPC statement 's serialized form: Name Type Description Size uint32 The size of the FPC statement payload. Payload Type uint32 Set to 2 to denote a FPC statement Payload . Version uint8 The version of the FPC statement payload. Conflicts Count uint32 The number of conflicts proceeding. Conflicts optOneOf Conflict Describes a voting details in a given round for a transaction conflict. Name Type Description TransactionID ByteArray[32] The ID of the conflicting transaction. Opinion Represents the node's opinion value over the conflict in a given round. Name Type Description Value uint8 The node's opinion value in a given round. Round uint8 The round number. Timestamps Count uint32 The number of timestamp voting proceeding. Timestamps optOneOf Timestamp Describes the voting details over the timestamp for a given message and round. Name Type Description MessageID ByteArray[32] The ID of the message that contains the timestamp. Opinion Represents the node's opinion value over the conflict in a given round. Name Type Description Value uint8 The node's opinion value in a given round. Round uint8 The round number.","title":"FPC statement"},{"location":"IOTA-NECTAR/2.3%20Standard%20Payloads%20Layout/#drng-beacon-payloads","text":"Messages that contain randomness (issued by the dRNG committee nodes). A single Beacon message is not sufficient to reveal the random number. Instead, sigThreshold or more Beacon messages are needed for the random number to be revealed. To recover the random number from the individual Beacon messages, all nodes in the network would need to perform Lagrange interpolation. To avoid that, the committee nodes produce a CollectiveBeacon , which contains a pre-computed random number (meaning that the committee nodes perform the Lagrange interpolation on their own). More information in Section 6.5 - Distributed Random Number Generator . The following table describes the dRNG Beacon and CollectiveBeacon payload's serialized form: Name Type Description Size uint32 The size of the payload. Payload Type uint32 Set to 6 to denote a Collective Beacon payload or to 5 for Beacon payload. Version uint8 The version of the payload. InstanceID uint32 The identifier of the dRNG instance. dRNG subpayload oneOf TypeBeacon Defines payload data for Beacon payload type. Name Type Description Round uint64 The round of the current beacon. PartialPK ByteArray[96] The public key of the issuer. PartialSignature ByteArray[96] The collective signature of the current beacon. TypeCollectiveBeacon Defines payload data for CollectiveBeacon payload type. Name Type Description Round uint64 The round of the current beacon. PrevSignature ByteArray[96] The collective signature of the previous beacon. Signature ByteArray[96] The collective signature of the current beacon. DistributedPK ByteArray[48] The distributed public key.","title":"dRNG beacon payloads"},{"location":"IOTA-NECTAR/2.3%20Standard%20Payloads%20Layout/#drng-application-message","text":"A message used by a node to declare its willingness to participate in the Committee Selection process. Any node can issue an application message. However, low mana nodes are unlikely to be selected; hence, they can decide to not take part in sending application messages. Name Type Description Size uint32 The size of the payload. Payload Type uint32 Set to 3 to denote a Application Message payload. Version uint8 The version of the payload. InstanceID uint32 The identifier of the dRNG instance.","title":"dRNG application message"},{"location":"IOTA-NECTAR/2.3%20Standard%20Payloads%20Layout/#drng-dkg-payload","text":"The Deal messages exchanged to produce a public/private collective key during the DKG phase. The Deal messages are issued by the nodes that qualified for the dRNG committee participation (see Section 6.5 - Distributed Random Number Generator ). Name Type Description Size uint32 The size of the payload. Payload Type uint32 Set to 4 to denote a Deal Message payload. Version uint8 The version of the payload. InstanceID uint32 The identifier of the dRNG instance. FromIndex uint32 The index of the dealer. ToIndex uint32 The index of the verifier. Deal oneOf EncryptedDeal An encrypted share struct. Name Type Description Dhkey ByteArray An ephemeral Diffie-Hellman key. Nonce ByteArray The nonce used in AES-GCM. EncryptedShare ByteArray The ciphertext of the share. Threshold uint32 The threshold of the secret sharing protocol (decided during committee selection). Commitments ByteArray The commitments of the polynomial used to derive the share.","title":"dRNG DKG payload"},{"location":"IOTA-NECTAR/2.3%20Standard%20Payloads%20Layout/#salt-declaration-payload","text":"The salt declaration payload is used by nodes to declare their initial salt. In a salt declaration message, the declaring node includes the following fields: Name Type Description Size uint32 The size of the payload. Payload Type uint32 Set to 7 to denote a Salt declaration . Version uint8 The version of the payload. NodeID uint32 The declaring node ID (which may be different from the node ID of the issuer of the message). Salt oneOf Salt The public salt of the requester defined. Name Type Description Bytes ByteArray The value of the salt. ExpTime time The expiration time of the salt. Timestamp time The timestamp of the payload, which shall be close to the timestamp of its containing message. Signature The node signature, that ensures all 'redeclarations' would be malicious.","title":"Salt declaration payload"},{"location":"IOTA-NECTAR/2.3%20Standard%20Payloads%20Layout/#indexations-payload","text":"Allows the addition of an index to the encapsulating message, as well as some arbitrary data. Nodes will expose an API that will enable the querying of messages by the index. Adding those capabilities may open nodes to DOS attack vectors: 1. Proliferation of index keys that may blow up the node's DB 2. Proliferation of messages associated with the same index Node implementations may provide weak guarantees regarding the completion of indexes to address the above scenarios. Besides the index, the payload will also have a data field. A message that has been attached to the Tangle has several useful properties: verifying that the content of the data did not change and determining the approximate time it was published by checking timestamps. If the payload will be incorporated under the signed transaction payload , the content will be signed as well. The structure of the payload is simple: Name Type Description Size uint32 The size of the payload. Payload Type uint32 Set to 8 to denote an Indexation payload . Version uint8 The version of the payload. Index ByteArray The index key of the message. Data ByteArray Data we are attaching. Note that index field should be 1 to 64 bytes long for the payload to be valid. The data may have a length of 0.","title":"Indexations payload"},{"location":"IOTA-NECTAR/2.4%20Data%20flow/","text":"2.4 Data flow \u00b6 This section provides a high-level description of the interaction between components of the IOTA 2.0 protocol. The protocol can be divided into three main elements: a P2P overlay network, an immutable data structure, and a consensus mechanism. In the IOTA 2.0 protocol, these three elements are abstracted into layers, where\u2014similarly to other architectures\u2014upper layers build on the functionality provided by the layers below them. The definition of the different layers is merely about the convenience of creating a clear separation of concerns. All modules and their interactions will be described later in this document. 2.3.1 Network Layer \u00b6 The network will be maintained by the network layer modules, which can be characterized as a pure P2P overlay network, meaning that it is a system that runs on top of another network (e.g., the internet), and where all nodes have the same roles and perform the same actions (in contrast to client-server systems). IOTA 2.0's Network Layer consists of two basic modules: the peer discovery module (which provides a list of nodes actively using the network), and the neighbor selection module (also known as autopeering), which actually select peers. Finally, the gossip is managed by the network layer as well. 2.3.2 Communication Layer \u00b6 The communication layer concerns the information propagated through the network layer, which is contained in objects called messages. This layer forms a DAG with messages as vertices called The Tangle : a replicated, shared and distributed data structure that emerges through a combination of deterministic rules, cooperation, and (either direct or virtual) voting\u2014as FPC and approval weight based finality. Since nodes have finite capabilities, the number of messages that the network can process is limited. Thus, the network might become overloaded, either simply because of honest heavy usage or because of malicious (spam) attacks. To protect the network from halting or even from getting inconsistent, the rate control and congestion control modules control when and how many messages can be gossiped. 2.3.3 (Decentralized) Application Layer \u00b6 On top of the communication layer lives the application layer. Anybody can develop applications that run on this layer, and nodes can choose which applications to run. Of course, these applications can also be dependent on each other. There are several core applications that must be run by all nodes, as the value transfer applications, which maintains the ledger state and a quantity called Mana , that serves as a scarce resource to our Sybil protection mechanism. Additionally, all nodes must run what we call the consensus applications, which regulate timestamps in the messages and resolve conflicts. The Fast Probabilistic Consensus (Fast Probabilistic Consensus) application provides a binary voting protocol that produces consensus on a bit. Section 6.1 - Object of Consensus outlines how this binary voting protocol is used to vote on actual objects, particularly transactions and timestamps. In particular, FPC determines which transactions are to be written to the ledger, and which ones should be left to be orphaned. The FPC application uses another application called dRNG (distributed Random Number Generator). Lastly, the Node Perception Reorganization application enables nodes to reorganize their perception of the Tangle if needed.\". 2.3.4 Data flow - Overview \u00b6 The diagram below represents the interaction between the different modules in the protocol. Each blue box represents a component, which have events (in yellow boxes) that belong to them. Those events will trigger methods (the green boxes), that can also trigger other methods. This triggering is represented by the arrows in the diagram. Finally, the purple boxes represent events that do no belong to the component that triggered them. As an example, take the Parser component. The function ProcessGossipMessage will trigger the method Parse , which is the only entry to the component. There are three possible outcomes to the Parser : triggering a ParsingFailed event, a MessageRejected event, or a MessageParsed event. In the last case, the event will trigger the StoreMessage method (which is the entry to the Storage component), whereas the first two events do not trigger any other component. We present what we call the data flow, i.e., the life cycle of a message, from message reception (meaning that we focus here on the point of view of a node receiving a message issued by another node) up until acceptance in the Tangle. The message creation complete process is described in Section 4.8 - Message Creation. Notice that any message, either created locally by the node or received from a neighbor needs to pass through most of the data flow. Specifically, all messages pass from the Storage component to the Tip Manager. 2.3.4.1 Message Factory \u00b6 The IssuePayload function creates a valid payload which is provided to the CreateMessage method, along with a set of parents chosen with the Section 4.3 - Tip Selection Algorithm . Then, the Message Factory component is responsible to find a nonce compatible with the PoW requirements defined by the rate control module. Finally, the message is signed (see Section 2.2 - Message Layout ). Notice that the message generation should follow the rates imposed by the rate setter, as defined in Section 4.6 - Congestion Control 2.3.4.2 Parser \u00b6 The first step after the arrival of the message to the message inbox is the parsing, which consists of the five following different filtering processes (meaning that the messages that don't pass these steps will not be stored): Recently Seen Bytes: it compares the incoming messages with a pool of recently seen bytes to filter duplicates. If the message does not pass this check, the message is dropped. If it passes the check, it goes to the next step. Parsing and Syntactical Validation: it checks if the message and the payload (when present) are syntactically valid, as defined in Section 2.2 - Message Layout and Section 2.3 - Payloads Layout . If the parsing fails, a ParsingFailed event is triggered; if the Syntactical Validation fails, a MessageRejected event is triggered. If it passes both checks, it goes to the next step. Timestamp Difference Check: it checks if the timestamps of the payload and the message are consistent with each other, i.e., if transaction.timestamp+TW >= message.timestamp >= transaction.timestamp , where TW is the maximal difference between message timestamp and transaction timestamp, as defined in Section 4.2 - Timestamps . Evidently, this step is only executed when the message contains a payload. If the message does not pass this check, a MessageRejected event is triggered. If it passes the check, it goes to the next step. Signature check: it checks if the message signature is valid (see Section 2.2 - Message Layout ). If the message does not pass this check, a MessageRejected event is triggered. If it passes the check, it goes to the next step. aPoW check: it checks if the PoW requirements are met, as defined in Section 4.5 - Rate Control . If the message does not pass this check, a MessageRejected event is triggered. If it passes the check, a MessageParsed event is issued, which will trigger the Storage module. 2.3.4.3 Storage \u00b6 Only the messages that pass the Parser will be stored, along with its metadata receivedTime . As defined in Section 2.2 - Message Layout , the message has additional metadata fields, such as solidificationTime and other Boolean flags, that will be set in future points of the data flow. The storage also performs a cleaning process, which can be triggered periodically or everytime a message is marked as invalid, to delete invalid messages. 2.3.4.4 Solidifier \u00b6 The solidification is the process of requesting missing messages. In this step, the node checks if all the past cone of the message is known; in the case that the node realizes that a message in the past cone is missing, it will send a request to its neighbors asking for that missing message. This process is recursively repeated until all of a message's past cone up to the genesis (or snapshot) becomes known to the node (for more information, see Section 4.4 - Solidification ). This way, the protocol enables any node to retrieve the entire message history, even for nodes that have just joined the network. When the solidification process successfully ends, the flag solid in its metadata is set to TRUE . In the case that the process does not terminate successfully, the flag invalid is set to TRUE . If, while solidifying, the node realizes that one of the parents of the message is invalid , the message itself is also marked as invalid . Also in the solidifier, the \"Parents age check\" is performed. It consists in checking if the timestamp of the message and the timestamps of each of its parents satisfy parent.timestamp+DELTA >= message.timestamp >= parent.timestamp (see Section 4.2 - Timestamps ). As in the solidification case, if the above condition is not met, the message is marked as invalid . 2.3.4.5 Scheduler \u00b6 One may think of the scheduler as a gatekeeper to the more expensive computations. Once the steps above are successful, the message is enqueued into the outbox. The outbox is split into several queues, each one corresponding to a different node issuing messages. Once the message is enqueued into the right place, the queue is sorted by increasing message timestamp. The dequeueing process is done using a modified version of the deficit round robin (DRR) algorithm, as described in Section 4.6 - Congestion Control . A maximum (fixed) global rate SCHEDULING_RATE , at which messages will be scheduled, is set. 2.3.4.6 Booker \u00b6 After scheduling, the message goes to the booker. This step is different between messages that contain a transaction payload and messages that do not contain it. In the case of a non-value message, booking into the Tangle occurs after the conflicting parents branches check, i.e., after checking if the parents' branches contain sets of (two or more) transactions that belong to the same conflict set (see Section 5.2 - Ledger State ). In the case of this check not being successful, the message is marked as invalid and not booked. In the case of a value message, initially, the following check is done: UTXO check: it checks if the inputs of the transaction were already booked. If the message does not pass this check, the message is not booked and a TransactionNotBooked event is triggered. If it passes the check, it goes to the next block of steps. Then, the following objective checks are done: Balances check: it checks if the sum of the values of the generated outputs equals the sum of the values of the consumed inputs. If the message does not pass this check, the message is marked as invalid and not booked. If it passes the check, it goes to the next step. Unlock conditions: checks if the unlock conditions (see Section 2.3 - Standard Payloads Layout ) are valid. If the message does not pass this check, the message is marked as invalid and not booked. If it passes the check, it goes to the next step. Inputs' branches validity check: it checks if all the consumed inputs belong to a valid branch. If the message does not pass this check, the message is marked as invalid and not booked. If it passes the check, it goes to the next step. After the objective checks, the following subjective checks are done: Inputs' branches rejection check: it checks if all the consumed inputs belong to a non-rejected branch. Notice that this is not an objective check, so the node is susceptible (even if with a small probability) to have its opinion about rejected branches changed by a reorganization. For that reason, if the message does not pass this check, the message is booked into the Tangle and ledger state (even though the balances are not altered by this message, since it will be booked to a rejected branch). This is what we call \"lazy booking\", which is done to avoid huge re-calculations in case of a reorganization of the ledger. If it passes the check, it goes to the next step. Double spend check: it checks if any of the inputs is conflicting with a transaction that was already confirmed. As in the last step, this check is not objective and, thus, if the message does not pass this check, it is lazy booked into the Tangle and ledger state, into an invalid branch. If it passes the check, it goes to the next step. At this point, the missing steps are the most computationally expensive: Past cone check: it checks if the inputs of the transaction were generated by transactions in the past cone of the message. As this check is objective, if the message does not pass this check, the message is marked as invalid and not booked. If it passes the check, it goes to the next step. Inputs' conflicting branches check: it checks if the branches of the inputs are conflicting. As in the last step, if the message does not pass this check, the message is marked as invalid and not booked. If it passes the check, it goes to the next step. Conflict check: it checks if the inputs are conflicting with an unconfirmed transaction. In this step, the branch to which the message belongs is computed. In both cases (passing the check or not), the message is booked into the ledger state and the Tangle, but its branch ID will be different depending on the outcome of the check (see Section 5.2 - Ledger State ). Finally, after a message is booked, it can be gossiped. 2.3.4.7 Opinion Former \u00b6 The opinion former consists of two independent processes, that can be done in parallel: the payload opinion setting and the message timestamp opinion setting. The message timestamp opinion setting is described in Section 4.2 - Timestamps , and it's done after a initial timestamp check (and possible FPC voting, as described in Section 6.3 - Fast Probabilistic Consensus ). In parallel to the message timestamp opinion setting, a payload evaluation is also done. If the message does not contain a transaction payload, the payload opinion is automatically set to liked . Otherwise, it has to pass the FCoB rule (and possibly, an FPC voting) in order to be liked , as described in Section 4.2 - Timestamps and Section 6.3 - Fast Probabilistic Consensus . 2.3.4.8 Tip Manager \u00b6 The first check done in the tip manager is the eligibility check, which is defined in Section 4.2 - Timestamps , after passing it, a message is said to be eligible for tip selection (otherwise, it's not eligible ). If a message is eligible for tip selection and its payload is liked , along with all its weak past cone, the message is added to the strong tip pool and its parents are removed from the strong tip pool (for more information about the different tip pools, see Section 4.3 - Tip Selection Algorithm ). If a message is eligible for tip selection, its payload is liked and the message is not in the strong pool, it is added to the weak tip pool and its parents are removed from any the pool that they are included.","title":"2.4 Data flow"},{"location":"IOTA-NECTAR/2.4%20Data%20flow/#24-data-flow","text":"This section provides a high-level description of the interaction between components of the IOTA 2.0 protocol. The protocol can be divided into three main elements: a P2P overlay network, an immutable data structure, and a consensus mechanism. In the IOTA 2.0 protocol, these three elements are abstracted into layers, where\u2014similarly to other architectures\u2014upper layers build on the functionality provided by the layers below them. The definition of the different layers is merely about the convenience of creating a clear separation of concerns. All modules and their interactions will be described later in this document.","title":"2.4 Data flow"},{"location":"IOTA-NECTAR/2.4%20Data%20flow/#231-network-layer","text":"The network will be maintained by the network layer modules, which can be characterized as a pure P2P overlay network, meaning that it is a system that runs on top of another network (e.g., the internet), and where all nodes have the same roles and perform the same actions (in contrast to client-server systems). IOTA 2.0's Network Layer consists of two basic modules: the peer discovery module (which provides a list of nodes actively using the network), and the neighbor selection module (also known as autopeering), which actually select peers. Finally, the gossip is managed by the network layer as well.","title":"2.3.1 Network Layer"},{"location":"IOTA-NECTAR/2.4%20Data%20flow/#232-communication-layer","text":"The communication layer concerns the information propagated through the network layer, which is contained in objects called messages. This layer forms a DAG with messages as vertices called The Tangle : a replicated, shared and distributed data structure that emerges through a combination of deterministic rules, cooperation, and (either direct or virtual) voting\u2014as FPC and approval weight based finality. Since nodes have finite capabilities, the number of messages that the network can process is limited. Thus, the network might become overloaded, either simply because of honest heavy usage or because of malicious (spam) attacks. To protect the network from halting or even from getting inconsistent, the rate control and congestion control modules control when and how many messages can be gossiped.","title":"2.3.2 Communication Layer"},{"location":"IOTA-NECTAR/2.4%20Data%20flow/#233-decentralized-application-layer","text":"On top of the communication layer lives the application layer. Anybody can develop applications that run on this layer, and nodes can choose which applications to run. Of course, these applications can also be dependent on each other. There are several core applications that must be run by all nodes, as the value transfer applications, which maintains the ledger state and a quantity called Mana , that serves as a scarce resource to our Sybil protection mechanism. Additionally, all nodes must run what we call the consensus applications, which regulate timestamps in the messages and resolve conflicts. The Fast Probabilistic Consensus (Fast Probabilistic Consensus) application provides a binary voting protocol that produces consensus on a bit. Section 6.1 - Object of Consensus outlines how this binary voting protocol is used to vote on actual objects, particularly transactions and timestamps. In particular, FPC determines which transactions are to be written to the ledger, and which ones should be left to be orphaned. The FPC application uses another application called dRNG (distributed Random Number Generator). Lastly, the Node Perception Reorganization application enables nodes to reorganize their perception of the Tangle if needed.\".","title":"2.3.3 (Decentralized) Application Layer"},{"location":"IOTA-NECTAR/2.4%20Data%20flow/#234-data-flow-overview","text":"The diagram below represents the interaction between the different modules in the protocol. Each blue box represents a component, which have events (in yellow boxes) that belong to them. Those events will trigger methods (the green boxes), that can also trigger other methods. This triggering is represented by the arrows in the diagram. Finally, the purple boxes represent events that do no belong to the component that triggered them. As an example, take the Parser component. The function ProcessGossipMessage will trigger the method Parse , which is the only entry to the component. There are three possible outcomes to the Parser : triggering a ParsingFailed event, a MessageRejected event, or a MessageParsed event. In the last case, the event will trigger the StoreMessage method (which is the entry to the Storage component), whereas the first two events do not trigger any other component. We present what we call the data flow, i.e., the life cycle of a message, from message reception (meaning that we focus here on the point of view of a node receiving a message issued by another node) up until acceptance in the Tangle. The message creation complete process is described in Section 4.8 - Message Creation. Notice that any message, either created locally by the node or received from a neighbor needs to pass through most of the data flow. Specifically, all messages pass from the Storage component to the Tip Manager.","title":"2.3.4 Data flow - Overview"},{"location":"IOTA-NECTAR/2.4%20Data%20flow/#2341-message-factory","text":"The IssuePayload function creates a valid payload which is provided to the CreateMessage method, along with a set of parents chosen with the Section 4.3 - Tip Selection Algorithm . Then, the Message Factory component is responsible to find a nonce compatible with the PoW requirements defined by the rate control module. Finally, the message is signed (see Section 2.2 - Message Layout ). Notice that the message generation should follow the rates imposed by the rate setter, as defined in Section 4.6 - Congestion Control","title":"2.3.4.1 Message Factory"},{"location":"IOTA-NECTAR/2.4%20Data%20flow/#2342-parser","text":"The first step after the arrival of the message to the message inbox is the parsing, which consists of the five following different filtering processes (meaning that the messages that don't pass these steps will not be stored): Recently Seen Bytes: it compares the incoming messages with a pool of recently seen bytes to filter duplicates. If the message does not pass this check, the message is dropped. If it passes the check, it goes to the next step. Parsing and Syntactical Validation: it checks if the message and the payload (when present) are syntactically valid, as defined in Section 2.2 - Message Layout and Section 2.3 - Payloads Layout . If the parsing fails, a ParsingFailed event is triggered; if the Syntactical Validation fails, a MessageRejected event is triggered. If it passes both checks, it goes to the next step. Timestamp Difference Check: it checks if the timestamps of the payload and the message are consistent with each other, i.e., if transaction.timestamp+TW >= message.timestamp >= transaction.timestamp , where TW is the maximal difference between message timestamp and transaction timestamp, as defined in Section 4.2 - Timestamps . Evidently, this step is only executed when the message contains a payload. If the message does not pass this check, a MessageRejected event is triggered. If it passes the check, it goes to the next step. Signature check: it checks if the message signature is valid (see Section 2.2 - Message Layout ). If the message does not pass this check, a MessageRejected event is triggered. If it passes the check, it goes to the next step. aPoW check: it checks if the PoW requirements are met, as defined in Section 4.5 - Rate Control . If the message does not pass this check, a MessageRejected event is triggered. If it passes the check, a MessageParsed event is issued, which will trigger the Storage module.","title":"2.3.4.2 Parser"},{"location":"IOTA-NECTAR/2.4%20Data%20flow/#2343-storage","text":"Only the messages that pass the Parser will be stored, along with its metadata receivedTime . As defined in Section 2.2 - Message Layout , the message has additional metadata fields, such as solidificationTime and other Boolean flags, that will be set in future points of the data flow. The storage also performs a cleaning process, which can be triggered periodically or everytime a message is marked as invalid, to delete invalid messages.","title":"2.3.4.3 Storage"},{"location":"IOTA-NECTAR/2.4%20Data%20flow/#2344-solidifier","text":"The solidification is the process of requesting missing messages. In this step, the node checks if all the past cone of the message is known; in the case that the node realizes that a message in the past cone is missing, it will send a request to its neighbors asking for that missing message. This process is recursively repeated until all of a message's past cone up to the genesis (or snapshot) becomes known to the node (for more information, see Section 4.4 - Solidification ). This way, the protocol enables any node to retrieve the entire message history, even for nodes that have just joined the network. When the solidification process successfully ends, the flag solid in its metadata is set to TRUE . In the case that the process does not terminate successfully, the flag invalid is set to TRUE . If, while solidifying, the node realizes that one of the parents of the message is invalid , the message itself is also marked as invalid . Also in the solidifier, the \"Parents age check\" is performed. It consists in checking if the timestamp of the message and the timestamps of each of its parents satisfy parent.timestamp+DELTA >= message.timestamp >= parent.timestamp (see Section 4.2 - Timestamps ). As in the solidification case, if the above condition is not met, the message is marked as invalid .","title":"2.3.4.4 Solidifier"},{"location":"IOTA-NECTAR/2.4%20Data%20flow/#2345-scheduler","text":"One may think of the scheduler as a gatekeeper to the more expensive computations. Once the steps above are successful, the message is enqueued into the outbox. The outbox is split into several queues, each one corresponding to a different node issuing messages. Once the message is enqueued into the right place, the queue is sorted by increasing message timestamp. The dequeueing process is done using a modified version of the deficit round robin (DRR) algorithm, as described in Section 4.6 - Congestion Control . A maximum (fixed) global rate SCHEDULING_RATE , at which messages will be scheduled, is set.","title":"2.3.4.5 Scheduler"},{"location":"IOTA-NECTAR/2.4%20Data%20flow/#2346-booker","text":"After scheduling, the message goes to the booker. This step is different between messages that contain a transaction payload and messages that do not contain it. In the case of a non-value message, booking into the Tangle occurs after the conflicting parents branches check, i.e., after checking if the parents' branches contain sets of (two or more) transactions that belong to the same conflict set (see Section 5.2 - Ledger State ). In the case of this check not being successful, the message is marked as invalid and not booked. In the case of a value message, initially, the following check is done: UTXO check: it checks if the inputs of the transaction were already booked. If the message does not pass this check, the message is not booked and a TransactionNotBooked event is triggered. If it passes the check, it goes to the next block of steps. Then, the following objective checks are done: Balances check: it checks if the sum of the values of the generated outputs equals the sum of the values of the consumed inputs. If the message does not pass this check, the message is marked as invalid and not booked. If it passes the check, it goes to the next step. Unlock conditions: checks if the unlock conditions (see Section 2.3 - Standard Payloads Layout ) are valid. If the message does not pass this check, the message is marked as invalid and not booked. If it passes the check, it goes to the next step. Inputs' branches validity check: it checks if all the consumed inputs belong to a valid branch. If the message does not pass this check, the message is marked as invalid and not booked. If it passes the check, it goes to the next step. After the objective checks, the following subjective checks are done: Inputs' branches rejection check: it checks if all the consumed inputs belong to a non-rejected branch. Notice that this is not an objective check, so the node is susceptible (even if with a small probability) to have its opinion about rejected branches changed by a reorganization. For that reason, if the message does not pass this check, the message is booked into the Tangle and ledger state (even though the balances are not altered by this message, since it will be booked to a rejected branch). This is what we call \"lazy booking\", which is done to avoid huge re-calculations in case of a reorganization of the ledger. If it passes the check, it goes to the next step. Double spend check: it checks if any of the inputs is conflicting with a transaction that was already confirmed. As in the last step, this check is not objective and, thus, if the message does not pass this check, it is lazy booked into the Tangle and ledger state, into an invalid branch. If it passes the check, it goes to the next step. At this point, the missing steps are the most computationally expensive: Past cone check: it checks if the inputs of the transaction were generated by transactions in the past cone of the message. As this check is objective, if the message does not pass this check, the message is marked as invalid and not booked. If it passes the check, it goes to the next step. Inputs' conflicting branches check: it checks if the branches of the inputs are conflicting. As in the last step, if the message does not pass this check, the message is marked as invalid and not booked. If it passes the check, it goes to the next step. Conflict check: it checks if the inputs are conflicting with an unconfirmed transaction. In this step, the branch to which the message belongs is computed. In both cases (passing the check or not), the message is booked into the ledger state and the Tangle, but its branch ID will be different depending on the outcome of the check (see Section 5.2 - Ledger State ). Finally, after a message is booked, it can be gossiped.","title":"2.3.4.6 Booker"},{"location":"IOTA-NECTAR/2.4%20Data%20flow/#2347-opinion-former","text":"The opinion former consists of two independent processes, that can be done in parallel: the payload opinion setting and the message timestamp opinion setting. The message timestamp opinion setting is described in Section 4.2 - Timestamps , and it's done after a initial timestamp check (and possible FPC voting, as described in Section 6.3 - Fast Probabilistic Consensus ). In parallel to the message timestamp opinion setting, a payload evaluation is also done. If the message does not contain a transaction payload, the payload opinion is automatically set to liked . Otherwise, it has to pass the FCoB rule (and possibly, an FPC voting) in order to be liked , as described in Section 4.2 - Timestamps and Section 6.3 - Fast Probabilistic Consensus .","title":"2.3.4.7 Opinion Former"},{"location":"IOTA-NECTAR/2.4%20Data%20flow/#2348-tip-manager","text":"The first check done in the tip manager is the eligibility check, which is defined in Section 4.2 - Timestamps , after passing it, a message is said to be eligible for tip selection (otherwise, it's not eligible ). If a message is eligible for tip selection and its payload is liked , along with all its weak past cone, the message is added to the strong tip pool and its parents are removed from the strong tip pool (for more information about the different tip pools, see Section 4.3 - Tip Selection Algorithm ). If a message is eligible for tip selection, its payload is liked and the message is not in the strong pool, it is added to the weak tip pool and its parents are removed from any the pool that they are included.","title":"2.3.4.8 Tip Manager"},{"location":"IOTA-NECTAR/3.3%20Peer%20Discovery/","text":"3.3 Peer Discovery \u00b6 Introduction \u00b6 This section defines the Peer Discovery protocol, its logic and the different requests and responses exchanged. In order to establish connections, an IOTA node needs to discover and maintain a list of the reachable IP addresses of other peers. Moreover, some external modules, such as the Neighbor Selection and the Fast Probabilistic Consensus (FPC) may require an updated list of known peers. The main goal of the Peer Discovery protocol is to expose an interface providing a list of all the verified peers. Throughout this section the terms Node and Peer are used interchangeably to refer to a Node device. The usage of the Ping and Pong mechanism is to be considered as a bidirectional exchange similarly to how described by other standards such as CoAP and WebSocket . Detailed design \u00b6 To bootstrap the peer discovery, a node must be able to reach one or more entry nodes. To achieve this, the implementation of the protocol shall provide a hard-coded list of trusted entry nodes run by the IF or by trusted community members that answer to peer discovery packets coming from new nodes joining the IOTA network. This approach is a common practice of many distributed networks [Neudecker 2018] . Public Key-based Cryptography (PKC) shall be used for uniquely identifying peers and for authenticating each packet. The usage of the Ping and Pong protocols is that Ping are sent to verify a given peer and, upon reception of a valid Pong as a response from that peer, the peer is verified. Once a peer has been verified, it can be queried to discover new peers by sending a DiscoveryRequest . As a response, a DiscoveryResponse shall be returned, containing a list of new peers. The new peer nodes in this list shall be verified by the receiving application. This process is summarized in the following figure and detailed in the following subsections: Node identities \u00b6 Every node has a cryptographic identity, a key on the ed25519 elliptic curve. The blake2b hash of the public key of the peer serves as its identifier or node ID . Verification \u00b6 The verification process aims at both verifying peer identities and checking their online status. Each peer shall maintain a list of all the known peers. This list shall be called known_peer_list . Elements of any known peer list shall contain a reference to a Peer and a time at which it shall be verified/re-verified. As such, the known_peer_list can be seen as a time-priority queue. A newly discovered peer gets added to the list at the current time. Whenever a peer is verified, its time value on the known_peer_list gets updated to the time at which that peer shall be re-verified. The intent of this arrangement is to allow the node application to first verify newly discovered (and thus still unverified) peers and then to re-verify older peers (to confirm their online status) by iterating over the known_peer_list . It is worthwhile to note that the order in which the known_peer_list is worked through is important. For example, if the peer is added to the front ('head') of the known_peer_list , it is possible for an adversary to front-fill the known_peer_list with a selection of its own nodes. This is resolved by the use of the time-priority queue. The verification process always initiates from a Ping . Upon reception of a Ping , a peer shall check its validity by: * verifying that the signature of the Ping is valid and discarding the request otherwise; * checking that the version and network_id fields match its configuration and discarding the Ping otherwise; * checking that the timestamp field is fresh (i.e., not older than a given time) and discarding the packet otherwise; * checking that the dest_addr matches its IP address and discarding the Ping otherwise. Upon successful validation of a received Ping , a peer shall respond with a Pong . In case the sender of the Ping is a new peer from the perspective of the receiving node, the receiver peer shall add it to its known_peer_list . This enables the verification process to also occur in the reverse direction. Upon reception of a Pong , a peer shall check its validity by: * verifying that the signature of the Pong is valid and discarding it otherwise; * checking that the req_hash field matches a request (i.e. Ping ) previously sent and not expired (i.e., the difference between the timestamp of the Ping and Pong is not greater than a given threshold) and discarding the associated Ping or Pong otherwise; * checking that the dest_addr matches its IP address and discarding the associated Ping or Pong otherwise. Upon successful validation of a received Pong , a peer shall : * add the peer sender of the Pong to a list of verified peers called verified_peer_list ; * move the peer entry of the known_peer_list to the tail. Removal \u00b6 While verifying a new peer, if no or an invalid Pong is received after max_verify_attempts attempts, that node shall be removed from the known_peer_list . Each expected reply should have a timeout such that if no answer is received after that, an attempt is considered concluded and counted as failed. Each peer on the verified_peer_list shall be re-verified after verification_lifetime hours; while re-verifying a peer, if no or invalid Pong is received after max_reverify_attempts attempts, the peer shall be removed from the verified_peer_list . Discovery \u00b6 Each peer entry of the verified_peer_list may be used to discover new peers. This process is initiated by sending a DiscoveryRequest . Upon reception of a DiscoveryRequest , a peer node shall check its validity by: * checking that the sender of the DiscoveryRequest is a verified peer (i.e. is stored in the verified_peer_list ) and discarding the request otherwise; * verifying that the signature of the DiscoveryRequest is valid and discarding the request otherwise; * checking that the timestamp field is fresh (i.e., not older than a given time) and discarding the request otherwise. Upon successful validation of a received DiscoveryRequest , a peer shall reply with a DiscoveryResponse . Upon reception of a DiscoveryResponse , a peer shall check its validity by: * verifying that the signature of the DiscoveryResponse is valid and discarding the response otherwise; * checking that the req_hash field matches a discovery request (i.e. DiscoveryRequest ) previously sent and not expired (i.e., the difference between the timestamp of the DiscoveryRequest and DiscoveryResponse is not greater than a given threshold) and discarding the response otherwise. Upon successful validation of a received DiscoveryResponse , a node shall add the nodes contained in the peers field to the known_peer_list . Ping and Pong Layout \u00b6 Each Ping and Pong shall be encapsulated into a data field of a generic Request and Response . Its type shall be specified in the type field. Each request and response shall be signed with the ed25519 private key of the sender's identity and shall contain the related public key, in order to allow the packet receiving node to verify the signature. All the received responses shall be verified and those with invalid signature shall be discarded. Request and Response Layout \u00b6 Name Type Description type uint8 Defines the type of the request or response. data ByteArray contains the payload of the request or response (e.g., a Ping). public_key ByteArray[32] The ed25519 public key of the peer's identity used to verify its signatures. signature ByteArray[32] The ed25519 signature of the `data` field, signed by using the private key of the peer's identity. Ping \u00b6 Name Type Description version uint32 The version of the protocol. network_id uint32 The network identifier. timestamp time The unix timestamp of the Ping. src_addr string The IP address, in string form, of the sender (e.g., \"192.0.2.1\", \"[2001:db8::1]\"). src_port uint32 The listening port of the sender. dst_addr string The string form of the receiver's IP address. This provides a way to discover the external address (after NAT). Pong \u00b6 Name Type Description req_hash ByteArray[32] The blake2b digest of the corresponding received Ping. services Services supported by the Pong sender. Name Type Description serviceID ByteArray[32] The service ID (e.g., autopeering, gossip, fpc). network string The string form of the network (e.g., udp, tcp). port uint32 The listening port of the service. dst_addr string the string form of the receiver's IP address. This MUST mirror the src_addr of the Ping's IP packet. It provides a way to discover the external address (after NAT). DiscoveryRequest \u00b6 Name Type Description timestamp time The unix timestamp of the DiscoveryRequest. DiscoveryResponse \u00b6 Name Type Description req_hash ByteArray[32] The blake2b digest of the corresponding received DiscoveryRequest. peers The list of some randomly chosen peers known by the sender of the DiscoveryResponse between(1,6). Name Type Description public_key ByteArray[32] The ed25519 public key of the peer's identity used to verify its signature. ip string The string form of the peer's IP address. services Services supported by the peer. Name Type Description serviceID ByteArray[32] The service ID (e.g., autopeering, gossip, fpc). network string The string form of the network (e.g., udp, tcp). port uint32 The listening port of the service. Denial of Service \u00b6 All the requests and responses exchanged during the Peer Discovery protocol are sent via UDP. As such, any UDP based Denial of Service attack could harm the normal functionality of the protocol. To limit this, hardware based protection such as Firewall or alternatively, rate limiting the incoming requests and responses via leaky/token buckets based techniques could be used.","title":"3.3 Peer Discovery"},{"location":"IOTA-NECTAR/3.3%20Peer%20Discovery/#33-peer-discovery","text":"","title":"3.3 Peer Discovery"},{"location":"IOTA-NECTAR/3.3%20Peer%20Discovery/#introduction","text":"This section defines the Peer Discovery protocol, its logic and the different requests and responses exchanged. In order to establish connections, an IOTA node needs to discover and maintain a list of the reachable IP addresses of other peers. Moreover, some external modules, such as the Neighbor Selection and the Fast Probabilistic Consensus (FPC) may require an updated list of known peers. The main goal of the Peer Discovery protocol is to expose an interface providing a list of all the verified peers. Throughout this section the terms Node and Peer are used interchangeably to refer to a Node device. The usage of the Ping and Pong mechanism is to be considered as a bidirectional exchange similarly to how described by other standards such as CoAP and WebSocket .","title":"Introduction"},{"location":"IOTA-NECTAR/3.3%20Peer%20Discovery/#detailed-design","text":"To bootstrap the peer discovery, a node must be able to reach one or more entry nodes. To achieve this, the implementation of the protocol shall provide a hard-coded list of trusted entry nodes run by the IF or by trusted community members that answer to peer discovery packets coming from new nodes joining the IOTA network. This approach is a common practice of many distributed networks [Neudecker 2018] . Public Key-based Cryptography (PKC) shall be used for uniquely identifying peers and for authenticating each packet. The usage of the Ping and Pong protocols is that Ping are sent to verify a given peer and, upon reception of a valid Pong as a response from that peer, the peer is verified. Once a peer has been verified, it can be queried to discover new peers by sending a DiscoveryRequest . As a response, a DiscoveryResponse shall be returned, containing a list of new peers. The new peer nodes in this list shall be verified by the receiving application. This process is summarized in the following figure and detailed in the following subsections:","title":"Detailed design"},{"location":"IOTA-NECTAR/3.3%20Peer%20Discovery/#node-identities","text":"Every node has a cryptographic identity, a key on the ed25519 elliptic curve. The blake2b hash of the public key of the peer serves as its identifier or node ID .","title":"Node identities"},{"location":"IOTA-NECTAR/3.3%20Peer%20Discovery/#verification","text":"The verification process aims at both verifying peer identities and checking their online status. Each peer shall maintain a list of all the known peers. This list shall be called known_peer_list . Elements of any known peer list shall contain a reference to a Peer and a time at which it shall be verified/re-verified. As such, the known_peer_list can be seen as a time-priority queue. A newly discovered peer gets added to the list at the current time. Whenever a peer is verified, its time value on the known_peer_list gets updated to the time at which that peer shall be re-verified. The intent of this arrangement is to allow the node application to first verify newly discovered (and thus still unverified) peers and then to re-verify older peers (to confirm their online status) by iterating over the known_peer_list . It is worthwhile to note that the order in which the known_peer_list is worked through is important. For example, if the peer is added to the front ('head') of the known_peer_list , it is possible for an adversary to front-fill the known_peer_list with a selection of its own nodes. This is resolved by the use of the time-priority queue. The verification process always initiates from a Ping . Upon reception of a Ping , a peer shall check its validity by: * verifying that the signature of the Ping is valid and discarding the request otherwise; * checking that the version and network_id fields match its configuration and discarding the Ping otherwise; * checking that the timestamp field is fresh (i.e., not older than a given time) and discarding the packet otherwise; * checking that the dest_addr matches its IP address and discarding the Ping otherwise. Upon successful validation of a received Ping , a peer shall respond with a Pong . In case the sender of the Ping is a new peer from the perspective of the receiving node, the receiver peer shall add it to its known_peer_list . This enables the verification process to also occur in the reverse direction. Upon reception of a Pong , a peer shall check its validity by: * verifying that the signature of the Pong is valid and discarding it otherwise; * checking that the req_hash field matches a request (i.e. Ping ) previously sent and not expired (i.e., the difference between the timestamp of the Ping and Pong is not greater than a given threshold) and discarding the associated Ping or Pong otherwise; * checking that the dest_addr matches its IP address and discarding the associated Ping or Pong otherwise. Upon successful validation of a received Pong , a peer shall : * add the peer sender of the Pong to a list of verified peers called verified_peer_list ; * move the peer entry of the known_peer_list to the tail.","title":"Verification"},{"location":"IOTA-NECTAR/3.3%20Peer%20Discovery/#removal","text":"While verifying a new peer, if no or an invalid Pong is received after max_verify_attempts attempts, that node shall be removed from the known_peer_list . Each expected reply should have a timeout such that if no answer is received after that, an attempt is considered concluded and counted as failed. Each peer on the verified_peer_list shall be re-verified after verification_lifetime hours; while re-verifying a peer, if no or invalid Pong is received after max_reverify_attempts attempts, the peer shall be removed from the verified_peer_list .","title":"Removal"},{"location":"IOTA-NECTAR/3.3%20Peer%20Discovery/#discovery","text":"Each peer entry of the verified_peer_list may be used to discover new peers. This process is initiated by sending a DiscoveryRequest . Upon reception of a DiscoveryRequest , a peer node shall check its validity by: * checking that the sender of the DiscoveryRequest is a verified peer (i.e. is stored in the verified_peer_list ) and discarding the request otherwise; * verifying that the signature of the DiscoveryRequest is valid and discarding the request otherwise; * checking that the timestamp field is fresh (i.e., not older than a given time) and discarding the request otherwise. Upon successful validation of a received DiscoveryRequest , a peer shall reply with a DiscoveryResponse . Upon reception of a DiscoveryResponse , a peer shall check its validity by: * verifying that the signature of the DiscoveryResponse is valid and discarding the response otherwise; * checking that the req_hash field matches a discovery request (i.e. DiscoveryRequest ) previously sent and not expired (i.e., the difference between the timestamp of the DiscoveryRequest and DiscoveryResponse is not greater than a given threshold) and discarding the response otherwise. Upon successful validation of a received DiscoveryResponse , a node shall add the nodes contained in the peers field to the known_peer_list .","title":"Discovery"},{"location":"IOTA-NECTAR/3.3%20Peer%20Discovery/#ping-and-pong-layout","text":"Each Ping and Pong shall be encapsulated into a data field of a generic Request and Response . Its type shall be specified in the type field. Each request and response shall be signed with the ed25519 private key of the sender's identity and shall contain the related public key, in order to allow the packet receiving node to verify the signature. All the received responses shall be verified and those with invalid signature shall be discarded.","title":"Ping and Pong Layout"},{"location":"IOTA-NECTAR/3.3%20Peer%20Discovery/#request-and-response-layout","text":"Name Type Description type uint8 Defines the type of the request or response. data ByteArray contains the payload of the request or response (e.g., a Ping). public_key ByteArray[32] The ed25519 public key of the peer's identity used to verify its signatures. signature ByteArray[32] The ed25519 signature of the `data` field, signed by using the private key of the peer's identity.","title":"Request and Response Layout"},{"location":"IOTA-NECTAR/3.3%20Peer%20Discovery/#ping","text":"Name Type Description version uint32 The version of the protocol. network_id uint32 The network identifier. timestamp time The unix timestamp of the Ping. src_addr string The IP address, in string form, of the sender (e.g., \"192.0.2.1\", \"[2001:db8::1]\"). src_port uint32 The listening port of the sender. dst_addr string The string form of the receiver's IP address. This provides a way to discover the external address (after NAT).","title":"Ping"},{"location":"IOTA-NECTAR/3.3%20Peer%20Discovery/#pong","text":"Name Type Description req_hash ByteArray[32] The blake2b digest of the corresponding received Ping. services Services supported by the Pong sender. Name Type Description serviceID ByteArray[32] The service ID (e.g., autopeering, gossip, fpc). network string The string form of the network (e.g., udp, tcp). port uint32 The listening port of the service. dst_addr string the string form of the receiver's IP address. This MUST mirror the src_addr of the Ping's IP packet. It provides a way to discover the external address (after NAT).","title":"Pong"},{"location":"IOTA-NECTAR/3.3%20Peer%20Discovery/#discoveryrequest","text":"Name Type Description timestamp time The unix timestamp of the DiscoveryRequest.","title":"DiscoveryRequest"},{"location":"IOTA-NECTAR/3.3%20Peer%20Discovery/#discoveryresponse","text":"Name Type Description req_hash ByteArray[32] The blake2b digest of the corresponding received DiscoveryRequest. peers The list of some randomly chosen peers known by the sender of the DiscoveryResponse between(1,6). Name Type Description public_key ByteArray[32] The ed25519 public key of the peer's identity used to verify its signature. ip string The string form of the peer's IP address. services Services supported by the peer. Name Type Description serviceID ByteArray[32] The service ID (e.g., autopeering, gossip, fpc). network string The string form of the network (e.g., udp, tcp). port uint32 The listening port of the service.","title":"DiscoveryResponse"},{"location":"IOTA-NECTAR/3.3%20Peer%20Discovery/#denial-of-service","text":"All the requests and responses exchanged during the Peer Discovery protocol are sent via UDP. As such, any UDP based Denial of Service attack could harm the normal functionality of the protocol. To limit this, hardware based protection such as Firewall or alternatively, rate limiting the incoming requests and responses via leaky/token buckets based techniques could be used.","title":"Denial of Service"},{"location":"IOTA-NECTAR/3.4%20Neighbor%20Selection/","text":"3.4 Neighbor Selection \u00b6 Introduction \u00b6 This section defines the Neighbor Selection protocol, its logic and the different requests and responses exchanged between nodes. In order for the network to work efficiently and for the nodes to be kept up-to-date about the ledger state, nodes exchange information with each other. Each node establishes a communication channel with a small subset of nodes (i.e., neighbors) via a process called peering . Such a process must be resilient against eclipse attacks: if all of a node\u2019s neighbors are controlled by an attacker, then the attacker has complete control over the node\u2019s view of the Tangle. Moreover, to prevent or limitate sybil-based attacks, the neighbor selection protocol makes use of a scarce resource dubbed Consensus Mana: arbitrary nodes can be created, but it is difficult to produce high mana nodes. Throughout this section, the terms Node and Peer are used interchangeably to refer to a Node device. The term neighbors implies a mutual relationship between two nodes put in place as a direct connection established and used by the gossip layer. Dependencies \u00b6 The Neighbor Selection protocol depends on: Peer discovery: to get a list of the known and verified node peers. Consensus Mana: to make the neighbor selection based on cMana value. Whenever mana value term is used in this specification, it refers to the Active cMana value from the last finalized epoch. Detailed design \u00b6 The goal of the neighbor selection is to build a node's neighborhood (to be used by the gossip protocol) while preventing attackers from \u201ctricking\u201d other nodes into becoming neighbors. Neighbors are established when one node sends a peering request to another node, which in turn accepts or rejects the request with a peering response. To prevent attacks, the protocol makes the peering request verifiably random such that attackers cannot create nodes to which the target node will send requests. At its core, the neighbor selection protocol uses both a screening process called Consensus Mana rank and a score function that takes into account some randomness dubbed private salt and public salt . Half of the neighbors will be constituted from nodes that accepted the peering request, while half will be constituted of nodes that will request for the peering. The two distinct groups of neighbors are consequently called: + Chosen neighbors (outbound). The peers that the node proactively selected through the neighbor selection mechanism. + Accepted neighbors (inbound). The peers that sent the peering request to the node and were accepted as a neighbor. Local variables \u00b6 Local variables defined here are included to help in understanding the protocol described in this section. The node application shall handle those variables in some form. Name Type Description saltUpdateInterval duration The time interval at which nodes shall update their salts. responseTimeout duration The time that node waits for a response during one peering attempt. requestExpirationTime duration The time used for the request timestamp validation, if the timestamp is older than this threshold the request is dropped. maxPeeringAttempts integer The maximum number of peering requests retries sent to the selected node before the next salt update. Node identities \u00b6 As for the peer discovery protocol, every node has a cryptographic identity, a key on the Ed25519 elliptic curve. The blake2b hash of the public key of the peer node serves as its identifier or node ID . Salt generation \u00b6 Nodes shall have a public and private salt both defined as array bytes of size 20. Nodes shall update both their public and private salt at a common fixed time interval saltUpdateInterval (e.g. 3 hours). The public salt is used for outbound peering requests, while the private salt is used during inbound peering requests. The public salt must satisfy the following requirements: Future salts must be unguessable: mining node ids to reduce the request score shall be prohibitive. This offers protection for the requesting nodes. Salts must be chosen in a non-arbitrary way: if adversaries may choose their salt, they could manufacture malicious requests to any node. This section proposes to set the public salts using hash chains, while private salts can be randomly generated on the fly. The nodes shall create a hash chain \u03b6 = {\u03b6_0, \u03b6_1, ..., \u03b6_m} where next chain element is created by hashing the previous one: \u03b6_{i+1} = hash(\u03b6_i) . Then nodes shall make public the last element \u03b6_m of their hash chain as their initial salt. Every future salt is the next element of the hash chain. Under this proposal, property 1 above holds because cryptographic hash functions are virtually irreversible. Property 2 holds fairly well: an adversary can only choose one element of their hash chain. Indeed, an adversary can pick a number to be their 300 th salt, hash it 300 times, and post that as their initial salt. However, an adversary can only do this for one round since hash functions have effectively random outputs. Thus an adversary is limited in their ability to choose their own salt. Mana rank interval \u00b6 Each peer discovered and verified via the Peer Discovery protocol shall have a consensus mana value associated with it. The peer running the Neighbor Selection protocol shall keep this information up-to-date and use it to update a data structure called manaRank containing the list of the nodes' identities for each mana value. The aim of this ranking is to select a subset of peers having similar mana to the node preparing the ranking. More specifically, let's define potentialNeighbors to be such a subset, that is divided into a lower and an upper set with respect to a targetMana value (i.e., the mana value of the node performing the ranking). By iterating over the manaRank , each node shall fill both the lower and upper sets with nodes' identities having a similar rank to itself, not less/greater than a given threshold rho respectively, except when each subset does not reach the minimal size r . The following pseudocode describes a reference implementation of this process: Inputs: manaRank: mapping between mana values and the list of nodes' identities with that mana; targetMana: the mana value of the node performing the ranking; rho: the ratio determining the length of the rank to consider; r: the minimum number of nodes' identities to return for both lower and upper sets; Largest(r, targetMana): the set of r largest cMana holders less than targetMana; Smallest(r, targetMana): the set of r smallest cMana holders greater than targetMana; Outputs: potentialNeighbors: the set of nodes' identities to consider for neighbor selection; FOR mana IN manaRank nodeID = manaRank [ mana ] IF mana > targetMana IF mana / targetMana < rho Append ( upperSet , nodeID ) ELSE IF mana == 0 || mana == targetMana BREAK ELSE IF targetMana / mana < rho Append ( lowerSet , nodeID ) IF Len ( lowerSet ) < r // set lowerSet with the r largest mana holders less than targetMana lowerSet = Largest ( r , targetMana ) IF Len ( upperSet ) < r // set upperSet with the r smallest mana holders greater than targetMana upperSet = Smallest ( r , targetMana ) potentialNeighbors = Append ( upperSet , lowerSet ) RETURN potentialNeighbors Selection \u00b6 The maximum number of neighbors is a parameter of the gossip protocol. This section proposes to use a size of 8 equally divided into 4 chosen (outbound) and 4 accepted (inbound) neighbors. It is crucial to decide on a fixed number of neighbors, as the constant number decreases an eclipse probability exponentially. The chosen k is a compromise between having more connections resulting in lower performance and increased protection from an eclipse attack. The operations involved during neighbor selection are listed in the following: Get an up-to-date list of verified and known peers from the Peer Discovery protocol. Use mana rank to filter the previous list to obtain a list of peers to be potential neighbors. Use the score function to request/accept neighbors. The score between two nodes is measured through the score function s , defined by: s(nodeID1, nodeID2, salt) = hash(nodeID1 || nodeID2 || salt), where: nodeID1 and nodeID2 are the identities of the considered nodes. salt is the salt value that can be private or public depending on the peering direction (inbound/outbound). hash is the blake2b hash function. || is the concatanation operation. Note that the value used as the score is an unsigned integer derived from the first 4 bytes of the byte array after the hash function. In order to connect to new neighbors, each node with ID ownID and public salt pubSalt keeps a list of potential neighbors derived via Mana rank that is sorted by their score d(ownID, \u00b7, pubSalt) . Then, the node shall send peering requests in ascending order , containing its own current public salt and a timestamp representing the issuance time of the request. The connecting node shall repeat this process until it has established connections to enough neighbors or it finds closer peers. Those neighbors make up its list of chosen neighbors. This entire process is also illustrated in the following pseudocode: Inputs: k: desired amount of neighbors; c: current list of chosen neighbors; p: list of potential peers; localID: local nodeID pubSalt: local public salt; pSorted = SortByScoreAsc ( P , localID , pubSalt ) FOR p IN pSorted peeringRequest = SendPeeringRequest ( p ) IF peeringRequest . accepted Append ( c , p ) IF Len ( c ) == Ceil ( k / 2 ) RETURN More specifically, after sending a peering request a node shall : * wait to get a Peering Response that could be positive or negative. * If positive, add the peer to its chosen neighbor list * If negative, filter out the peer from future requests until the next salt update or the end of the list of potential neighbors is reached. * If after responseTimeout no response is received, try again for a fixed maxPeeringAttempts . If not successful, filter out the peer from future requests until the next salt update or the end of the list of potential neighbors is reached. Similar to the previous case, in order to accept neighbors, every node with ID ownID shall generate a private salt privSalt . Upon reception of a Peering Request , a peer shall make a decision to accept, reject or discard the request by: * verifying that the signature of the Peering Request is valid and discard the request otherwise; * checking that the timestamp field is valid (i.e., not older than a given threshold requestExpirationTime specified by the node) and discard the request otherwise; * checking that the mana of the requester peer is within the own Mana rank and send back a negative Peering Response otherwise; * checking that the requestor salt matches its hash chain by: * taking the difference between the timestamp of the peering request and the time the initial salt was set, and then dividing this number by saltUpdateInterval , rounding down; * hashing the requester public salt as many times as the number of salt changes; * finally, if the result does not match the initial salt, discard the peering request; * applying a statistical test to the request defined as s(remoteID, ownID, \u03b6_remote) < \u03b8 for a fixed threshold \u03b8, and discard it otherwise; * this test determines the effectiveness of the brute force attack when an attacker tries to establish a connection with a desired peer; * with \u03b8 set to 0.01 an attacker has only 1% of chance of being successful; * accept the peering request by sending back a positive Peering Response if either one of the following conditions is satisfied, and send back a negative Peering Response otherwise: * the current size of the accepted neighbors list is smaller than Floor(k/2) ; * the score defined as s(ownID, remoteID, privSalt) is lower than the current highest score among accepted neighbors. In this case, send a Peering Drop to drop the accepted neighbor with the highest score replaced by the requester peer. Neighbor Removal \u00b6 Neighbor removal can occur for several reasons: * A node is replacing a neighbor with a better (in terms of score function) one; * From the gossip layer, the connection with a neighbor is lost; * If some form of reputation or bad behavior is being monitored, a neighbor could be dropped in case of misbehavior. For example, a node could respond to the peering request but choose not to gossip received messages. Independently from the reason, when a peer drops a neighbor shall send a Peering Drop and remove the neighbor from its requested/accepted neighbor list. Upon reception of a Peering Drop , the peer shall remove the dropping neighbor from its requested/accepted neighbor list. Requests and responses \u00b6 Each peering request, response, drop shall be encapsulated into a data field of a generic Request and Response . Its type shall be specified in the type field and signed with the ed25519 private key of the sender's identity and contain the related public key to allow the receiver to verify the signature. All the received peering request, response, drop shall be verified and those with invalid signatures be discarded. Request and Response Layout \u00b6 Name Type Description type uint8 Defines the type of the request or response. data ByteArray Contains the payload of the request or response (e.g., a PeeringRequest). public_key ByteArray[32] The ed25519 public key of the peer's identity used to verify its signatures. signature ByteArray[32] The ed25519 signature of the `data` field, signed by using the private key of the peer's identity. Peering Request \u00b6 Name Type Description timestamp time The unix timestamp of the PeeringRequest. salt ByteArray[20] The public salt of the requester. Peering Response \u00b6 Name Type Description req_hash ByteArray[32] The blake2b digest of the corresponding received PeeringRequest. status bool The response (true or false) of the PeeringRequest. Peering Drop \u00b6 Name Type Description timestamp time The unix timestamp of the drop.","title":"3.4 Neighbor Selection"},{"location":"IOTA-NECTAR/3.4%20Neighbor%20Selection/#34-neighbor-selection","text":"","title":"3.4 Neighbor Selection"},{"location":"IOTA-NECTAR/3.4%20Neighbor%20Selection/#introduction","text":"This section defines the Neighbor Selection protocol, its logic and the different requests and responses exchanged between nodes. In order for the network to work efficiently and for the nodes to be kept up-to-date about the ledger state, nodes exchange information with each other. Each node establishes a communication channel with a small subset of nodes (i.e., neighbors) via a process called peering . Such a process must be resilient against eclipse attacks: if all of a node\u2019s neighbors are controlled by an attacker, then the attacker has complete control over the node\u2019s view of the Tangle. Moreover, to prevent or limitate sybil-based attacks, the neighbor selection protocol makes use of a scarce resource dubbed Consensus Mana: arbitrary nodes can be created, but it is difficult to produce high mana nodes. Throughout this section, the terms Node and Peer are used interchangeably to refer to a Node device. The term neighbors implies a mutual relationship between two nodes put in place as a direct connection established and used by the gossip layer.","title":"Introduction"},{"location":"IOTA-NECTAR/3.4%20Neighbor%20Selection/#dependencies","text":"The Neighbor Selection protocol depends on: Peer discovery: to get a list of the known and verified node peers. Consensus Mana: to make the neighbor selection based on cMana value. Whenever mana value term is used in this specification, it refers to the Active cMana value from the last finalized epoch.","title":"Dependencies"},{"location":"IOTA-NECTAR/3.4%20Neighbor%20Selection/#detailed-design","text":"The goal of the neighbor selection is to build a node's neighborhood (to be used by the gossip protocol) while preventing attackers from \u201ctricking\u201d other nodes into becoming neighbors. Neighbors are established when one node sends a peering request to another node, which in turn accepts or rejects the request with a peering response. To prevent attacks, the protocol makes the peering request verifiably random such that attackers cannot create nodes to which the target node will send requests. At its core, the neighbor selection protocol uses both a screening process called Consensus Mana rank and a score function that takes into account some randomness dubbed private salt and public salt . Half of the neighbors will be constituted from nodes that accepted the peering request, while half will be constituted of nodes that will request for the peering. The two distinct groups of neighbors are consequently called: + Chosen neighbors (outbound). The peers that the node proactively selected through the neighbor selection mechanism. + Accepted neighbors (inbound). The peers that sent the peering request to the node and were accepted as a neighbor.","title":"Detailed design"},{"location":"IOTA-NECTAR/3.4%20Neighbor%20Selection/#local-variables","text":"Local variables defined here are included to help in understanding the protocol described in this section. The node application shall handle those variables in some form. Name Type Description saltUpdateInterval duration The time interval at which nodes shall update their salts. responseTimeout duration The time that node waits for a response during one peering attempt. requestExpirationTime duration The time used for the request timestamp validation, if the timestamp is older than this threshold the request is dropped. maxPeeringAttempts integer The maximum number of peering requests retries sent to the selected node before the next salt update.","title":"Local variables"},{"location":"IOTA-NECTAR/3.4%20Neighbor%20Selection/#node-identities","text":"As for the peer discovery protocol, every node has a cryptographic identity, a key on the Ed25519 elliptic curve. The blake2b hash of the public key of the peer node serves as its identifier or node ID .","title":"Node identities"},{"location":"IOTA-NECTAR/3.4%20Neighbor%20Selection/#salt-generation","text":"Nodes shall have a public and private salt both defined as array bytes of size 20. Nodes shall update both their public and private salt at a common fixed time interval saltUpdateInterval (e.g. 3 hours). The public salt is used for outbound peering requests, while the private salt is used during inbound peering requests. The public salt must satisfy the following requirements: Future salts must be unguessable: mining node ids to reduce the request score shall be prohibitive. This offers protection for the requesting nodes. Salts must be chosen in a non-arbitrary way: if adversaries may choose their salt, they could manufacture malicious requests to any node. This section proposes to set the public salts using hash chains, while private salts can be randomly generated on the fly. The nodes shall create a hash chain \u03b6 = {\u03b6_0, \u03b6_1, ..., \u03b6_m} where next chain element is created by hashing the previous one: \u03b6_{i+1} = hash(\u03b6_i) . Then nodes shall make public the last element \u03b6_m of their hash chain as their initial salt. Every future salt is the next element of the hash chain. Under this proposal, property 1 above holds because cryptographic hash functions are virtually irreversible. Property 2 holds fairly well: an adversary can only choose one element of their hash chain. Indeed, an adversary can pick a number to be their 300 th salt, hash it 300 times, and post that as their initial salt. However, an adversary can only do this for one round since hash functions have effectively random outputs. Thus an adversary is limited in their ability to choose their own salt.","title":"Salt generation"},{"location":"IOTA-NECTAR/3.4%20Neighbor%20Selection/#mana-rank-interval","text":"Each peer discovered and verified via the Peer Discovery protocol shall have a consensus mana value associated with it. The peer running the Neighbor Selection protocol shall keep this information up-to-date and use it to update a data structure called manaRank containing the list of the nodes' identities for each mana value. The aim of this ranking is to select a subset of peers having similar mana to the node preparing the ranking. More specifically, let's define potentialNeighbors to be such a subset, that is divided into a lower and an upper set with respect to a targetMana value (i.e., the mana value of the node performing the ranking). By iterating over the manaRank , each node shall fill both the lower and upper sets with nodes' identities having a similar rank to itself, not less/greater than a given threshold rho respectively, except when each subset does not reach the minimal size r . The following pseudocode describes a reference implementation of this process: Inputs: manaRank: mapping between mana values and the list of nodes' identities with that mana; targetMana: the mana value of the node performing the ranking; rho: the ratio determining the length of the rank to consider; r: the minimum number of nodes' identities to return for both lower and upper sets; Largest(r, targetMana): the set of r largest cMana holders less than targetMana; Smallest(r, targetMana): the set of r smallest cMana holders greater than targetMana; Outputs: potentialNeighbors: the set of nodes' identities to consider for neighbor selection; FOR mana IN manaRank nodeID = manaRank [ mana ] IF mana > targetMana IF mana / targetMana < rho Append ( upperSet , nodeID ) ELSE IF mana == 0 || mana == targetMana BREAK ELSE IF targetMana / mana < rho Append ( lowerSet , nodeID ) IF Len ( lowerSet ) < r // set lowerSet with the r largest mana holders less than targetMana lowerSet = Largest ( r , targetMana ) IF Len ( upperSet ) < r // set upperSet with the r smallest mana holders greater than targetMana upperSet = Smallest ( r , targetMana ) potentialNeighbors = Append ( upperSet , lowerSet ) RETURN potentialNeighbors","title":"Mana rank interval"},{"location":"IOTA-NECTAR/3.4%20Neighbor%20Selection/#selection","text":"The maximum number of neighbors is a parameter of the gossip protocol. This section proposes to use a size of 8 equally divided into 4 chosen (outbound) and 4 accepted (inbound) neighbors. It is crucial to decide on a fixed number of neighbors, as the constant number decreases an eclipse probability exponentially. The chosen k is a compromise between having more connections resulting in lower performance and increased protection from an eclipse attack. The operations involved during neighbor selection are listed in the following: Get an up-to-date list of verified and known peers from the Peer Discovery protocol. Use mana rank to filter the previous list to obtain a list of peers to be potential neighbors. Use the score function to request/accept neighbors. The score between two nodes is measured through the score function s , defined by: s(nodeID1, nodeID2, salt) = hash(nodeID1 || nodeID2 || salt), where: nodeID1 and nodeID2 are the identities of the considered nodes. salt is the salt value that can be private or public depending on the peering direction (inbound/outbound). hash is the blake2b hash function. || is the concatanation operation. Note that the value used as the score is an unsigned integer derived from the first 4 bytes of the byte array after the hash function. In order to connect to new neighbors, each node with ID ownID and public salt pubSalt keeps a list of potential neighbors derived via Mana rank that is sorted by their score d(ownID, \u00b7, pubSalt) . Then, the node shall send peering requests in ascending order , containing its own current public salt and a timestamp representing the issuance time of the request. The connecting node shall repeat this process until it has established connections to enough neighbors or it finds closer peers. Those neighbors make up its list of chosen neighbors. This entire process is also illustrated in the following pseudocode: Inputs: k: desired amount of neighbors; c: current list of chosen neighbors; p: list of potential peers; localID: local nodeID pubSalt: local public salt; pSorted = SortByScoreAsc ( P , localID , pubSalt ) FOR p IN pSorted peeringRequest = SendPeeringRequest ( p ) IF peeringRequest . accepted Append ( c , p ) IF Len ( c ) == Ceil ( k / 2 ) RETURN More specifically, after sending a peering request a node shall : * wait to get a Peering Response that could be positive or negative. * If positive, add the peer to its chosen neighbor list * If negative, filter out the peer from future requests until the next salt update or the end of the list of potential neighbors is reached. * If after responseTimeout no response is received, try again for a fixed maxPeeringAttempts . If not successful, filter out the peer from future requests until the next salt update or the end of the list of potential neighbors is reached. Similar to the previous case, in order to accept neighbors, every node with ID ownID shall generate a private salt privSalt . Upon reception of a Peering Request , a peer shall make a decision to accept, reject or discard the request by: * verifying that the signature of the Peering Request is valid and discard the request otherwise; * checking that the timestamp field is valid (i.e., not older than a given threshold requestExpirationTime specified by the node) and discard the request otherwise; * checking that the mana of the requester peer is within the own Mana rank and send back a negative Peering Response otherwise; * checking that the requestor salt matches its hash chain by: * taking the difference between the timestamp of the peering request and the time the initial salt was set, and then dividing this number by saltUpdateInterval , rounding down; * hashing the requester public salt as many times as the number of salt changes; * finally, if the result does not match the initial salt, discard the peering request; * applying a statistical test to the request defined as s(remoteID, ownID, \u03b6_remote) < \u03b8 for a fixed threshold \u03b8, and discard it otherwise; * this test determines the effectiveness of the brute force attack when an attacker tries to establish a connection with a desired peer; * with \u03b8 set to 0.01 an attacker has only 1% of chance of being successful; * accept the peering request by sending back a positive Peering Response if either one of the following conditions is satisfied, and send back a negative Peering Response otherwise: * the current size of the accepted neighbors list is smaller than Floor(k/2) ; * the score defined as s(ownID, remoteID, privSalt) is lower than the current highest score among accepted neighbors. In this case, send a Peering Drop to drop the accepted neighbor with the highest score replaced by the requester peer.","title":"Selection"},{"location":"IOTA-NECTAR/3.4%20Neighbor%20Selection/#neighbor-removal","text":"Neighbor removal can occur for several reasons: * A node is replacing a neighbor with a better (in terms of score function) one; * From the gossip layer, the connection with a neighbor is lost; * If some form of reputation or bad behavior is being monitored, a neighbor could be dropped in case of misbehavior. For example, a node could respond to the peering request but choose not to gossip received messages. Independently from the reason, when a peer drops a neighbor shall send a Peering Drop and remove the neighbor from its requested/accepted neighbor list. Upon reception of a Peering Drop , the peer shall remove the dropping neighbor from its requested/accepted neighbor list.","title":"Neighbor Removal"},{"location":"IOTA-NECTAR/3.4%20Neighbor%20Selection/#requests-and-responses","text":"Each peering request, response, drop shall be encapsulated into a data field of a generic Request and Response . Its type shall be specified in the type field and signed with the ed25519 private key of the sender's identity and contain the related public key to allow the receiver to verify the signature. All the received peering request, response, drop shall be verified and those with invalid signatures be discarded.","title":"Requests and responses"},{"location":"IOTA-NECTAR/3.4%20Neighbor%20Selection/#request-and-response-layout","text":"Name Type Description type uint8 Defines the type of the request or response. data ByteArray Contains the payload of the request or response (e.g., a PeeringRequest). public_key ByteArray[32] The ed25519 public key of the peer's identity used to verify its signatures. signature ByteArray[32] The ed25519 signature of the `data` field, signed by using the private key of the peer's identity.","title":"Request and Response Layout"},{"location":"IOTA-NECTAR/3.4%20Neighbor%20Selection/#peering-request","text":"Name Type Description timestamp time The unix timestamp of the PeeringRequest. salt ByteArray[20] The public salt of the requester.","title":"Peering Request"},{"location":"IOTA-NECTAR/3.4%20Neighbor%20Selection/#peering-response","text":"Name Type Description req_hash ByteArray[32] The blake2b digest of the corresponding received PeeringRequest. status bool The response (true or false) of the PeeringRequest.","title":"Peering Response"},{"location":"IOTA-NECTAR/3.4%20Neighbor%20Selection/#peering-drop","text":"Name Type Description timestamp time The unix timestamp of the drop.","title":"Peering Drop"},{"location":"IOTA-NECTAR/4.1%20The%20Tangle/","text":"4.1 The Tangle \u00b6 This specification describes the data structure used in the IOTA protocol, and introduces its main terminology. 4.1.1 Description \u00b6 The Tangle represents a growing partially-ordered set of messages, linked with each other through cryptographic primitives, and replicated to all nodes in the peer-to-peer network. The Tangle enables the possibility to store data and to keep a ledger, the latter being based on UTXO-DAG formed by transactions contained in messages. In mathematical terms, the Tangle is a Directed Acyclic (multi)Graph with messages as vertices and directed edges as references to existing messages. Directed edges are labelled: \\(0\\) represents direct references flagged as weak , and \\(1\\) represents direct references flagged as strong (see Section approval switch ). Messages are linked with each other through cryptographic hashes. The acyclicity condition means that there is no directed cycle composed of weak or strong edges. 4.1.2 Definitions \u00b6 In this section we provide some useful terminology which is useful to understand the basic elements of the protocol. 4.1.2.1 Approval switch \u00b6 Here we present the set of rules, called approval switch , which allow nodes to alternatively approve single messages or the entire past cone of a message. Parent : The protocol requires that each message contains a field parents in order to guarantee cryptographic references among messages in the Tangle. These references can be of two types, strong and weak , and are defined by the field parents type . Intuitively, we say that \\(y\\) is a strong (resp. weak ) parent of a message \\(x\\) if \\(x\\) has a directed strong (resp. weak) edge to \\(y\\) . Each message has a possible number of parents from 2 to 8 with repetitions (with 2 as a default value), where at least one is a strong parent. More information about parents can be found in Section 2.2 - Message layout . Approvers : A message \\(x\\) directly approves \\(y\\) if \\(y\\) is a parent of \\(x\\) . Moreover, \\(x\\) is a strong (resp. weak ) approver of \\(y\\) if \\(y\\) is a strong (resp. weak) parent of \\(x\\) . More generally, we say that a message \\(x\\) strongly approves \\(y\\) if there is a directed path of strong approvals from \\(x\\) to \\(y\\) , and \\(x\\) weakly approves \\(y\\) if there is a directed path of approvals of any type from \\(x\\) to \\(y\\) . Past cone : We say that the (strong) past cone of \\(x\\) is the set of all messages strongly approved by \\(x\\) , and the weak past cone of \\(x\\) is the set of all messages weakly or strongly approved by \\(x\\) . Future cone : We define the future cone of a message \\(x\\) as the set of messages that weakly or strongly approve \\(x\\) . Please note that, unlike its past cone, the future cone of a message changes over time. Genesis : The genesis is the message that creates the entire token supply. Note that this implies that no other tokens will ever be created or, equivalently, no mining occurs. This message has no outgoing edges and is in the weak past cone of every other message. In short, strong approvals are equivalent to the approvals in the legacy IOTA: if \\(x\\) strongly approves \\(y\\) , it approves also \\(y\\) 's past cone. Moreover, weak approvals emulate the White Flag approach from Chrysalis: approving a message does not necessarily approve its past cone. This feature allows, for instance, two conflicting messages to be part of the Tangle without creating unmergeable branches. 4.1.2.2 Validity \u00b6 This subsection introduces the definitions of validity for transactions and messages. * (Transaction) Validity : A transaction is valid if it passes the syntactical filter and its references are valid (see Section 2.3 - Payloads Layout for information): * It is syntactically correct. * Unblock conditions are met (see Section 5.1 - UTXO for further information). * Balances are zero, i.e., the sum of the inputs in the transaction's payload is equal to the sum of the outputs spent. * No conflicts in the past cone on the UTXO DAG (two transactions conflict if they consume the same UTXO output). (Message) Individual Validity : A message is considered individually valid if it passes all the objective filters, i.e. the ones included in the Message Parser (see Section 2.4 - Data Flow ): It is syntactically correct. Its signature is valid. Its Proof of Work is correct. (Message) Weak Validity : A message is weakly valid if: Its Individually Valid. Its parents are weakly valid. Its transaction is valid. It passes the Parent Age Check. (Message) Strong Validity : A message is strongly valid if: It is weakly valid. Its strong parents do not have a conflicting past. Its strong parents are strongly valid. 4.1.2.3 Branches \u00b6 In the IOTA protocol, multiple version of the ledger state can temporarily coexist. These multiple versions of the ledger state are called branches . As soon as conflicts are detected, new branches are generated where the outputs created by conflicting transactions and those created by transactions that spend these outputs are tracked. If all past conflicts are resolved and no new conflicts are detected, then only one branch will exist. More rigorously, we can refer to a branch as a non-conflicting collection of past cones of outputs in the UTXO DAG. Additional information, as well as the distinction between conflict and aggregated branches, is given in Section 5.2 - Ledger state . 4.1.2.2 Solidification \u00b6 Due to the asynchronicity of the network, we may receive messages for which their past cone has missing elements. We refer to these messages as unsolid messages. It is not possible neither to approve nor to gossip unsolid messages. The actions required to obtain such missing messages is called solidification procedure , and are described in detail in Section 4.4 - Solidification . 4.1.3 Example \u00b6 In the figure below it is shown an example of the Tangle (strong edges are with a continuous line, weak edges are with a dotted line). Message \\(D\\) contains a transaction that has been rejected. Thus, in the legacy IOTA implementation, its future cone would be orphaned due to the monotonicity rule. In particular, both messages \\(E\\) (data) and \\(F\\) (transaction) directly reference \\(D\\) . In IOTA 2.0, the introduction of the approval switch allows that these messages can be picked up via a weak approval, as messages \\(G\\) and \\(H\\) exemplify.","title":"4.1 The Tangle"},{"location":"IOTA-NECTAR/4.1%20The%20Tangle/#41-the-tangle","text":"This specification describes the data structure used in the IOTA protocol, and introduces its main terminology.","title":"4.1 The Tangle"},{"location":"IOTA-NECTAR/4.1%20The%20Tangle/#411-description","text":"The Tangle represents a growing partially-ordered set of messages, linked with each other through cryptographic primitives, and replicated to all nodes in the peer-to-peer network. The Tangle enables the possibility to store data and to keep a ledger, the latter being based on UTXO-DAG formed by transactions contained in messages. In mathematical terms, the Tangle is a Directed Acyclic (multi)Graph with messages as vertices and directed edges as references to existing messages. Directed edges are labelled: \\(0\\) represents direct references flagged as weak , and \\(1\\) represents direct references flagged as strong (see Section approval switch ). Messages are linked with each other through cryptographic hashes. The acyclicity condition means that there is no directed cycle composed of weak or strong edges.","title":"4.1.1 Description"},{"location":"IOTA-NECTAR/4.1%20The%20Tangle/#412-definitions","text":"In this section we provide some useful terminology which is useful to understand the basic elements of the protocol.","title":"4.1.2 Definitions"},{"location":"IOTA-NECTAR/4.1%20The%20Tangle/#4121-approval-switch","text":"Here we present the set of rules, called approval switch , which allow nodes to alternatively approve single messages or the entire past cone of a message. Parent : The protocol requires that each message contains a field parents in order to guarantee cryptographic references among messages in the Tangle. These references can be of two types, strong and weak , and are defined by the field parents type . Intuitively, we say that \\(y\\) is a strong (resp. weak ) parent of a message \\(x\\) if \\(x\\) has a directed strong (resp. weak) edge to \\(y\\) . Each message has a possible number of parents from 2 to 8 with repetitions (with 2 as a default value), where at least one is a strong parent. More information about parents can be found in Section 2.2 - Message layout . Approvers : A message \\(x\\) directly approves \\(y\\) if \\(y\\) is a parent of \\(x\\) . Moreover, \\(x\\) is a strong (resp. weak ) approver of \\(y\\) if \\(y\\) is a strong (resp. weak) parent of \\(x\\) . More generally, we say that a message \\(x\\) strongly approves \\(y\\) if there is a directed path of strong approvals from \\(x\\) to \\(y\\) , and \\(x\\) weakly approves \\(y\\) if there is a directed path of approvals of any type from \\(x\\) to \\(y\\) . Past cone : We say that the (strong) past cone of \\(x\\) is the set of all messages strongly approved by \\(x\\) , and the weak past cone of \\(x\\) is the set of all messages weakly or strongly approved by \\(x\\) . Future cone : We define the future cone of a message \\(x\\) as the set of messages that weakly or strongly approve \\(x\\) . Please note that, unlike its past cone, the future cone of a message changes over time. Genesis : The genesis is the message that creates the entire token supply. Note that this implies that no other tokens will ever be created or, equivalently, no mining occurs. This message has no outgoing edges and is in the weak past cone of every other message. In short, strong approvals are equivalent to the approvals in the legacy IOTA: if \\(x\\) strongly approves \\(y\\) , it approves also \\(y\\) 's past cone. Moreover, weak approvals emulate the White Flag approach from Chrysalis: approving a message does not necessarily approve its past cone. This feature allows, for instance, two conflicting messages to be part of the Tangle without creating unmergeable branches.","title":"4.1.2.1 Approval switch"},{"location":"IOTA-NECTAR/4.1%20The%20Tangle/#4122-validity","text":"This subsection introduces the definitions of validity for transactions and messages. * (Transaction) Validity : A transaction is valid if it passes the syntactical filter and its references are valid (see Section 2.3 - Payloads Layout for information): * It is syntactically correct. * Unblock conditions are met (see Section 5.1 - UTXO for further information). * Balances are zero, i.e., the sum of the inputs in the transaction's payload is equal to the sum of the outputs spent. * No conflicts in the past cone on the UTXO DAG (two transactions conflict if they consume the same UTXO output). (Message) Individual Validity : A message is considered individually valid if it passes all the objective filters, i.e. the ones included in the Message Parser (see Section 2.4 - Data Flow ): It is syntactically correct. Its signature is valid. Its Proof of Work is correct. (Message) Weak Validity : A message is weakly valid if: Its Individually Valid. Its parents are weakly valid. Its transaction is valid. It passes the Parent Age Check. (Message) Strong Validity : A message is strongly valid if: It is weakly valid. Its strong parents do not have a conflicting past. Its strong parents are strongly valid.","title":"4.1.2.2 Validity"},{"location":"IOTA-NECTAR/4.1%20The%20Tangle/#4123-branches","text":"In the IOTA protocol, multiple version of the ledger state can temporarily coexist. These multiple versions of the ledger state are called branches . As soon as conflicts are detected, new branches are generated where the outputs created by conflicting transactions and those created by transactions that spend these outputs are tracked. If all past conflicts are resolved and no new conflicts are detected, then only one branch will exist. More rigorously, we can refer to a branch as a non-conflicting collection of past cones of outputs in the UTXO DAG. Additional information, as well as the distinction between conflict and aggregated branches, is given in Section 5.2 - Ledger state .","title":"4.1.2.3 Branches"},{"location":"IOTA-NECTAR/4.1%20The%20Tangle/#4122-solidification","text":"Due to the asynchronicity of the network, we may receive messages for which their past cone has missing elements. We refer to these messages as unsolid messages. It is not possible neither to approve nor to gossip unsolid messages. The actions required to obtain such missing messages is called solidification procedure , and are described in detail in Section 4.4 - Solidification .","title":"4.1.2.2 Solidification"},{"location":"IOTA-NECTAR/4.1%20The%20Tangle/#413-example","text":"In the figure below it is shown an example of the Tangle (strong edges are with a continuous line, weak edges are with a dotted line). Message \\(D\\) contains a transaction that has been rejected. Thus, in the legacy IOTA implementation, its future cone would be orphaned due to the monotonicity rule. In particular, both messages \\(E\\) (data) and \\(F\\) (transaction) directly reference \\(D\\) . In IOTA 2.0, the introduction of the approval switch allows that these messages can be picked up via a weak approval, as messages \\(G\\) and \\(H\\) exemplify.","title":"4.1.3 Example"},{"location":"IOTA-NECTAR/4.2%20Timestamps/","text":"4.2 Timestamps \u00b6 4.2.1 Motivation \u00b6 In order to enable snapshotting based on time constraints rather than special messages in the Tangle (e.g. checkpoints), nodes need to share the same perception of time. Specifically, they need to have consensus on the age of messages . This is one of the reasons that messages must contain a field timestamp which represents the creation time of the message and is signed by the issuing node. Having consensus on the creation time of messages enables not only total ordering but also new applications that require certain guarantees regarding time. Specifically, we use message timestamps to enforce timestamps in transactions, which may also be used in computing the Mana associated to a particular node ID. In this document, we propose a mechanism to achieve consensus on message timestamps by combining a synchronous and an asynchronous approach. While online nodes may leverage FPC to vote on timestamps, nodes that join the network at a later time use an approach based on the approval weight (described in Section 6.4 - Approval Weight and Finality ) to determine the validity of timestamps. This specification also outlines a tool called \"Epochs\", which groups messages into different objective periods. This tool may be used for the following purposes: - finality and approval weight: the activity of certain nodes within an epoch can be recorded, and then the approval weight (i.e. the number of nodes, weighted by consensus, which issued a message referencing a particular message) can then be measured as a percentage of \"active consensus mana\". - committee selection: a committee elected as the highest active consensus mana holders can be easily and objectively formed for the DRNG committee. 4.2.2 Preliminaries \u00b6 4.2.2.1 Requirements \u00b6 In DLTs, there are many ways to potentially introduce timestamps. Any useful timestamping scheme however must satisfy the following requirements. 1. Nodes must have consensus on the timestamp associated to each message. 2. For every time t , there is a t_1>t such that any new message issued with timestamp t and received by a node after t_1 (measured by its local clock) will be considered too far in the past and will be orphaned. 4.2.2.2 Dependencies \u00b6 Opinion Setting FPC: used to perform voting on timestamps. Approval weight: corrects opinions on timestamps when out of sync. 4.2.3.3 Modules dependent on timestamps \u00b6 Tip selection: only messages with correct timestamps will be eligible for tip selection. Active Consensus Mana in approval weight uses epochs. DRNG uses Epochs. The Congestion control orders messages by timestamps, and only processes messages whose timestamp is close to the current time. The rate control system uses timestamps to compute the correct PoWs. The snapshotting uses timestamps to determine which messages to prune from the tangle. 4.2.2.4 Parameters \u00b6 Name Type Description DLARGE duration Gratuitous network delay estimate~ 15 s W duration window ~1 minute. Require W>2DLARGE DELTA duration Maximal difference between a message timestamp and its parents' message timestamp. Require DELTA>W+DLARGE TW duration Maximal difference between message timestamp and transaction timestamp EPOCHLENGTH duration Length of each epoch = 1 hour SYNCH_THRESHOLD duration the max difference between CurrentTime and TangleTime in which we consider our node in sync TIMESTAMP_CUTOFF duration messages with timestamp older than this will be disliked with level 3 knowledge 4.2.2.5 Clock synchronization \u00b6 Nodes need to share a reasonably similar perception of time in order to effectively judge the accuracy of timestamps. Therefore, we propose that nodes synchronize their clock on startup and resynchronize periodically every 60min to counter drift of local clocks. Instead of changing a nodes' system clock, we introduce an offset parameter to adjust for differences between network time and local time of a node. Initially, the Network Time Protocol (NTP) ( Go implementation ) may be used to achieve this task. We gracefully shut down the node if: - initial synchronization of time fails - resynchronization fails for more than maxSyncAttempts times 4.2.3 General Timestamp rules \u00b6 Every message contains a timestamp, which is signed by the issuing node. Thus the timestamp itself is objective and immutable. Furthermore, transactions will also contain a timestamp, which will be also signed and thus immutable. We first discuss the rules regarding message timestamps. In order for a message to be eligible for tip selection, the timestamp of every message in its past cone (both weak and strong) must satisfy certain requirements. These requirements fall into two categories: objective and subjective. The objective criteria only depend on information written directly in the Tangle and are applied immediately upon solidification. Thus all nodes immediately have consensus on the objective criteria. In this section, we will discuss these objective criteria. The quality of the timestamp is a subjective criterion since it is based on the solidification time of the message. Thus, nodes must use a consensus algorithm, e.g. FPC, to decide which messages should be rejected based on subjective criteria. Specifically, nodes will use FPC to vote on whether or not a timestamp plus W is before the arrival time. Consensus matters are not discussed in this document: see sections 6.1 , 6.2 and 6.3 to discuss how FPC votes on timestamps. Lastly, for any time t , a node is sure that it has received all the messages with timestamp less than t which will be finalized when + CurrentTime >= t + TIMESTAMP_CUTOFF = t + W + 2*DLARGE , i.e. wait ~1.5 minutes + SyncStatus = TRUE Indeed, after TIMESTAMP_CUTOFF = W + 2*DLARGE all messages which arrive will be considered bad with level of knowledge 3: see Section 6.1 - Object of Consensus . If the node is in sync, then it will have received all old messages which will be confirmed. 4.2.3.1 Age of parents \u00b6 It is problematic when incoming messages reference extremely old messages. If any new message may reference any message in the Tangle, then a node will need to keep all messages readily available, precluding snapshotting. For this reason, we require that the difference between the timestamp of a message and the timestamp of its parents must be at most DELTA units of time. Additionally, we require that timestamps are monotonic, i.e. parents must have a timestamp smaller than their children's timestamps. 4.2.3.2 Message timestamp vs transaction timestamp \u00b6 Transactions contain a timestamp that is signed by the user when creating the transaction. It is thus different from the timestamp in the message which is created and signed by the node. We require transaction.timestamp+TW >= message.timestamp >= transaction.timestamp where TW defines the maximum allowed difference between both timestamps. If a node receives a transaction from a user with an invalid timestamp it does not create a message but discards the transaction with a corresponding error message to the user. To prevent a user's local clock differences causing issues the node should offer an API endpoint to retrieve its SyncedTime according to the network time. 4.2.3.3 Reattachments \u00b6 Reattachments of a transaction are possible during the time window TW . Specifically, a transaction may be reattached in a new message as long as the condition message.timestamp-TW >= transaction.timestamp is fulfilled. If for some reason a transaction is not picked up (even after reattachment) and thus being orphaned, the user needs to create a new transaction with a current timestamp. 4.2.3.4 Age of UTXO \u00b6 Inputs to a transaction (unspent outputs) inherit their spent time from the transaction timestamp. Similarly, unspent outputs inherit their creation time from the transaction timestamp as well. For a transaction to be considered valid we require transaction.timestamp >= inputs.timestamp In other words, all inputs to a transaction need to have a smaller or equal timestamp than the transaction. In turn, all created unspent outputs will have a greater or equal timestamp than all inputs. 4.2.4 Consensus on timestamps \u00b6 The accuracy of the timestamps will be enforced through FPC voting. Specifically, FPC will allow nodes to come to consensus on whether or not timestamp+W is greater than the arrival time: see Section 6.2 - Opinion Setting . Messages which are deemed to fail this criterion will be rejected. Messages whose entire past cone is both valid, and satisfies this criterion, will be flagged as eligible and can be referenced messages selected by the Tip Selection Algorithm: see Section 4.3 - Tip Selection Algorithm . 4.2.4.1 Not in Sync \u00b6 Any node not in sync will receive messages much later than the rest of the network. Thus, all messages will appear to have inaccurate timestamps and will be wrongfully rejected by the algorithms in Section 6.2 - Opinion Setting . Thus nodes will not actively participate in any voting until their status is in sync, see Section 4.2.5. In general, a node that just completed the syncing phase must check, for each message, how much mana is in its future cone and set the opinion accordingly. More specifically: 1. Run the solidification up to being in sync (by following beacons) 2. Derive local markers 3. Decide eligibility for every message (5-10% mana min threshold) Clearly this synchronization procedure may only work to make an apparently bad timestamp reset to be a good timestamp. For example, if a node receives a message one day later than the rest of the network, the node will initially reject the timestamp. However, the resync mechanism will recognize the message is correct because it is buried under an entire day's worth of messages. What about the converse situation? Being out of sync will only delay the arrival of a message. If a node receives a message with a timestamp satisfying timestamp+W>arrivalTime , this condition would also be satisfied for all nodes which received the message earlier. Thus, if a node is out of sync and is receiving messages later than everyone else, if this node likes a timestamp, all other notes will have already liked it. Therefore, nodes will not like timestamps which were previously rejected by most of the network. 4.2.4.2 Future Timestamps \u00b6 Note that the resync mechanism only works because we only dislike a message if it is too old. If we disliked messages whose timestamps were in the future, then it is possible that some nodes would like it, and others disliked it. Suppose for example at 11:00:00 a node issues a message X with timestamp 12:00:00, and that then all nodes rejected this timestamp for being too far in the future. Now suppose at 12:00:00 a new node N joins the network at receives X . According to node N , the timestamp of X is accurate, and will accept it, while other nodes will reject it. The resynchronization mechanism fails in this case. To protect against messages with a timestamp that is issued in the future, the congestion control algorithm does not schedule the message until the timestamp is less than or equal to CurrentTime . Thus messages from the future will not be added to the Tangle until the appropriate time. If an attacker sends too many future messages, these messages may overload the scheduler's queues. However, this is a standard type of attack that the congestion control algorithm is prepared to handle. 4.2.5 Tangle Time \u00b6 4.2.5.1 Motivation \u00b6 For a variety of reasons, a node needs to be able to determine if it is in sync with the rest of the network, including the following: + to signal to clients that its perception is healthy, + to know when to issue messages (nodes out of sync should not issue messages, lest they are added to the wrong part of the Tangle), + to schedule messages at the correct rate: out of sync nodes should schedule faster in order to catch up with the network, + and to optimize FPC: nodes should not query while syncing, but instead rely on the approval weight. 4.2.5.2 Tangle Time \u00b6 Every DLT is a clock, or more specifically a network of synchronized clocks. This clock has a natural correspondence with \"real time\". If the DLT clock differs significantly from local time, then the we can conclude that our DLT clock is off from all the other clocks, and thus the node is out of sync. For IOTA 2.0, we make precise the meaning of the DLT clock with what we dub \"Tangle time\". FUNCTION Time = TangleTime RETURN largest timestamp of all grade 3 final messages ``` Thus Tangle time is the last timestamp in a message which was been confirmed . Tangle time cannot be attacked without controlling enough mana to accept incorrect timestamps , making it a reliable , attack - resistant quantity . Typically speaking , ` CurrentTime - TangleTime ` is , on average , the approximate confirmation time of messages . Thus , if this difference is too far off , then we can conclude that we do not know which messages are confirmed and thus we are out of sync . In this spirit , we are able to define the following two functions . ``` vbnet FUNCTION Time = SyncAmount RETURN CurrentTime - TangleTime FUNCTION bool = SyncStatus IF SyncAmount <= SYNCH_THRESHOLD RETURN TRUE ELSE RETURN FALSE 4.2.6 Epochs \u00b6 Epochs are universal time intervals that group messages in the Tangle based on their timestamps. - An epoch is identified by its unique epoch index. Epoch indices are strictly increasing with respect to time. - Every time interval EPOCHLENGTH , a new epoch is started and the previous ends. - A message M or a transaction belongs to an Epoch X , if its timestamp falls into the time window of Epoch X such that T( M )\u2208 [t X-1 , t X ), where - T( M ) is the timestamp of message M , - t x-1 is the end of the previous epoch, - and t x is the end of Epoch X . - A transaction might not be in the same epoch as the message containing it. - The start of the network corresponds to t 1 , that is the end of Epoch 1 . - Epoch 0 and Epoch 1 are special epochs, since they only contain the genesis message(s), and their content is defined before starting the network. These two epochs might be used to initialize the network and active consensus mana states to a desired values. - For every network, the end of Epoch 0 is defined as an arbitrary point in time, similarly to how Unix epoch time is defined as 00:00:00 UTC on 1 January 1970. - Epoch interval EPOCHLENGTH cannot be chosen arbitrarily: it must be much larger than DELTA . Furthermore, short epochs can potentially cause make certain calculations involving the approval wait more complicated. Figure 1 gives a brief overview of how the Tangle is divided into epochs: Epoch 0 contains the genesis message(s), that hold the genesis output(s). By allowing multiple outputs to exist before the start of the network, a desired initial state for the network can be set. Epoch 2 is the first epoch after the start of the network, when nodes may start issuing messages. Note, that a message can be valid with one strong parent only. Upon processing a message and verifying its timestamp as described in Opinion Setting Specification , the message is solidified and can be added to the epoch. Epoch 2 ends at t 2 , but it can happen that a message is issued just before t 2 , therefore it reaches most nodes and gets solidified during Epoch 3 . In this case, the node can still determine the correct epoch the message belongs to due to the consensus on the message timestamp. This also means, that finalizing an epoch (declaring that no more messages can be added to it) is delayed after the end of the epoch by at least W time. 4.2.6 Limitations \u00b6 When not in sync, a different behavior is required which complicates the protocol. Using NTP as clock synchronization mechanism as proposed is a single point of failure. It can only be considered as an initial implementation into GoShimmer and needs to be replaced by a decentralized alternative.","title":"4.2 Timestamps"},{"location":"IOTA-NECTAR/4.2%20Timestamps/#42-timestamps","text":"","title":"4.2 Timestamps"},{"location":"IOTA-NECTAR/4.2%20Timestamps/#421-motivation","text":"In order to enable snapshotting based on time constraints rather than special messages in the Tangle (e.g. checkpoints), nodes need to share the same perception of time. Specifically, they need to have consensus on the age of messages . This is one of the reasons that messages must contain a field timestamp which represents the creation time of the message and is signed by the issuing node. Having consensus on the creation time of messages enables not only total ordering but also new applications that require certain guarantees regarding time. Specifically, we use message timestamps to enforce timestamps in transactions, which may also be used in computing the Mana associated to a particular node ID. In this document, we propose a mechanism to achieve consensus on message timestamps by combining a synchronous and an asynchronous approach. While online nodes may leverage FPC to vote on timestamps, nodes that join the network at a later time use an approach based on the approval weight (described in Section 6.4 - Approval Weight and Finality ) to determine the validity of timestamps. This specification also outlines a tool called \"Epochs\", which groups messages into different objective periods. This tool may be used for the following purposes: - finality and approval weight: the activity of certain nodes within an epoch can be recorded, and then the approval weight (i.e. the number of nodes, weighted by consensus, which issued a message referencing a particular message) can then be measured as a percentage of \"active consensus mana\". - committee selection: a committee elected as the highest active consensus mana holders can be easily and objectively formed for the DRNG committee.","title":"4.2.1 Motivation"},{"location":"IOTA-NECTAR/4.2%20Timestamps/#422-preliminaries","text":"","title":"4.2.2 Preliminaries"},{"location":"IOTA-NECTAR/4.2%20Timestamps/#4221-requirements","text":"In DLTs, there are many ways to potentially introduce timestamps. Any useful timestamping scheme however must satisfy the following requirements. 1. Nodes must have consensus on the timestamp associated to each message. 2. For every time t , there is a t_1>t such that any new message issued with timestamp t and received by a node after t_1 (measured by its local clock) will be considered too far in the past and will be orphaned.","title":"4.2.2.1 Requirements"},{"location":"IOTA-NECTAR/4.2%20Timestamps/#4222-dependencies","text":"Opinion Setting FPC: used to perform voting on timestamps. Approval weight: corrects opinions on timestamps when out of sync.","title":"4.2.2.2 Dependencies"},{"location":"IOTA-NECTAR/4.2%20Timestamps/#4233-modules-dependent-on-timestamps","text":"Tip selection: only messages with correct timestamps will be eligible for tip selection. Active Consensus Mana in approval weight uses epochs. DRNG uses Epochs. The Congestion control orders messages by timestamps, and only processes messages whose timestamp is close to the current time. The rate control system uses timestamps to compute the correct PoWs. The snapshotting uses timestamps to determine which messages to prune from the tangle.","title":"4.2.3.3 Modules dependent on timestamps"},{"location":"IOTA-NECTAR/4.2%20Timestamps/#4224-parameters","text":"Name Type Description DLARGE duration Gratuitous network delay estimate~ 15 s W duration window ~1 minute. Require W>2DLARGE DELTA duration Maximal difference between a message timestamp and its parents' message timestamp. Require DELTA>W+DLARGE TW duration Maximal difference between message timestamp and transaction timestamp EPOCHLENGTH duration Length of each epoch = 1 hour SYNCH_THRESHOLD duration the max difference between CurrentTime and TangleTime in which we consider our node in sync TIMESTAMP_CUTOFF duration messages with timestamp older than this will be disliked with level 3 knowledge","title":"4.2.2.4 Parameters"},{"location":"IOTA-NECTAR/4.2%20Timestamps/#4225-clock-synchronization","text":"Nodes need to share a reasonably similar perception of time in order to effectively judge the accuracy of timestamps. Therefore, we propose that nodes synchronize their clock on startup and resynchronize periodically every 60min to counter drift of local clocks. Instead of changing a nodes' system clock, we introduce an offset parameter to adjust for differences between network time and local time of a node. Initially, the Network Time Protocol (NTP) ( Go implementation ) may be used to achieve this task. We gracefully shut down the node if: - initial synchronization of time fails - resynchronization fails for more than maxSyncAttempts times","title":"4.2.2.5 Clock synchronization"},{"location":"IOTA-NECTAR/4.2%20Timestamps/#423-general-timestamp-rules","text":"Every message contains a timestamp, which is signed by the issuing node. Thus the timestamp itself is objective and immutable. Furthermore, transactions will also contain a timestamp, which will be also signed and thus immutable. We first discuss the rules regarding message timestamps. In order for a message to be eligible for tip selection, the timestamp of every message in its past cone (both weak and strong) must satisfy certain requirements. These requirements fall into two categories: objective and subjective. The objective criteria only depend on information written directly in the Tangle and are applied immediately upon solidification. Thus all nodes immediately have consensus on the objective criteria. In this section, we will discuss these objective criteria. The quality of the timestamp is a subjective criterion since it is based on the solidification time of the message. Thus, nodes must use a consensus algorithm, e.g. FPC, to decide which messages should be rejected based on subjective criteria. Specifically, nodes will use FPC to vote on whether or not a timestamp plus W is before the arrival time. Consensus matters are not discussed in this document: see sections 6.1 , 6.2 and 6.3 to discuss how FPC votes on timestamps. Lastly, for any time t , a node is sure that it has received all the messages with timestamp less than t which will be finalized when + CurrentTime >= t + TIMESTAMP_CUTOFF = t + W + 2*DLARGE , i.e. wait ~1.5 minutes + SyncStatus = TRUE Indeed, after TIMESTAMP_CUTOFF = W + 2*DLARGE all messages which arrive will be considered bad with level of knowledge 3: see Section 6.1 - Object of Consensus . If the node is in sync, then it will have received all old messages which will be confirmed.","title":"4.2.3 General Timestamp rules"},{"location":"IOTA-NECTAR/4.2%20Timestamps/#4231-age-of-parents","text":"It is problematic when incoming messages reference extremely old messages. If any new message may reference any message in the Tangle, then a node will need to keep all messages readily available, precluding snapshotting. For this reason, we require that the difference between the timestamp of a message and the timestamp of its parents must be at most DELTA units of time. Additionally, we require that timestamps are monotonic, i.e. parents must have a timestamp smaller than their children's timestamps.","title":"4.2.3.1 Age of parents"},{"location":"IOTA-NECTAR/4.2%20Timestamps/#4232-message-timestamp-vs-transaction-timestamp","text":"Transactions contain a timestamp that is signed by the user when creating the transaction. It is thus different from the timestamp in the message which is created and signed by the node. We require transaction.timestamp+TW >= message.timestamp >= transaction.timestamp where TW defines the maximum allowed difference between both timestamps. If a node receives a transaction from a user with an invalid timestamp it does not create a message but discards the transaction with a corresponding error message to the user. To prevent a user's local clock differences causing issues the node should offer an API endpoint to retrieve its SyncedTime according to the network time.","title":"4.2.3.2 Message timestamp vs transaction timestamp"},{"location":"IOTA-NECTAR/4.2%20Timestamps/#4233-reattachments","text":"Reattachments of a transaction are possible during the time window TW . Specifically, a transaction may be reattached in a new message as long as the condition message.timestamp-TW >= transaction.timestamp is fulfilled. If for some reason a transaction is not picked up (even after reattachment) and thus being orphaned, the user needs to create a new transaction with a current timestamp.","title":"4.2.3.3 Reattachments"},{"location":"IOTA-NECTAR/4.2%20Timestamps/#4234-age-of-utxo","text":"Inputs to a transaction (unspent outputs) inherit their spent time from the transaction timestamp. Similarly, unspent outputs inherit their creation time from the transaction timestamp as well. For a transaction to be considered valid we require transaction.timestamp >= inputs.timestamp In other words, all inputs to a transaction need to have a smaller or equal timestamp than the transaction. In turn, all created unspent outputs will have a greater or equal timestamp than all inputs.","title":"4.2.3.4 Age of UTXO"},{"location":"IOTA-NECTAR/4.2%20Timestamps/#424-consensus-on-timestamps","text":"The accuracy of the timestamps will be enforced through FPC voting. Specifically, FPC will allow nodes to come to consensus on whether or not timestamp+W is greater than the arrival time: see Section 6.2 - Opinion Setting . Messages which are deemed to fail this criterion will be rejected. Messages whose entire past cone is both valid, and satisfies this criterion, will be flagged as eligible and can be referenced messages selected by the Tip Selection Algorithm: see Section 4.3 - Tip Selection Algorithm .","title":"4.2.4 Consensus on timestamps"},{"location":"IOTA-NECTAR/4.2%20Timestamps/#4241-not-in-sync","text":"Any node not in sync will receive messages much later than the rest of the network. Thus, all messages will appear to have inaccurate timestamps and will be wrongfully rejected by the algorithms in Section 6.2 - Opinion Setting . Thus nodes will not actively participate in any voting until their status is in sync, see Section 4.2.5. In general, a node that just completed the syncing phase must check, for each message, how much mana is in its future cone and set the opinion accordingly. More specifically: 1. Run the solidification up to being in sync (by following beacons) 2. Derive local markers 3. Decide eligibility for every message (5-10% mana min threshold) Clearly this synchronization procedure may only work to make an apparently bad timestamp reset to be a good timestamp. For example, if a node receives a message one day later than the rest of the network, the node will initially reject the timestamp. However, the resync mechanism will recognize the message is correct because it is buried under an entire day's worth of messages. What about the converse situation? Being out of sync will only delay the arrival of a message. If a node receives a message with a timestamp satisfying timestamp+W>arrivalTime , this condition would also be satisfied for all nodes which received the message earlier. Thus, if a node is out of sync and is receiving messages later than everyone else, if this node likes a timestamp, all other notes will have already liked it. Therefore, nodes will not like timestamps which were previously rejected by most of the network.","title":"4.2.4.1 Not in Sync"},{"location":"IOTA-NECTAR/4.2%20Timestamps/#4242-future-timestamps","text":"Note that the resync mechanism only works because we only dislike a message if it is too old. If we disliked messages whose timestamps were in the future, then it is possible that some nodes would like it, and others disliked it. Suppose for example at 11:00:00 a node issues a message X with timestamp 12:00:00, and that then all nodes rejected this timestamp for being too far in the future. Now suppose at 12:00:00 a new node N joins the network at receives X . According to node N , the timestamp of X is accurate, and will accept it, while other nodes will reject it. The resynchronization mechanism fails in this case. To protect against messages with a timestamp that is issued in the future, the congestion control algorithm does not schedule the message until the timestamp is less than or equal to CurrentTime . Thus messages from the future will not be added to the Tangle until the appropriate time. If an attacker sends too many future messages, these messages may overload the scheduler's queues. However, this is a standard type of attack that the congestion control algorithm is prepared to handle.","title":"4.2.4.2 Future Timestamps"},{"location":"IOTA-NECTAR/4.2%20Timestamps/#425-tangle-time","text":"","title":"4.2.5 Tangle Time"},{"location":"IOTA-NECTAR/4.2%20Timestamps/#4251-motivation","text":"For a variety of reasons, a node needs to be able to determine if it is in sync with the rest of the network, including the following: + to signal to clients that its perception is healthy, + to know when to issue messages (nodes out of sync should not issue messages, lest they are added to the wrong part of the Tangle), + to schedule messages at the correct rate: out of sync nodes should schedule faster in order to catch up with the network, + and to optimize FPC: nodes should not query while syncing, but instead rely on the approval weight.","title":"4.2.5.1 Motivation"},{"location":"IOTA-NECTAR/4.2%20Timestamps/#4252-tangle-time","text":"Every DLT is a clock, or more specifically a network of synchronized clocks. This clock has a natural correspondence with \"real time\". If the DLT clock differs significantly from local time, then the we can conclude that our DLT clock is off from all the other clocks, and thus the node is out of sync. For IOTA 2.0, we make precise the meaning of the DLT clock with what we dub \"Tangle time\". FUNCTION Time = TangleTime RETURN largest timestamp of all grade 3 final messages ``` Thus Tangle time is the last timestamp in a message which was been confirmed . Tangle time cannot be attacked without controlling enough mana to accept incorrect timestamps , making it a reliable , attack - resistant quantity . Typically speaking , ` CurrentTime - TangleTime ` is , on average , the approximate confirmation time of messages . Thus , if this difference is too far off , then we can conclude that we do not know which messages are confirmed and thus we are out of sync . In this spirit , we are able to define the following two functions . ``` vbnet FUNCTION Time = SyncAmount RETURN CurrentTime - TangleTime FUNCTION bool = SyncStatus IF SyncAmount <= SYNCH_THRESHOLD RETURN TRUE ELSE RETURN FALSE","title":"4.2.5.2 Tangle Time"},{"location":"IOTA-NECTAR/4.2%20Timestamps/#426-epochs","text":"Epochs are universal time intervals that group messages in the Tangle based on their timestamps. - An epoch is identified by its unique epoch index. Epoch indices are strictly increasing with respect to time. - Every time interval EPOCHLENGTH , a new epoch is started and the previous ends. - A message M or a transaction belongs to an Epoch X , if its timestamp falls into the time window of Epoch X such that T( M )\u2208 [t X-1 , t X ), where - T( M ) is the timestamp of message M , - t x-1 is the end of the previous epoch, - and t x is the end of Epoch X . - A transaction might not be in the same epoch as the message containing it. - The start of the network corresponds to t 1 , that is the end of Epoch 1 . - Epoch 0 and Epoch 1 are special epochs, since they only contain the genesis message(s), and their content is defined before starting the network. These two epochs might be used to initialize the network and active consensus mana states to a desired values. - For every network, the end of Epoch 0 is defined as an arbitrary point in time, similarly to how Unix epoch time is defined as 00:00:00 UTC on 1 January 1970. - Epoch interval EPOCHLENGTH cannot be chosen arbitrarily: it must be much larger than DELTA . Furthermore, short epochs can potentially cause make certain calculations involving the approval wait more complicated. Figure 1 gives a brief overview of how the Tangle is divided into epochs: Epoch 0 contains the genesis message(s), that hold the genesis output(s). By allowing multiple outputs to exist before the start of the network, a desired initial state for the network can be set. Epoch 2 is the first epoch after the start of the network, when nodes may start issuing messages. Note, that a message can be valid with one strong parent only. Upon processing a message and verifying its timestamp as described in Opinion Setting Specification , the message is solidified and can be added to the epoch. Epoch 2 ends at t 2 , but it can happen that a message is issued just before t 2 , therefore it reaches most nodes and gets solidified during Epoch 3 . In this case, the node can still determine the correct epoch the message belongs to due to the consensus on the message timestamp. This also means, that finalizing an epoch (declaring that no more messages can be added to it) is delayed after the end of the epoch by at least W time.","title":"4.2.6 Epochs"},{"location":"IOTA-NECTAR/4.2%20Timestamps/#426-limitations","text":"When not in sync, a different behavior is required which complicates the protocol. Using NTP as clock synchronization mechanism as proposed is a single point of failure. It can only be considered as an initial implementation into GoShimmer and needs to be replaced by a decentralized alternative.","title":"4.2.6 Limitations"},{"location":"IOTA-NECTAR/4.3%20Tip%20Selection%20Algorithm/","text":"4.3 Tip Selection Algorithm \u00b6 4.3.1 Introduction \u00b6 The tip selection algorithm is the method by which messages are selected for approval by other issued messages joining the network. This approval mechanism represents \u201cbelief\u201d in the Tangle: If message \\(y\\) approves message \\(x\\) , this implies that the node issuing \\(y\\) believes that \\(x\\) , and possibly its past cone, are \"good\". The tip selection algorithm allows the Tangle to grow in a stable and secure way, with quick approval and finality times. We call the new Tip-Section algorithm \"R-URTS\", which means \"Restricted Uniform Random Tip Selection\". Here we summarize the main differences that the new Tip Selection Algorithm has, compared to the legacy version: Uniform Selection: Unlike the old Random Walk tip selection, we will use a much faster and simpler solution that will select uniformly among a subset of eligible tips. Approval Switch Mechanism: A new mechanism that will allow us to keep a clear Tangle while preventing orphanage from splits due to disliked branches. Although we will not be using here, the new message layout (more information in Section 2.2 - Message Layout ) has the capabilities for a message to have a non-fixed number of messages that it approves (parents), which range from two to eight. This can be used to develop tip spam protection mechanisms among other purposes. We will denote the number of parents being used in the algorithm by Parental Number . 4.3.2 Definitions \u00b6 One of the main improvements of the new Tip Selection Algorithm comes from its ability to keep both a clean non-conflicting subtangle, as well as to ignore the existence of conflicts in its selection, hence emulating the ability that Chrysalis White Flag approach has of being unsplittable. In IOTA 2.0, those properties come from the approval switch mechanism. In the rest of this subsection, we present the theory of the approval switch, which classify approvals and messages in \"weak\" and \"strong\". This information is necessary to define the tip pools , i.e., the sets of (recent) messages which are selectable by the Tip Selection Algorithm (we provide a more complete description of tip pools later in this document). 4.3.2.1 Approval switch \u00b6 In order to properly define and explain the approval switch mechanism, we will need some extra defintions. We also refer to the basic concept of branches ( Section 5.2 - Ledger State ) and validity ( Section 4.1 - The Tangle ), as they are required to the understanding of some of the definitions below. Tip : A message is considered a tip (by a node) if it is selectable by the Tip Selection Algorithm, i.e. it is an element of any Tip Pool (of that node). In general, it is perceived as a message that has yet to receive any direct approvers. Eligibility : A Message is said eligible if: It is weakly valid; It passes the timestamp check with level of knowledge at least 2; All its parents are also eligible messages. Approval switch : : A binary field with values strong and weak in the message associated with each of its parents, filled by its issuer node. Strong approval : Represents that the issuer node declares that the message and its entire past cone are liked. Weak approval : Represents that the issuer node declares that the message and its payload is liked, but its past cone is not completely liked. 4.3.2.2 Branch \u00b6 Furthermore, to properly define the tip pool, additional definitions derived by the branch are required. Here we give a summarized definition for the sake of understanding. Monotonically Liked Branch : A branch is monotonically liked if all of its transactions are individually liked. Monotonically Liked Message : A message is monotonically liked if its aggregated branch is monotonically liked. 4.3.2.3 Strong and weak messages \u00b6 In a heuristic way, one can think of a monotonically liked message as a message that has a liked payload and that all other payloads that depend on it are also liked. With this we can classify the messages: Strong Messages : We say a message \\(x\\) is strong (for a node) if it is: Eligible; Monotonically liked. Weak Messages : We say a message \\(x\\) is weak (for a node) it is: Eligible; Contains a liked payload; It is not monotonically liked with level of knowledge at least 2. Image X.X.X: An example of strong and weak parents. Observe that although B is in the past cone of I, it is not in its strong past cone. 4.3.3 Tip Pools \u00b6 The tip is a product of the construction of the Tip Pools, and in general it represents messages that are yet to be directly approved by other messages. The tip pools are built by filtering the messages that arrive from the neighbors, checking which ones are proper to be selectable by the algorithm. In this subsection we will define such filters and classifications that are used to make the Tip Pools. Differently from the legacy implementation, we will not have a single pool, but instead two, divided according to the new concept of the Approval Switch mechanism. 4.3.3.1 Construction of the Tip Pools \u00b6 We will define a sequence of pools, each one selected by filtering the previous one regarding one condition, until we conclude with the two elements used in the Tip Selection Algorithm: the Strong Tips Pool and the Weak Tip Pool . Eligible Messages Pool: This pool consists of all messages that were also approved by the Eligibility Check (see Section 2.4 - Data Flow ). Liked Payload Pool: This pool consists of all eligible messages that contain a payload tagged as \"liked\", i.e. is either data or an individually liked transaction. Strong Tips Pool : This pool consists of all strong messages in the Liked Payload Pool . Weak Tips Pool : This pool consists of all messages from the Liked Payload Pool that were not included in the Strong Tips Pool . The two main pools to be used by the tip selection algorithm are the Strong Tips Pool and the Weak Tips Pool . Observe that from our definition, each pool in the list is always constructed by performing a filtering in the previous one, but how this filtering will be performed is considered an implementation detail and hence will not be further considered here. 4.3.3.2 Update of the tip pools \u00b6 There are two types of updates that can be done with the strong and weak tip pools: Removal : Tips are removed when they are approved by other messages. This can happen in two ways: When the node issues a message, the selected tips will be removed from the respective tip pools after the Tip Selection Algorithm is performed (we briefly explain the procedure in the [R-URTS]). When a new message is received, its parents shall be removed from the respective tip pools by the Tip Manager application (further information may be found in the Section 2.4 - Data Flow ). Rearrangement: Tips can be changed from the strong tip pool to the weak tip pool, or from the weak tip pool to the strong tip pool if the perception of the branches they belong to changes, this is explained in more details in Section 6.5 - Node Peception Reorganization. 4.3.4 R-URTS \u00b6 We want to reiterate here that, ultimately, the tip selection is a free procedure not enforced by the protocol. Therefore each node may, if it sees worth, to select its approvees in a manual way or following another algorithm of its preference. What we will present here is the standard algorithm, that works both as a suggestion but also as something that the nodes will have implemented and will use by default. The suggested standard tip selection algorithm is R-URTS (Restricted Uniform Random Tip Selection), which selects messages with uniform probability among the list of tips restricted by some condition. Let us give an example for a Tip Selection Algorithm with Parental Number \\(k\\) : Consider the Strong Tips Pool and the Weak Tip Pools updated. The node shall select the first tip from the Strong Tips Pool . The node shall select tips from numbered \\(2\\) to \\(k\\) from the union of the Strong Tips Pool and the Weak Tips Pool . The node shall register in the message's Parents type field if each selected parent was from the strong or weak tip pools. The node shall remove the selected tips from their respective pools.","title":"4.3 Tip Selection Algorithm"},{"location":"IOTA-NECTAR/4.3%20Tip%20Selection%20Algorithm/#43-tip-selection-algorithm","text":"","title":"4.3 Tip Selection Algorithm"},{"location":"IOTA-NECTAR/4.3%20Tip%20Selection%20Algorithm/#431-introduction","text":"The tip selection algorithm is the method by which messages are selected for approval by other issued messages joining the network. This approval mechanism represents \u201cbelief\u201d in the Tangle: If message \\(y\\) approves message \\(x\\) , this implies that the node issuing \\(y\\) believes that \\(x\\) , and possibly its past cone, are \"good\". The tip selection algorithm allows the Tangle to grow in a stable and secure way, with quick approval and finality times. We call the new Tip-Section algorithm \"R-URTS\", which means \"Restricted Uniform Random Tip Selection\". Here we summarize the main differences that the new Tip Selection Algorithm has, compared to the legacy version: Uniform Selection: Unlike the old Random Walk tip selection, we will use a much faster and simpler solution that will select uniformly among a subset of eligible tips. Approval Switch Mechanism: A new mechanism that will allow us to keep a clear Tangle while preventing orphanage from splits due to disliked branches. Although we will not be using here, the new message layout (more information in Section 2.2 - Message Layout ) has the capabilities for a message to have a non-fixed number of messages that it approves (parents), which range from two to eight. This can be used to develop tip spam protection mechanisms among other purposes. We will denote the number of parents being used in the algorithm by Parental Number .","title":"4.3.1 Introduction"},{"location":"IOTA-NECTAR/4.3%20Tip%20Selection%20Algorithm/#432-definitions","text":"One of the main improvements of the new Tip Selection Algorithm comes from its ability to keep both a clean non-conflicting subtangle, as well as to ignore the existence of conflicts in its selection, hence emulating the ability that Chrysalis White Flag approach has of being unsplittable. In IOTA 2.0, those properties come from the approval switch mechanism. In the rest of this subsection, we present the theory of the approval switch, which classify approvals and messages in \"weak\" and \"strong\". This information is necessary to define the tip pools , i.e., the sets of (recent) messages which are selectable by the Tip Selection Algorithm (we provide a more complete description of tip pools later in this document).","title":"4.3.2 Definitions"},{"location":"IOTA-NECTAR/4.3%20Tip%20Selection%20Algorithm/#4321-approval-switch","text":"In order to properly define and explain the approval switch mechanism, we will need some extra defintions. We also refer to the basic concept of branches ( Section 5.2 - Ledger State ) and validity ( Section 4.1 - The Tangle ), as they are required to the understanding of some of the definitions below. Tip : A message is considered a tip (by a node) if it is selectable by the Tip Selection Algorithm, i.e. it is an element of any Tip Pool (of that node). In general, it is perceived as a message that has yet to receive any direct approvers. Eligibility : A Message is said eligible if: It is weakly valid; It passes the timestamp check with level of knowledge at least 2; All its parents are also eligible messages. Approval switch : : A binary field with values strong and weak in the message associated with each of its parents, filled by its issuer node. Strong approval : Represents that the issuer node declares that the message and its entire past cone are liked. Weak approval : Represents that the issuer node declares that the message and its payload is liked, but its past cone is not completely liked.","title":"4.3.2.1 Approval switch"},{"location":"IOTA-NECTAR/4.3%20Tip%20Selection%20Algorithm/#4322-branch","text":"Furthermore, to properly define the tip pool, additional definitions derived by the branch are required. Here we give a summarized definition for the sake of understanding. Monotonically Liked Branch : A branch is monotonically liked if all of its transactions are individually liked. Monotonically Liked Message : A message is monotonically liked if its aggregated branch is monotonically liked.","title":"4.3.2.2 Branch"},{"location":"IOTA-NECTAR/4.3%20Tip%20Selection%20Algorithm/#4323-strong-and-weak-messages","text":"In a heuristic way, one can think of a monotonically liked message as a message that has a liked payload and that all other payloads that depend on it are also liked. With this we can classify the messages: Strong Messages : We say a message \\(x\\) is strong (for a node) if it is: Eligible; Monotonically liked. Weak Messages : We say a message \\(x\\) is weak (for a node) it is: Eligible; Contains a liked payload; It is not monotonically liked with level of knowledge at least 2. Image X.X.X: An example of strong and weak parents. Observe that although B is in the past cone of I, it is not in its strong past cone.","title":"4.3.2.3 Strong and weak messages"},{"location":"IOTA-NECTAR/4.3%20Tip%20Selection%20Algorithm/#433-tip-pools","text":"The tip is a product of the construction of the Tip Pools, and in general it represents messages that are yet to be directly approved by other messages. The tip pools are built by filtering the messages that arrive from the neighbors, checking which ones are proper to be selectable by the algorithm. In this subsection we will define such filters and classifications that are used to make the Tip Pools. Differently from the legacy implementation, we will not have a single pool, but instead two, divided according to the new concept of the Approval Switch mechanism.","title":"4.3.3 Tip Pools"},{"location":"IOTA-NECTAR/4.3%20Tip%20Selection%20Algorithm/#4331-construction-of-the-tip-pools","text":"We will define a sequence of pools, each one selected by filtering the previous one regarding one condition, until we conclude with the two elements used in the Tip Selection Algorithm: the Strong Tips Pool and the Weak Tip Pool . Eligible Messages Pool: This pool consists of all messages that were also approved by the Eligibility Check (see Section 2.4 - Data Flow ). Liked Payload Pool: This pool consists of all eligible messages that contain a payload tagged as \"liked\", i.e. is either data or an individually liked transaction. Strong Tips Pool : This pool consists of all strong messages in the Liked Payload Pool . Weak Tips Pool : This pool consists of all messages from the Liked Payload Pool that were not included in the Strong Tips Pool . The two main pools to be used by the tip selection algorithm are the Strong Tips Pool and the Weak Tips Pool . Observe that from our definition, each pool in the list is always constructed by performing a filtering in the previous one, but how this filtering will be performed is considered an implementation detail and hence will not be further considered here.","title":"4.3.3.1 Construction of the Tip Pools"},{"location":"IOTA-NECTAR/4.3%20Tip%20Selection%20Algorithm/#4332-update-of-the-tip-pools","text":"There are two types of updates that can be done with the strong and weak tip pools: Removal : Tips are removed when they are approved by other messages. This can happen in two ways: When the node issues a message, the selected tips will be removed from the respective tip pools after the Tip Selection Algorithm is performed (we briefly explain the procedure in the [R-URTS]). When a new message is received, its parents shall be removed from the respective tip pools by the Tip Manager application (further information may be found in the Section 2.4 - Data Flow ). Rearrangement: Tips can be changed from the strong tip pool to the weak tip pool, or from the weak tip pool to the strong tip pool if the perception of the branches they belong to changes, this is explained in more details in Section 6.5 - Node Peception Reorganization.","title":"4.3.3.2 Update of the tip pools"},{"location":"IOTA-NECTAR/4.3%20Tip%20Selection%20Algorithm/#434-r-urts","text":"We want to reiterate here that, ultimately, the tip selection is a free procedure not enforced by the protocol. Therefore each node may, if it sees worth, to select its approvees in a manual way or following another algorithm of its preference. What we will present here is the standard algorithm, that works both as a suggestion but also as something that the nodes will have implemented and will use by default. The suggested standard tip selection algorithm is R-URTS (Restricted Uniform Random Tip Selection), which selects messages with uniform probability among the list of tips restricted by some condition. Let us give an example for a Tip Selection Algorithm with Parental Number \\(k\\) : Consider the Strong Tips Pool and the Weak Tip Pools updated. The node shall select the first tip from the Strong Tips Pool . The node shall select tips from numbered \\(2\\) to \\(k\\) from the union of the Strong Tips Pool and the Weak Tips Pool . The node shall register in the message's Parents type field if each selected parent was from the strong or weak tip pools. The node shall remove the selected tips from their respective pools.","title":"4.3.4 R-URTS"},{"location":"IOTA-NECTAR/4.4%20Solidification/","text":"4.4 Solidification \u00b6 A message is solid if all its parents are stored, solid and valid. This section defines how messages get solid in the Tangle. 4.4.1 Motivation \u00b6 Solidification is a process of requesting missing referenced messages. It may be recursively repeated until all of a message's past cone up to the genesis (or snapshot) becomes solid. In that way, the Tangle enables all nodes to retrieve all of a message's history, even the ones joining the network at a point later in time. 4.4.2 Definitions \u00b6 valid : A message is considered valid if it passes the following filters from the solidifier and from the message booker: solidifier: it checks if parents are valid, booker: it check if the contained transaction is valid. Notice that only messages containing a transaction are required to perform this check.. TODO: link to message layout semantic check, and transaction syntactic/semantic check in ledgerstate spec. parents age check : A check that ensures the timestamps of parents and child are valid, following the details defined in Section 4.2 - Timestamps . solid : A message is solid if it passes parents age check and all its parents are stored in the storage, solid and valid. 4.4.3 Parameters \u00b6 retryInterval : The time interval of resending the same solidification request. maxRequestThreshold : The maximum retry times to send a solidification request. 4.4.4 Detailed Design \u00b6 During solidification, if a node is missing a referenced message, the corresponding message ID is stored in the solidification buffer . A node asks its neighbors for the missing message by sending a solidification request containing the message ID. Once the requested message is received from its neighbors, its message ID shall be removed from the solidification buffer . The requested message is marked as solid after it passes the standard solidification checks. If any of the checks fails, the message remains unsolid. If a message gets solid, it shall walk through the rest of the data flow, then propagate the solid status its future cone by performing the solidification checks on each of the message in its future cone again. Figure 4.4.4.1 shows the solidification process: Figure 4.4.4.1, solidification workflow 4.4.5 Communication details \u00b6 Nodes send and receive solidification request/response via gossip layer. The solidification request is created and scheduled by the gossip manager, if a node does not get the requested message, the gossip manager resends it every retryInterval . If the requested message is not received within maxRequestThreshold rounds, the solidification request must be removed from the solidification buffer . 4.4.5.1 Request and response \u00b6 Below we define the form of SolidificationRequest and SolidificationResponse: SolidificationRequest \u00b6 Name Type Description type uint8 Indicates that the packet is SolidificationRequest. messageID ByteArray[32] Contains the message ID of the requested message. SolidificationResponse \u00b6 Name Type Description type uint8 Indicates that the packet is SolidificationResponse. message ByteArray Contains the entire requested message. 4.4.6 Denial of Service \u00b6 All requests/responses exchanged during the solidification are sent via UDP. As such, any UDP based Denial of Service attack may harm the normal functionality of the solidification. To limit this, hardware based protection such as firewall or alternatively may be used.","title":"4.4 Solidification"},{"location":"IOTA-NECTAR/4.4%20Solidification/#44-solidification","text":"A message is solid if all its parents are stored, solid and valid. This section defines how messages get solid in the Tangle.","title":"4.4 Solidification"},{"location":"IOTA-NECTAR/4.4%20Solidification/#441-motivation","text":"Solidification is a process of requesting missing referenced messages. It may be recursively repeated until all of a message's past cone up to the genesis (or snapshot) becomes solid. In that way, the Tangle enables all nodes to retrieve all of a message's history, even the ones joining the network at a point later in time.","title":"4.4.1 Motivation"},{"location":"IOTA-NECTAR/4.4%20Solidification/#442-definitions","text":"valid : A message is considered valid if it passes the following filters from the solidifier and from the message booker: solidifier: it checks if parents are valid, booker: it check if the contained transaction is valid. Notice that only messages containing a transaction are required to perform this check.. TODO: link to message layout semantic check, and transaction syntactic/semantic check in ledgerstate spec. parents age check : A check that ensures the timestamps of parents and child are valid, following the details defined in Section 4.2 - Timestamps . solid : A message is solid if it passes parents age check and all its parents are stored in the storage, solid and valid.","title":"4.4.2 Definitions"},{"location":"IOTA-NECTAR/4.4%20Solidification/#443-parameters","text":"retryInterval : The time interval of resending the same solidification request. maxRequestThreshold : The maximum retry times to send a solidification request.","title":"4.4.3 Parameters"},{"location":"IOTA-NECTAR/4.4%20Solidification/#444-detailed-design","text":"During solidification, if a node is missing a referenced message, the corresponding message ID is stored in the solidification buffer . A node asks its neighbors for the missing message by sending a solidification request containing the message ID. Once the requested message is received from its neighbors, its message ID shall be removed from the solidification buffer . The requested message is marked as solid after it passes the standard solidification checks. If any of the checks fails, the message remains unsolid. If a message gets solid, it shall walk through the rest of the data flow, then propagate the solid status its future cone by performing the solidification checks on each of the message in its future cone again. Figure 4.4.4.1 shows the solidification process: Figure 4.4.4.1, solidification workflow","title":"4.4.4 Detailed Design"},{"location":"IOTA-NECTAR/4.4%20Solidification/#445-communication-details","text":"Nodes send and receive solidification request/response via gossip layer. The solidification request is created and scheduled by the gossip manager, if a node does not get the requested message, the gossip manager resends it every retryInterval . If the requested message is not received within maxRequestThreshold rounds, the solidification request must be removed from the solidification buffer .","title":"4.4.5 Communication details"},{"location":"IOTA-NECTAR/4.4%20Solidification/#4451-request-and-response","text":"Below we define the form of SolidificationRequest and SolidificationResponse:","title":"4.4.5.1 Request and response"},{"location":"IOTA-NECTAR/4.4%20Solidification/#solidificationrequest","text":"Name Type Description type uint8 Indicates that the packet is SolidificationRequest. messageID ByteArray[32] Contains the message ID of the requested message.","title":"SolidificationRequest"},{"location":"IOTA-NECTAR/4.4%20Solidification/#solidificationresponse","text":"Name Type Description type uint8 Indicates that the packet is SolidificationResponse. message ByteArray Contains the entire requested message.","title":"SolidificationResponse"},{"location":"IOTA-NECTAR/4.4%20Solidification/#446-denial-of-service","text":"All requests/responses exchanged during the solidification are sent via UDP. As such, any UDP based Denial of Service attack may harm the normal functionality of the solidification. To limit this, hardware based protection such as firewall or alternatively may be used.","title":"4.4.6 Denial of Service"},{"location":"IOTA-NECTAR/4.5%20Rate%20Control/","text":"4.5 Rate Control through Adaptive Proof of Work \u00b6 Summary \u00b6 In Proof of Work-based blockchains, a built-in rate limit is enforced by the mining difficulty adjustment and the message fees. Without this filter, however, an attacker may be able to easily issue a very large number of messages to potentially harm the network. In order to enable the machine-to-machine economy, IOTA does not allow neither mining race nor fees, which makes an explicit rate control mechanism necessary . In order to ensure that the network traffic does not exceed the allowed throughput determined by the limited resources, it is fundamental to limit the number of messages issued at node level. The mechanisms described act as an emergency break during spam attacks, by slowing down the rate of messages a node can issue. For honest nodes, the proof of work difficulty should be small enough not to hamper performance. Finer controls on the access are developed in Section 4.6 - Congestion Control , which regulate network traffic during normal periods of congestion. Legacy implementation \u00b6 In the legacy IOTA implementation, a user is asked to solve a proof of work (PoW) before issuing a new message. The user can either perform that computation locally or outsource it to a third-party service. In the legacy network, the difficulty of the PoW is set to some value POW_DIFFICULTY . Received messages are stored in a queue and processed in FIFO order. The protocol dictates that the nodes forward messages if and only if the difficulty of the PoW performed is greater or equal to POW_DIFFICULTY . Otherwise, messages shall be dropped. Proposal \u00b6 Similar to the legacy implementation, we require the solution of a given cryptographic puzzle before a message is issued. Here, however, we impose that the difficulty of the challenge progressively increases as a node issues multiple messages in a short time interval. The goal of this document is to define this rate control mechanism, called Adaptive PoW (APoW), which permits nodes' theoretical throughput to be independent on their hardware equipment. We believe that this mechanism is fundamental to prevent spam and denial-of-service attacks, disallowing dishonest nodes from inflating their neighbors' buffers through large number of messages in a short time. Unlike APoW, the congestion control mechanism described in Section 4.6 - Congestion Control sets the actual throughput depending on nodes' access Mana, and protects the protocol against Sybil attacks and selfish behavior. Prerequirements \u00b6 Node identity . We require node accountability where each message is associated with the node ID of its issuing node (see Section 3.3 - Peer Discovery ). Timestamp . In order to verify if the APoW has been performed correctly, message timestamps must pass some quality checks, see Section 4.2.3 - General Timestamps Rules . Adaptive Proof of Work \u00b6 All nodes in the network have knowledge of the following three fixed global parameters: Base difficulty \\((d_0)\\) . It sets the initial difficulty of PoW. Adaptation rate \\((\\gamma\\in [0, 1])\\) . It provides the rate at which difficulty will be adjusted. Equivalently, \\(1/\\gamma\\) indicates how many messages can be sent per time window without increasing the PoW difficulty. APoW time window \\((w>0)\\) . It describes the width of the time interval considered by the algorithm, i.e., its granularity. Message generation \u00b6 Let \\(t\\) be the output of the function CurrentTime() . If node m wants to issue a new message, it shall perform a PoW with difficulty \\(d_m(t)\\) such that \\[d_m(t) = d_0 + \\left \\lfloor{\\gamma\\cdot r_m(t)}\\right \\rfloor\\] where \\(r_m(t)\\) represents the number of messages issued by node m with (message) timestamp in the interval \\([t-w, t]\\) . Note that when \\(\\gamma = 0\\) , the algorithm becomes equivalent to the legacy IOTA implementation. Message verification \u00b6 When a node n receives a message from a neighbor, it shall check that PoW with an appropriate difficulty was performed. The verification of the correctness of the PoW computation is the last step of the parser checks, right after signature verification (see Section 2.4 - Data Flow ). Let us assume that node n receives a message with difficulty \\(d_m\\) issued by node m . To decide whether this message should be discarded, node n counts how many messages \\(r_m(t)\\) issued by m it has received in the last \\(w\\) time units. In accordance with the formula above, the node validates the PoW only if the following condition is satisfied: \\[d_m \\geq d_0 + \\left\\lfloor{\\gamma\\cdot r_m(t)}\\right\\rfloor.\\] Discussions on the correctness of this procedure can be found on a related article . Algorithm \u00b6 Protocol parameters \u00b6 In line with the previous section, all nodes know the following global constants: Parameter Type Description POW_BASE integer The base difficulty \\(d_0\\) APOW_RATE float The adaptation rate \\(\\gamma\\) (proposed values [0.1 - 1]) APOW_WINDOW integer The APoW time window \\(w\\) (proposed values [10 - 60s]) The choice of the time window is crucial in the correct functioning of the algorithm. Our claim is that the time window must be kept small for two main reasons: Message burst can be captured; Implementation is easier as it requires smaller caches. However, it is fundamental to keep this time window at least larger than the gratuitous network delay DLARGE (see Section 4.2 - Timestamps ). Local variables and metadata \u00b6 Variable/Metadata Type Description timestamp integer A value declared by the node representing time at which the message has been issued nodeID nodeID Identity of the node issuing the message defined as the blake2b hash of its public key targetDifficulty integer Minimum difficulty needed to pass the APoW verification powCheck boolean Boolean value which indicates whether the APoW verification is successful or not ownId nodeID Identity of the node running the algorithm msgCache list Cache storing the timestamp of the most recent messages received by ownID nodeMap list List of nodeIDs which have issued messages recently (within 2 APoW timestamp windows) Built-in functions \u00b6 Function Description Floor(x) Give the greatest integer less than or equal to x Sort(x, y) Sort list x by metric y Append(x, y) Add a new element y to list x Remove(x) Remove the oldest element from the ordered data structure x Head(x) Get (without removing) the oldest element from the ordered data structure x CurrentTime() Current time computed with the local clock Pseudocode \u00b6 TargetPoW(timestamp, nodeID) \u00b6 This function accesses the ledger to check the history of messages for nodeId . FUNCTION targetPoW = TargetPoW ( timestamp , nodeID ) # cache update ( this is done as an optimization ) WHILE CurrentTime () - Head ( msgCache ). timestamp > 2 * APOW_WINDOW Remove ( msgCache ) Append ( msgCache , < nodeID , timestamp > ) Sort ( msgCache , ` timestamp ` ) countMsg = 0 FOR msg IN msgCache [ nodeID ] IF msg > timestamp - APOW_WINDOW AND msg < timestamp countMsg ++ RETURN BASE_POW + Floor ( APOW_RATE * countMsg ) APoWGeneration() \u00b6 This function sets the difficulty at which the message creator should compute the PoW when generating a new message. ### upon creation of a new message FUNCTION targetPoW = APoWGeneration () RETURN TargetPoW ( CurrentTime (), ownID ) APoWVerification(msg) \u00b6 This function is triggered in the parser by new messages, see Section 2.4 - Data Flow . It returns TRUE if the PoW attached to the message is sufficient, or FALSE otherwise. ### upon arrival of a message msg FUNCTION powCheck = APoWVerification ( msg ) targetPoW = TargetPoW ( msg . timestamp , msg . nodeID ) IF msg . pow >= targetPoW IF nodeMap [ msg . nodeID ] == NULL Append ( nodeMap , msg . nodeID ) Append ( msgCache , msg . timestamp ) RETURN TRUE ELSE RETURN FALSE Implementation \u00b6 The most critical part of the algorithm concerns counting the number of messages recently issued by a node. Since querying the database may be expensive, we propose to cache the most recent messages. To this end, we use two data structures: nodeMap . Each entry in the hashmap corresponds to a different nodeId and points to the doubly linked list of recent messages of the same node. msgCache . A queue which removes old messages and adds new ones according to a FIFO policy. Both data structures point to the same locations of memory which store the timestamp of the message. These locations of memory also store the pointers to the other elements of nodeMap and msgCache . The size of the cache \\(C\\) (in number of timestamps) must be larger of the product between the maximum network throughput and the time window \\(w\\) . Assume that max throughput is 1000 TPS and the time window is 50 s, cache size must be larger than 50,000. Given \\(N\\) the number of nodes issuing recent messages, our caching scheme provides the following performance: cache update: \\(\\mathcal{O}(1)\\) ; msg counter: \\(\\mathcal{O}(C/N)\\) ; cache size: \\(<10\\) MB. Assume that a node receives a message with PoW difficulty equal to targetPoW . However, the node cannot (immediately) know whether older messages have been issued before the timestamp of such message, which would make its PoW not sufficient. In this case, in order not to slow down the network, the node will forward anyway the message for scheduling. An attacker may exploit the above in order to issue progressively older messages which would be accepted with easier PoW difficulty. Since the timestamp validation window is pretty large, this attack may theoretically be effective. In case a node receives a new message with a timestamp that would make other messages from the same node would not have the correct PoW difficulty, the node will be blacklisted. However, no transactions which are already scheduled would be dropped.","title":"4.5 Rate Control"},{"location":"IOTA-NECTAR/4.5%20Rate%20Control/#45-rate-control-through-adaptive-proof-of-work","text":"","title":"4.5 Rate Control through Adaptive Proof of Work"},{"location":"IOTA-NECTAR/4.5%20Rate%20Control/#summary","text":"In Proof of Work-based blockchains, a built-in rate limit is enforced by the mining difficulty adjustment and the message fees. Without this filter, however, an attacker may be able to easily issue a very large number of messages to potentially harm the network. In order to enable the machine-to-machine economy, IOTA does not allow neither mining race nor fees, which makes an explicit rate control mechanism necessary . In order to ensure that the network traffic does not exceed the allowed throughput determined by the limited resources, it is fundamental to limit the number of messages issued at node level. The mechanisms described act as an emergency break during spam attacks, by slowing down the rate of messages a node can issue. For honest nodes, the proof of work difficulty should be small enough not to hamper performance. Finer controls on the access are developed in Section 4.6 - Congestion Control , which regulate network traffic during normal periods of congestion.","title":"Summary"},{"location":"IOTA-NECTAR/4.5%20Rate%20Control/#legacy-implementation","text":"In the legacy IOTA implementation, a user is asked to solve a proof of work (PoW) before issuing a new message. The user can either perform that computation locally or outsource it to a third-party service. In the legacy network, the difficulty of the PoW is set to some value POW_DIFFICULTY . Received messages are stored in a queue and processed in FIFO order. The protocol dictates that the nodes forward messages if and only if the difficulty of the PoW performed is greater or equal to POW_DIFFICULTY . Otherwise, messages shall be dropped.","title":"Legacy implementation"},{"location":"IOTA-NECTAR/4.5%20Rate%20Control/#proposal","text":"Similar to the legacy implementation, we require the solution of a given cryptographic puzzle before a message is issued. Here, however, we impose that the difficulty of the challenge progressively increases as a node issues multiple messages in a short time interval. The goal of this document is to define this rate control mechanism, called Adaptive PoW (APoW), which permits nodes' theoretical throughput to be independent on their hardware equipment. We believe that this mechanism is fundamental to prevent spam and denial-of-service attacks, disallowing dishonest nodes from inflating their neighbors' buffers through large number of messages in a short time. Unlike APoW, the congestion control mechanism described in Section 4.6 - Congestion Control sets the actual throughput depending on nodes' access Mana, and protects the protocol against Sybil attacks and selfish behavior.","title":"Proposal"},{"location":"IOTA-NECTAR/4.5%20Rate%20Control/#prerequirements","text":"Node identity . We require node accountability where each message is associated with the node ID of its issuing node (see Section 3.3 - Peer Discovery ). Timestamp . In order to verify if the APoW has been performed correctly, message timestamps must pass some quality checks, see Section 4.2.3 - General Timestamps Rules .","title":"Prerequirements"},{"location":"IOTA-NECTAR/4.5%20Rate%20Control/#adaptive-proof-of-work","text":"All nodes in the network have knowledge of the following three fixed global parameters: Base difficulty \\((d_0)\\) . It sets the initial difficulty of PoW. Adaptation rate \\((\\gamma\\in [0, 1])\\) . It provides the rate at which difficulty will be adjusted. Equivalently, \\(1/\\gamma\\) indicates how many messages can be sent per time window without increasing the PoW difficulty. APoW time window \\((w>0)\\) . It describes the width of the time interval considered by the algorithm, i.e., its granularity.","title":"Adaptive Proof of Work"},{"location":"IOTA-NECTAR/4.5%20Rate%20Control/#message-generation","text":"Let \\(t\\) be the output of the function CurrentTime() . If node m wants to issue a new message, it shall perform a PoW with difficulty \\(d_m(t)\\) such that \\[d_m(t) = d_0 + \\left \\lfloor{\\gamma\\cdot r_m(t)}\\right \\rfloor\\] where \\(r_m(t)\\) represents the number of messages issued by node m with (message) timestamp in the interval \\([t-w, t]\\) . Note that when \\(\\gamma = 0\\) , the algorithm becomes equivalent to the legacy IOTA implementation.","title":"Message generation"},{"location":"IOTA-NECTAR/4.5%20Rate%20Control/#message-verification","text":"When a node n receives a message from a neighbor, it shall check that PoW with an appropriate difficulty was performed. The verification of the correctness of the PoW computation is the last step of the parser checks, right after signature verification (see Section 2.4 - Data Flow ). Let us assume that node n receives a message with difficulty \\(d_m\\) issued by node m . To decide whether this message should be discarded, node n counts how many messages \\(r_m(t)\\) issued by m it has received in the last \\(w\\) time units. In accordance with the formula above, the node validates the PoW only if the following condition is satisfied: \\[d_m \\geq d_0 + \\left\\lfloor{\\gamma\\cdot r_m(t)}\\right\\rfloor.\\] Discussions on the correctness of this procedure can be found on a related article .","title":"Message verification"},{"location":"IOTA-NECTAR/4.5%20Rate%20Control/#algorithm","text":"","title":"Algorithm"},{"location":"IOTA-NECTAR/4.5%20Rate%20Control/#protocol-parameters","text":"In line with the previous section, all nodes know the following global constants: Parameter Type Description POW_BASE integer The base difficulty \\(d_0\\) APOW_RATE float The adaptation rate \\(\\gamma\\) (proposed values [0.1 - 1]) APOW_WINDOW integer The APoW time window \\(w\\) (proposed values [10 - 60s]) The choice of the time window is crucial in the correct functioning of the algorithm. Our claim is that the time window must be kept small for two main reasons: Message burst can be captured; Implementation is easier as it requires smaller caches. However, it is fundamental to keep this time window at least larger than the gratuitous network delay DLARGE (see Section 4.2 - Timestamps ).","title":"Protocol parameters"},{"location":"IOTA-NECTAR/4.5%20Rate%20Control/#local-variables-and-metadata","text":"Variable/Metadata Type Description timestamp integer A value declared by the node representing time at which the message has been issued nodeID nodeID Identity of the node issuing the message defined as the blake2b hash of its public key targetDifficulty integer Minimum difficulty needed to pass the APoW verification powCheck boolean Boolean value which indicates whether the APoW verification is successful or not ownId nodeID Identity of the node running the algorithm msgCache list Cache storing the timestamp of the most recent messages received by ownID nodeMap list List of nodeIDs which have issued messages recently (within 2 APoW timestamp windows)","title":"Local variables and metadata"},{"location":"IOTA-NECTAR/4.5%20Rate%20Control/#built-in-functions","text":"Function Description Floor(x) Give the greatest integer less than or equal to x Sort(x, y) Sort list x by metric y Append(x, y) Add a new element y to list x Remove(x) Remove the oldest element from the ordered data structure x Head(x) Get (without removing) the oldest element from the ordered data structure x CurrentTime() Current time computed with the local clock","title":"Built-in functions"},{"location":"IOTA-NECTAR/4.5%20Rate%20Control/#pseudocode","text":"","title":"Pseudocode"},{"location":"IOTA-NECTAR/4.5%20Rate%20Control/#targetpowtimestamp-nodeid","text":"This function accesses the ledger to check the history of messages for nodeId . FUNCTION targetPoW = TargetPoW ( timestamp , nodeID ) # cache update ( this is done as an optimization ) WHILE CurrentTime () - Head ( msgCache ). timestamp > 2 * APOW_WINDOW Remove ( msgCache ) Append ( msgCache , < nodeID , timestamp > ) Sort ( msgCache , ` timestamp ` ) countMsg = 0 FOR msg IN msgCache [ nodeID ] IF msg > timestamp - APOW_WINDOW AND msg < timestamp countMsg ++ RETURN BASE_POW + Floor ( APOW_RATE * countMsg )","title":"TargetPoW(timestamp, nodeID)"},{"location":"IOTA-NECTAR/4.5%20Rate%20Control/#apowgeneration","text":"This function sets the difficulty at which the message creator should compute the PoW when generating a new message. ### upon creation of a new message FUNCTION targetPoW = APoWGeneration () RETURN TargetPoW ( CurrentTime (), ownID )","title":"APoWGeneration()"},{"location":"IOTA-NECTAR/4.5%20Rate%20Control/#apowverificationmsg","text":"This function is triggered in the parser by new messages, see Section 2.4 - Data Flow . It returns TRUE if the PoW attached to the message is sufficient, or FALSE otherwise. ### upon arrival of a message msg FUNCTION powCheck = APoWVerification ( msg ) targetPoW = TargetPoW ( msg . timestamp , msg . nodeID ) IF msg . pow >= targetPoW IF nodeMap [ msg . nodeID ] == NULL Append ( nodeMap , msg . nodeID ) Append ( msgCache , msg . timestamp ) RETURN TRUE ELSE RETURN FALSE","title":"APoWVerification(msg)"},{"location":"IOTA-NECTAR/4.5%20Rate%20Control/#implementation","text":"The most critical part of the algorithm concerns counting the number of messages recently issued by a node. Since querying the database may be expensive, we propose to cache the most recent messages. To this end, we use two data structures: nodeMap . Each entry in the hashmap corresponds to a different nodeId and points to the doubly linked list of recent messages of the same node. msgCache . A queue which removes old messages and adds new ones according to a FIFO policy. Both data structures point to the same locations of memory which store the timestamp of the message. These locations of memory also store the pointers to the other elements of nodeMap and msgCache . The size of the cache \\(C\\) (in number of timestamps) must be larger of the product between the maximum network throughput and the time window \\(w\\) . Assume that max throughput is 1000 TPS and the time window is 50 s, cache size must be larger than 50,000. Given \\(N\\) the number of nodes issuing recent messages, our caching scheme provides the following performance: cache update: \\(\\mathcal{O}(1)\\) ; msg counter: \\(\\mathcal{O}(C/N)\\) ; cache size: \\(<10\\) MB. Assume that a node receives a message with PoW difficulty equal to targetPoW . However, the node cannot (immediately) know whether older messages have been issued before the timestamp of such message, which would make its PoW not sufficient. In this case, in order not to slow down the network, the node will forward anyway the message for scheduling. An attacker may exploit the above in order to issue progressively older messages which would be accepted with easier PoW difficulty. Since the timestamp validation window is pretty large, this attack may theoretically be effective. In case a node receives a new message with a timestamp that would make other messages from the same node would not have the correct PoW difficulty, the node will be blacklisted. However, no transactions which are already scheduled would be dropped.","title":"Implementation"},{"location":"IOTA-NECTAR/4.6%20Congestion%20Control/","text":"4.6 Congestion control \u00b6 This specification provides a solution to deal with network congestion in the IOTA network. The congestion control algorithm described in this file decides which messages should be processed and gossiped to node's neighbors and in what order to do so. Summary \u00b6 Every network has to deal with its intrinsic limited resources in terms of bandwidth and node capabilities (CPU and storage). In this document, we present a congestion control algorithm to regulate the influx of messages in the network with the goal of maximizing throughput (messages/bytes per second) and minimizing delays. Furthermore, the following requirements must be satisfied: Consistency . If a message is written by one honest node, it shall be written by all honest nodes within some delay bound. Fairness . Nodes can obtain a share of the available throughput depending on their access Mana. Throughput is shared in such a way that an attempt to increase the allocation of any node necessarily results in the decrease in the allocation of some other node with an equal or smaller allocation (max-min fairness). Security . Malicious nodes shall be unable to interfere with either of the above requirements. Further information can be found in our a paper Access Control for Distributed Ledgers in the Internet of Things: A Networking Approach . Proposal \u00b6 In this specification, we present the congestion control algorithm that shall be implemented by all IOTA nodes. Nodes cannot take any advantage by not following the protocol. Conversely, they may eventually be considered as malicious nodes and banned. Our algorithm has three core components: * A scheduling algorithm which ensures fair access for all nodes according to their access Mana. * A TCP-inspired algorithm for decentralized rate setting to efficiently utilize the available bandwidth while preventing large delays. * A blacklisting policy to ban malicious nodes. Prerequirements \u00b6 Node identity . We require node accountability where each message is associated with the node ID of its issuing node (see Section 3.3 - Peer discovery ). Access mana . The congestion control module has knowledge of the access Mana of the nodes in the network in order to fairly share the available throughput. Without access Mana the network would be subject to Sybil attacks, which would incentivise even honest actors to artificially increase its own number of nodes (see Section 5.3 - Mana ). Timestamp . Before scheduling a new message, the scheduler verifies whether the message timestamp is valid or not. Message weight . Weight of a message is used to priority messages over the others and it is calculated depending on the type of message and of the message length, as described in Section 2.4 - Data Flow . Congestion control algorithm \u00b6 Outbox management \u00b6 Once the message has successfully passed the message parser checks and is solid, it is enqueued into the outbox for scheduling (see Section 2.4 - Data Flow ). The outbox is logically split into several queues, each one corresponding to a different node issuing messages. In this section, we describe the operations of message enqueuing (and dequeuing) into (from) the outbox. The enqueuing mechanism includes the following components: Classification . The mechanism identifies the queue where the message belongs to according to the node ID of the message issuer. Message enqueuing . The message is actually enqueued, queue is sorted by message timestamps in increasing order and counters are updated (e.g., counters for the total number of bytes in the queue). Message drop . In some circumstances, due to network congestion or to ongoing attacks, some messages shall be dropped to guarantee bounded delays and isolate attacker's messages. Specifically, a node shall drop messages in two situations: since buffers are of a limited size, if the total number of bytes in all queues exceeds a certain threshold, new incoming messages are dropped; to guarantee the security of the network, if a certain queue exceeds a given threshold, new incoming packets from that specific node ID will be dropped. The dequeue mechanism includes the following components: Queue selection . A queue is selected according to round robin scheduling algorithm. In particular, we use a modified version of the deficit round robin (DRR) algorithm, and we describe it in Section 3.4.2.2 - Scheduler. Message dequeuing . The first message of the queue is dequeued, and list of active nodes is updated. Scheduler management . Scheduler counters and pointers are updated. Scheduler \u00b6 The most critical task is the scheduling algorithm which must guarantee that, for an honest node node , the following requirements will be met: * node 's messages will not accumulate indefinitely at any node (i.e., starvation is avoided), so the consistency requirement will be ensured. * node 's fair share (according to its access Mana) of the network resources are allocated to it, guaranteeing the fairness requirement. * Malicious nodes sending above their allowed rate will not interrupt node 's throughput, fulfilling the security requirement. We remind the reader that the above requirements are described in Section 3.4.1 - Summary. Although nodes in our setting are capable of more complex and customised behaviour than a typical router in a packet-switched network, our scheduler must still be lightweight and scalable due to the potentially large number of nodes requiring differentiated treatment. It is estimated that over 10,000 nodes operate on the Bitcoin network, and we expect that an even greater number of nodes are likely to be present in the IoT setting. For this reason, we adopt a scheduler based on Deficit Round Robin (DRR) (the Linux implementation of the FQ-CoDel packet scheduler , which is based on DRR, supports anywhere up to 65535 separate queues). The DRR scans all non-empty queues in sequence. When a non-empty queue is selected, its priority counter (called deficit ) is incremented by a certain value (called quantum ). Then, the value of the deficit counter is a maximal amount of bytes that can be sent at this turn: if the deficit counter is greater than the weight of the message at the head of the queue, this message can be scheduled and the value of the counter is decremented by this weight. In our implementation, the quantum is proportional to node's access Mana and we add a cap on the maximum deficit that a node can achieve to keep the network latency low. It is also important to mention that the weight of the message can be assigned in such a way that specific messages can be prioritized (low weight) or penalized (large weight); by default, in our mechanism the weight is proportional to the message size measured in bytes. The weight of a message is set by the function WorkCalculator() , and additional details can be found in Section 2.4 - Data Flow . Here a fundamental remark: the network manager sets up a desired maximum (fixed) rate SCHEDULING_RATE at which messages will be scheduled , computed in weight (see above) per second. This implies that every message is scheduled after a delay which is equal to the weight (size as default) of the latest scheduled message times the parameter SCHEDULING_RATE . This rate mostly depends on the degree of decentralization desired: e.g., a larger rate leads to higher throughput but would leave behind slower devices which will fall out of sync. Rate setting \u00b6 If all nodes always had messages to issue, i.e., if nodes were continuously willing to issue new messages, the problem of rate setting would be very straightforward: nodes could simply operate at a fixed, assured rate, sharing the total throughput according to the percentage of access Mana owned. The scheduling algorithm would ensure that this rate is enforceable, and that increasing delays or dropped messages are only experienced by misbehaving node. However, it is unrealistic that all nodes will always have messages to issue, and we would like nodes to better utilise network resources, without causing excessive congestion and violating any requirement. We propose a rate setting algorithm inspired by TCP \u2014 each node employs additive increase, multiplicative decrease (AIMD) rules to update their issuance rate in response to congestion events. In the case of distributed ledgers, all message traffic passes through all nodes, contrary to the case of traffic typically found in packet switched networks and other traditional network architectures. Under these conditions, local congestion at a node is all that is required to indicate congestion elsewhere in the network. This observation is crucial, as it presents an opportunity for a congestion control algorithm based entirely on local traffic. Our rate setting algorithm outlines the AIMD rules employed by each node to set their issuance rate. Rate updates for a node node take place each time a new message is scheduled if the node has a non-empty set of its own messages not yet scheduled. Node node sets its own local additive-increase variable localIncrease(node) based on its access Mana and on a global increase rate parameter RATE_SETTING_INCREASE . An appropriate choice of RATE_SETTING_INCREASE ensures a conservative global increase rate which does not cause problems even when many nodes increase their rate simultaneously. Nodes wait RATE_SETTING_PAUSE seconds after a global multiplicative decrease parameter RATE_SETTING_DECREASE , during which there are no further updates made, to allow the reduced rate to take effect and prevent multiple successive decreases. At each update, node checks how many of its own messages are in its outbox queue, and responds with a multiplicative decrease if this number is above a threshold, backoff(node) , which is proportional to node 's access Mana. If the number of node 's messages in the outbox is below the threshold, node 's issuance rate is incremented by its local increase variable localIncrease(node) . Message blocking and blacklisting \u00b6 If an incoming message made the outbox total buffer size to exceed its maximum capacity MAX_BUFFER , the same message would be dropped. In our analysis, we set buffers to be large enough to accommodate traffic from all honest nodes. Furthermore, to mitigate spamming actions from malicious nodes, we add an additional constraint: if node 's access Mana-scaled queue length (i.e., queue length divided by node's access Mana) exceeds a given threshold MAX_QUEUE , any new incoming packet from node will be dropped, hence the node is blacklisted. The attacker is blacklisted for a certain time BLACKLIST_TIME during which no messages issued by node can be added to the outbox. Please note that it is still possible to receive message from the attacker through solidification requests, which is important in order to guarantee the consistency requirement. Finally, when a node is blacklisted, the blacklister does not increase its own rate for a time RATE_SETTING_QUARANTINE , to avoid errors in the perception of the current congestion level. Algorithmic details \u00b6 Protocol parameters \u00b6 In line with the previous section, all nodes know the following global variables: int SCHEDULING_RATE : clock time interval between subsequent executions of the function Schedule() float RATE_SETTING_INCREASE : global additive increase parameter float RATE_SETTING_DECREASE : global multiplicative decrease parameter (larger than 1) int RATE_SETTING_PAUSE : waiting time before next ownID 's rate update after backoff int RATE_SETTING_QUARANTINE : waiting time before next ownID 's rate update after blacklisting int MAX_BUFFER : maximum buffer size (in bytes) float MAX_QUEUE : maximum access Mana-scaled inbox length float MAX_DEFICIT : maximum cap for accumulated deficit float MAX_RATE : maximum rate at which a node can be allowed to issue messages int MIN_MANA : minimum amount of Mana needed to issue messages int BLACKLIST_TIME : time interval during which no messages from blacklisted nodes are added to the outbox Local variables \u00b6 float ownRate : issuance rate of ownID according to the rate setter list activeNode : updated list of nodes having at least one message in the outbox queue (more details in Section 3.4.3.5 - Implementation) queue bufferQueue : actual outbox queue where messages are ready to be scheduled (more details in Section 3.4.3.5 - Implementation) nodeID nextID : pointer to the specific queue where next message can be scheduled from list mana : contains the up-to-date (at the time the vector is used) value of the access Mana given a certain nodeId . The way in which mana is updated is out of the scope of this spec, and further information can be found in Section 5.3 - Mana float backoff : local threshold for rate setting's backoff float localIncrease : local additive increase parameter list blacklisted : list of timestamps indicating if a specific nodeId is blacklisted. If node is not blacklisted, the entry is 0 int pauseUpdates : time interval during which rate setter is not updated list messageWorker : list of messages that ownNode issued but are still not part of the outbox Built-in functions \u00b6 Len(x) : measures the length of a data structure x Append(x, y) : add a new element y to list x WorkCalculator(x) : provides the weight of message x Sort(x, y) : sort list x by metric y Parents(x) : gives the list of parents of a message x CurrentTime() : current time computed with the local clock Execute(x) : process and gossip message x Pause(x) : stop execution of a function for x time units Pseudocode \u00b6 The congestion control algorithm follows the solidification in the data flow: when a new message msg arrives to the scheduler, the function Enqueue(msg) will be triggered in order to properly add msg to the outbox. At the same time, at regular intervals (given by SCHEDULING_RATE times WorkCalculator(x) where x is the latest scheduled message), the function Schedule() picks a new message that has to be gossiped to neighbors and to be added to the local ledger. Simultaneously, RateSetting() adjusts the message generation rate of ownID according to the network congestion. Enqueue(msg) \u00b6 The function Enqueue(msg) adds a new message msg into the outbox and updates the list of active nodes accordingly. The checks on blacklisting condition ( blacklisted[nodeID] == FALSE ) and buffer size ( Len(bufferQueue) < MAX_BUFFER ) may be moved to the parser checker for optimization purposes. ### upon arrival of a new message msg ( having passed solidification ) ### FUNCTION Enqueue ( msg ) nodeID = msg . nodeID IF mana [ nodeID ] > MIN_MANA AND ( blacklisted [ nodeId ] == 0 OR CurrentTime () - blacklisted [ nodeID ] > BLACKLIST_TIME ) blacklisted [ nodeId ] = 0 IF Len ( bufferQueue ) < MAX_BUFFER IF activeNode [ nodeID ] ! = NULL # other messages from nodeID are already in the queue nodeQueue = activeNode [ nodeID ] IF ( Len ( nodeQueue ) + Len ( msg )) / mana [ nodeID ] < MAX_QUEUE # append msg Append ( bufferQueue , msg ) Sort ( bufferQueue , timestamp ) ELSE # blacklist nodeID and pause rate setting updates blacklisted [ nodeID ] = CurrentTime () pauseUpdates = Max ( pauseUpdates , RATE_SETTING_QUARANTINE ) ELSE # no other messages for nodeID are present in the buffer Append ( activeNode , nodeID ) activeNode [ nodeID ] . deficit = MAX_DEFICIT Append ( bufferQueue , msg ) RateSetting() \u00b6 The function RateSetting() updates the rate ownRate at which messages can be issued by the node. The maximum value that ownRate can reach is MAX_RATE . At the bootstrap, the value of ownRate is initialized by the proportion of access Mana owned by the node times RATE_SETTING_INCREASE . FUNCTION RateSetting () # update issueing rate if no recent backoff IF ownRate < MAX_RATE # retrieve message queue of the same node IF Len ( bufferQueue [ ownID ] ) / mana [ ownID ] > backoff ownRate = ownRate / RATE_SETTING_DECREASE pauseUpdates = Max ( pauseUpdates , RATE_SETTING_PAUSE ) ELSE ownRate += RATE_SETTING_INCREASE * mana [ ownID ] / Sum ( mana ) Schedule() \u00b6 At regular intervals, i.e., every SCHEDULING_RATE times WorkCalculator(x) where x is the latest scheduled message, the function Schedule() selects the next message to gossip and process, if at least one message exists in bufferQueue . Otherwise, it returns NULL and the scheduling slot is missed. The local variable pauseUpdates is initialized to 0 . FUNCTION msg = Schedule () WHILE TRUE IF Len ( bufferQueue ) > 0 # msg represents the message in the outbox msg = bufferQueue [ nextID ] . head # point to a nodeId with enough deficit , having a valid message WHILE activeNode [ nextID ] . deficit < Weight ( msg ) OR msg . timestamp > CurrentTime () OR Parents ( msg ) have not been scheduled activeNode [ nextID ] . deficit += mana [ nextID ] IF activeNode [ nextID ] . deficit > MAX_DEFICIT activeNode [ nextID ] . deficit = MAX_DEFICIT nextID ++ activeNode [ nextID ] . deficit -= Weight ( msg ) IF activeNode [ nextID ] . deficit < 0 activeNode [ nextID ] = 0 # remove scheduled message from queue Remove ( bufferQueue [ nextID ] . head ) # update list of active nodes IF Len ( bufferQueue [ nextID ] ) == 0 Remove ( activeNode [ nextID ] ) # update own rate setting IF pauseUpdates > 0 pauseUpdates -= 1 ELSE IF Len ( messageWorker ) > 0 RateSetting () Execute ( msg ) Pause ( SCHEDULING_RATE * WorkCalculator ( msg )) Implementation \u00b6 In this section, we describe the main architectural components used to handle the outbox queue, that is activeNode and bufferQueue . The scope of this section is to provide an insight on how to efficiently implement the above pseudocode. activeNode : it is a list which includes the node IDs of the nodes having at least one message in the outbox queue. Each node ID in the list points to its oldest message in the outbox buffer. bufferQueue : it is the actual outbox queue. It is possible to build overlapping virtual queues (indicated by colors in the figure) to represent different queues per node. This data structure has a limited fixed size MAX_BUFFER , and messages (in each queue) are sorted by timestamp. Other information about the hardware implementation of similar scheduling algorithms can be found at this link . Optional and future optimizations \u00b6 Synchronization \u00b6 When the network has a high level of congestion, it may be difficult for an out-of-sync node to synchronize as most of its scheduling rate is consumed by new messages. Hence, it is nice to have a mechanism allowing to schedule messages faster to catch up with the rest of the network under special conditions. Specifically, consider the following two scenarios: + Node is bootstrapping. + Node's syncStatus flag is set to FALSE (see Section 4.2 - Timestamp ). In either of these scenarios, the node is very far behind the rest of the newtork. In this case, we suggest to bypass the DRR scheduler, and schedule solid old messages in FIFO order at the largest possible rate the node can process. We repeat that this feature is optional: while it reduces the time needed to synchronize, it is not strictly needed for the correct functioning of the congestion control algorithm. Adaptive minimum access Mana \u00b6 Nodes must hold a sufficient amount of access Mana (larger than MIN_MANA ) to be able to successfully issue new messages. We are currently investigating a way to adapt this threshold over time, depending on the current traffic congestion of the network. Dynamic scheduling rate \u00b6 In the current proposal, the throughput is preset by the network manager. This value takes into account nodes\u2019 hardware as well as bandwidth capacity. Hardware improvement or protocol optimizations will not result in a performance improvement if the network manager does not change the throughput parameter SCHEDULING_RATE . We are currently investigating a way to dynamically adapt the throughput according to the network and protocol characteristics based on neighbors health state.","title":"4.6 Congestion control"},{"location":"IOTA-NECTAR/4.6%20Congestion%20Control/#46-congestion-control","text":"This specification provides a solution to deal with network congestion in the IOTA network. The congestion control algorithm described in this file decides which messages should be processed and gossiped to node's neighbors and in what order to do so.","title":"4.6 Congestion control"},{"location":"IOTA-NECTAR/4.6%20Congestion%20Control/#summary","text":"Every network has to deal with its intrinsic limited resources in terms of bandwidth and node capabilities (CPU and storage). In this document, we present a congestion control algorithm to regulate the influx of messages in the network with the goal of maximizing throughput (messages/bytes per second) and minimizing delays. Furthermore, the following requirements must be satisfied: Consistency . If a message is written by one honest node, it shall be written by all honest nodes within some delay bound. Fairness . Nodes can obtain a share of the available throughput depending on their access Mana. Throughput is shared in such a way that an attempt to increase the allocation of any node necessarily results in the decrease in the allocation of some other node with an equal or smaller allocation (max-min fairness). Security . Malicious nodes shall be unable to interfere with either of the above requirements. Further information can be found in our a paper Access Control for Distributed Ledgers in the Internet of Things: A Networking Approach .","title":"Summary"},{"location":"IOTA-NECTAR/4.6%20Congestion%20Control/#proposal","text":"In this specification, we present the congestion control algorithm that shall be implemented by all IOTA nodes. Nodes cannot take any advantage by not following the protocol. Conversely, they may eventually be considered as malicious nodes and banned. Our algorithm has three core components: * A scheduling algorithm which ensures fair access for all nodes according to their access Mana. * A TCP-inspired algorithm for decentralized rate setting to efficiently utilize the available bandwidth while preventing large delays. * A blacklisting policy to ban malicious nodes.","title":"Proposal"},{"location":"IOTA-NECTAR/4.6%20Congestion%20Control/#prerequirements","text":"Node identity . We require node accountability where each message is associated with the node ID of its issuing node (see Section 3.3 - Peer discovery ). Access mana . The congestion control module has knowledge of the access Mana of the nodes in the network in order to fairly share the available throughput. Without access Mana the network would be subject to Sybil attacks, which would incentivise even honest actors to artificially increase its own number of nodes (see Section 5.3 - Mana ). Timestamp . Before scheduling a new message, the scheduler verifies whether the message timestamp is valid or not. Message weight . Weight of a message is used to priority messages over the others and it is calculated depending on the type of message and of the message length, as described in Section 2.4 - Data Flow .","title":"Prerequirements"},{"location":"IOTA-NECTAR/4.6%20Congestion%20Control/#congestion-control-algorithm","text":"","title":"Congestion control algorithm"},{"location":"IOTA-NECTAR/4.6%20Congestion%20Control/#outbox-management","text":"Once the message has successfully passed the message parser checks and is solid, it is enqueued into the outbox for scheduling (see Section 2.4 - Data Flow ). The outbox is logically split into several queues, each one corresponding to a different node issuing messages. In this section, we describe the operations of message enqueuing (and dequeuing) into (from) the outbox. The enqueuing mechanism includes the following components: Classification . The mechanism identifies the queue where the message belongs to according to the node ID of the message issuer. Message enqueuing . The message is actually enqueued, queue is sorted by message timestamps in increasing order and counters are updated (e.g., counters for the total number of bytes in the queue). Message drop . In some circumstances, due to network congestion or to ongoing attacks, some messages shall be dropped to guarantee bounded delays and isolate attacker's messages. Specifically, a node shall drop messages in two situations: since buffers are of a limited size, if the total number of bytes in all queues exceeds a certain threshold, new incoming messages are dropped; to guarantee the security of the network, if a certain queue exceeds a given threshold, new incoming packets from that specific node ID will be dropped. The dequeue mechanism includes the following components: Queue selection . A queue is selected according to round robin scheduling algorithm. In particular, we use a modified version of the deficit round robin (DRR) algorithm, and we describe it in Section 3.4.2.2 - Scheduler. Message dequeuing . The first message of the queue is dequeued, and list of active nodes is updated. Scheduler management . Scheduler counters and pointers are updated.","title":"Outbox management"},{"location":"IOTA-NECTAR/4.6%20Congestion%20Control/#scheduler","text":"The most critical task is the scheduling algorithm which must guarantee that, for an honest node node , the following requirements will be met: * node 's messages will not accumulate indefinitely at any node (i.e., starvation is avoided), so the consistency requirement will be ensured. * node 's fair share (according to its access Mana) of the network resources are allocated to it, guaranteeing the fairness requirement. * Malicious nodes sending above their allowed rate will not interrupt node 's throughput, fulfilling the security requirement. We remind the reader that the above requirements are described in Section 3.4.1 - Summary. Although nodes in our setting are capable of more complex and customised behaviour than a typical router in a packet-switched network, our scheduler must still be lightweight and scalable due to the potentially large number of nodes requiring differentiated treatment. It is estimated that over 10,000 nodes operate on the Bitcoin network, and we expect that an even greater number of nodes are likely to be present in the IoT setting. For this reason, we adopt a scheduler based on Deficit Round Robin (DRR) (the Linux implementation of the FQ-CoDel packet scheduler , which is based on DRR, supports anywhere up to 65535 separate queues). The DRR scans all non-empty queues in sequence. When a non-empty queue is selected, its priority counter (called deficit ) is incremented by a certain value (called quantum ). Then, the value of the deficit counter is a maximal amount of bytes that can be sent at this turn: if the deficit counter is greater than the weight of the message at the head of the queue, this message can be scheduled and the value of the counter is decremented by this weight. In our implementation, the quantum is proportional to node's access Mana and we add a cap on the maximum deficit that a node can achieve to keep the network latency low. It is also important to mention that the weight of the message can be assigned in such a way that specific messages can be prioritized (low weight) or penalized (large weight); by default, in our mechanism the weight is proportional to the message size measured in bytes. The weight of a message is set by the function WorkCalculator() , and additional details can be found in Section 2.4 - Data Flow . Here a fundamental remark: the network manager sets up a desired maximum (fixed) rate SCHEDULING_RATE at which messages will be scheduled , computed in weight (see above) per second. This implies that every message is scheduled after a delay which is equal to the weight (size as default) of the latest scheduled message times the parameter SCHEDULING_RATE . This rate mostly depends on the degree of decentralization desired: e.g., a larger rate leads to higher throughput but would leave behind slower devices which will fall out of sync.","title":"Scheduler"},{"location":"IOTA-NECTAR/4.6%20Congestion%20Control/#rate-setting","text":"If all nodes always had messages to issue, i.e., if nodes were continuously willing to issue new messages, the problem of rate setting would be very straightforward: nodes could simply operate at a fixed, assured rate, sharing the total throughput according to the percentage of access Mana owned. The scheduling algorithm would ensure that this rate is enforceable, and that increasing delays or dropped messages are only experienced by misbehaving node. However, it is unrealistic that all nodes will always have messages to issue, and we would like nodes to better utilise network resources, without causing excessive congestion and violating any requirement. We propose a rate setting algorithm inspired by TCP \u2014 each node employs additive increase, multiplicative decrease (AIMD) rules to update their issuance rate in response to congestion events. In the case of distributed ledgers, all message traffic passes through all nodes, contrary to the case of traffic typically found in packet switched networks and other traditional network architectures. Under these conditions, local congestion at a node is all that is required to indicate congestion elsewhere in the network. This observation is crucial, as it presents an opportunity for a congestion control algorithm based entirely on local traffic. Our rate setting algorithm outlines the AIMD rules employed by each node to set their issuance rate. Rate updates for a node node take place each time a new message is scheduled if the node has a non-empty set of its own messages not yet scheduled. Node node sets its own local additive-increase variable localIncrease(node) based on its access Mana and on a global increase rate parameter RATE_SETTING_INCREASE . An appropriate choice of RATE_SETTING_INCREASE ensures a conservative global increase rate which does not cause problems even when many nodes increase their rate simultaneously. Nodes wait RATE_SETTING_PAUSE seconds after a global multiplicative decrease parameter RATE_SETTING_DECREASE , during which there are no further updates made, to allow the reduced rate to take effect and prevent multiple successive decreases. At each update, node checks how many of its own messages are in its outbox queue, and responds with a multiplicative decrease if this number is above a threshold, backoff(node) , which is proportional to node 's access Mana. If the number of node 's messages in the outbox is below the threshold, node 's issuance rate is incremented by its local increase variable localIncrease(node) .","title":"Rate setting"},{"location":"IOTA-NECTAR/4.6%20Congestion%20Control/#message-blocking-and-blacklisting","text":"If an incoming message made the outbox total buffer size to exceed its maximum capacity MAX_BUFFER , the same message would be dropped. In our analysis, we set buffers to be large enough to accommodate traffic from all honest nodes. Furthermore, to mitigate spamming actions from malicious nodes, we add an additional constraint: if node 's access Mana-scaled queue length (i.e., queue length divided by node's access Mana) exceeds a given threshold MAX_QUEUE , any new incoming packet from node will be dropped, hence the node is blacklisted. The attacker is blacklisted for a certain time BLACKLIST_TIME during which no messages issued by node can be added to the outbox. Please note that it is still possible to receive message from the attacker through solidification requests, which is important in order to guarantee the consistency requirement. Finally, when a node is blacklisted, the blacklister does not increase its own rate for a time RATE_SETTING_QUARANTINE , to avoid errors in the perception of the current congestion level.","title":"Message blocking and blacklisting"},{"location":"IOTA-NECTAR/4.6%20Congestion%20Control/#algorithmic-details","text":"","title":"Algorithmic details"},{"location":"IOTA-NECTAR/4.6%20Congestion%20Control/#protocol-parameters","text":"In line with the previous section, all nodes know the following global variables: int SCHEDULING_RATE : clock time interval between subsequent executions of the function Schedule() float RATE_SETTING_INCREASE : global additive increase parameter float RATE_SETTING_DECREASE : global multiplicative decrease parameter (larger than 1) int RATE_SETTING_PAUSE : waiting time before next ownID 's rate update after backoff int RATE_SETTING_QUARANTINE : waiting time before next ownID 's rate update after blacklisting int MAX_BUFFER : maximum buffer size (in bytes) float MAX_QUEUE : maximum access Mana-scaled inbox length float MAX_DEFICIT : maximum cap for accumulated deficit float MAX_RATE : maximum rate at which a node can be allowed to issue messages int MIN_MANA : minimum amount of Mana needed to issue messages int BLACKLIST_TIME : time interval during which no messages from blacklisted nodes are added to the outbox","title":"Protocol parameters"},{"location":"IOTA-NECTAR/4.6%20Congestion%20Control/#local-variables","text":"float ownRate : issuance rate of ownID according to the rate setter list activeNode : updated list of nodes having at least one message in the outbox queue (more details in Section 3.4.3.5 - Implementation) queue bufferQueue : actual outbox queue where messages are ready to be scheduled (more details in Section 3.4.3.5 - Implementation) nodeID nextID : pointer to the specific queue where next message can be scheduled from list mana : contains the up-to-date (at the time the vector is used) value of the access Mana given a certain nodeId . The way in which mana is updated is out of the scope of this spec, and further information can be found in Section 5.3 - Mana float backoff : local threshold for rate setting's backoff float localIncrease : local additive increase parameter list blacklisted : list of timestamps indicating if a specific nodeId is blacklisted. If node is not blacklisted, the entry is 0 int pauseUpdates : time interval during which rate setter is not updated list messageWorker : list of messages that ownNode issued but are still not part of the outbox","title":"Local variables"},{"location":"IOTA-NECTAR/4.6%20Congestion%20Control/#built-in-functions","text":"Len(x) : measures the length of a data structure x Append(x, y) : add a new element y to list x WorkCalculator(x) : provides the weight of message x Sort(x, y) : sort list x by metric y Parents(x) : gives the list of parents of a message x CurrentTime() : current time computed with the local clock Execute(x) : process and gossip message x Pause(x) : stop execution of a function for x time units","title":"Built-in functions"},{"location":"IOTA-NECTAR/4.6%20Congestion%20Control/#pseudocode","text":"The congestion control algorithm follows the solidification in the data flow: when a new message msg arrives to the scheduler, the function Enqueue(msg) will be triggered in order to properly add msg to the outbox. At the same time, at regular intervals (given by SCHEDULING_RATE times WorkCalculator(x) where x is the latest scheduled message), the function Schedule() picks a new message that has to be gossiped to neighbors and to be added to the local ledger. Simultaneously, RateSetting() adjusts the message generation rate of ownID according to the network congestion.","title":"Pseudocode"},{"location":"IOTA-NECTAR/4.6%20Congestion%20Control/#enqueuemsg","text":"The function Enqueue(msg) adds a new message msg into the outbox and updates the list of active nodes accordingly. The checks on blacklisting condition ( blacklisted[nodeID] == FALSE ) and buffer size ( Len(bufferQueue) < MAX_BUFFER ) may be moved to the parser checker for optimization purposes. ### upon arrival of a new message msg ( having passed solidification ) ### FUNCTION Enqueue ( msg ) nodeID = msg . nodeID IF mana [ nodeID ] > MIN_MANA AND ( blacklisted [ nodeId ] == 0 OR CurrentTime () - blacklisted [ nodeID ] > BLACKLIST_TIME ) blacklisted [ nodeId ] = 0 IF Len ( bufferQueue ) < MAX_BUFFER IF activeNode [ nodeID ] ! = NULL # other messages from nodeID are already in the queue nodeQueue = activeNode [ nodeID ] IF ( Len ( nodeQueue ) + Len ( msg )) / mana [ nodeID ] < MAX_QUEUE # append msg Append ( bufferQueue , msg ) Sort ( bufferQueue , timestamp ) ELSE # blacklist nodeID and pause rate setting updates blacklisted [ nodeID ] = CurrentTime () pauseUpdates = Max ( pauseUpdates , RATE_SETTING_QUARANTINE ) ELSE # no other messages for nodeID are present in the buffer Append ( activeNode , nodeID ) activeNode [ nodeID ] . deficit = MAX_DEFICIT Append ( bufferQueue , msg )","title":"Enqueue(msg)"},{"location":"IOTA-NECTAR/4.6%20Congestion%20Control/#ratesetting","text":"The function RateSetting() updates the rate ownRate at which messages can be issued by the node. The maximum value that ownRate can reach is MAX_RATE . At the bootstrap, the value of ownRate is initialized by the proportion of access Mana owned by the node times RATE_SETTING_INCREASE . FUNCTION RateSetting () # update issueing rate if no recent backoff IF ownRate < MAX_RATE # retrieve message queue of the same node IF Len ( bufferQueue [ ownID ] ) / mana [ ownID ] > backoff ownRate = ownRate / RATE_SETTING_DECREASE pauseUpdates = Max ( pauseUpdates , RATE_SETTING_PAUSE ) ELSE ownRate += RATE_SETTING_INCREASE * mana [ ownID ] / Sum ( mana )","title":"RateSetting()"},{"location":"IOTA-NECTAR/4.6%20Congestion%20Control/#schedule","text":"At regular intervals, i.e., every SCHEDULING_RATE times WorkCalculator(x) where x is the latest scheduled message, the function Schedule() selects the next message to gossip and process, if at least one message exists in bufferQueue . Otherwise, it returns NULL and the scheduling slot is missed. The local variable pauseUpdates is initialized to 0 . FUNCTION msg = Schedule () WHILE TRUE IF Len ( bufferQueue ) > 0 # msg represents the message in the outbox msg = bufferQueue [ nextID ] . head # point to a nodeId with enough deficit , having a valid message WHILE activeNode [ nextID ] . deficit < Weight ( msg ) OR msg . timestamp > CurrentTime () OR Parents ( msg ) have not been scheduled activeNode [ nextID ] . deficit += mana [ nextID ] IF activeNode [ nextID ] . deficit > MAX_DEFICIT activeNode [ nextID ] . deficit = MAX_DEFICIT nextID ++ activeNode [ nextID ] . deficit -= Weight ( msg ) IF activeNode [ nextID ] . deficit < 0 activeNode [ nextID ] = 0 # remove scheduled message from queue Remove ( bufferQueue [ nextID ] . head ) # update list of active nodes IF Len ( bufferQueue [ nextID ] ) == 0 Remove ( activeNode [ nextID ] ) # update own rate setting IF pauseUpdates > 0 pauseUpdates -= 1 ELSE IF Len ( messageWorker ) > 0 RateSetting () Execute ( msg ) Pause ( SCHEDULING_RATE * WorkCalculator ( msg ))","title":"Schedule()"},{"location":"IOTA-NECTAR/4.6%20Congestion%20Control/#implementation","text":"In this section, we describe the main architectural components used to handle the outbox queue, that is activeNode and bufferQueue . The scope of this section is to provide an insight on how to efficiently implement the above pseudocode. activeNode : it is a list which includes the node IDs of the nodes having at least one message in the outbox queue. Each node ID in the list points to its oldest message in the outbox buffer. bufferQueue : it is the actual outbox queue. It is possible to build overlapping virtual queues (indicated by colors in the figure) to represent different queues per node. This data structure has a limited fixed size MAX_BUFFER , and messages (in each queue) are sorted by timestamp. Other information about the hardware implementation of similar scheduling algorithms can be found at this link .","title":"Implementation"},{"location":"IOTA-NECTAR/4.6%20Congestion%20Control/#optional-and-future-optimizations","text":"","title":"Optional and future optimizations"},{"location":"IOTA-NECTAR/4.6%20Congestion%20Control/#synchronization","text":"When the network has a high level of congestion, it may be difficult for an out-of-sync node to synchronize as most of its scheduling rate is consumed by new messages. Hence, it is nice to have a mechanism allowing to schedule messages faster to catch up with the rest of the network under special conditions. Specifically, consider the following two scenarios: + Node is bootstrapping. + Node's syncStatus flag is set to FALSE (see Section 4.2 - Timestamp ). In either of these scenarios, the node is very far behind the rest of the newtork. In this case, we suggest to bypass the DRR scheduler, and schedule solid old messages in FIFO order at the largest possible rate the node can process. We repeat that this feature is optional: while it reduces the time needed to synchronize, it is not strictly needed for the correct functioning of the congestion control algorithm.","title":"Synchronization"},{"location":"IOTA-NECTAR/4.6%20Congestion%20Control/#adaptive-minimum-access-mana","text":"Nodes must hold a sufficient amount of access Mana (larger than MIN_MANA ) to be able to successfully issue new messages. We are currently investigating a way to adapt this threshold over time, depending on the current traffic congestion of the network.","title":"Adaptive minimum access Mana"},{"location":"IOTA-NECTAR/4.6%20Congestion%20Control/#dynamic-scheduling-rate","text":"In the current proposal, the throughput is preset by the network manager. This value takes into account nodes\u2019 hardware as well as bandwidth capacity. Hardware improvement or protocol optimizations will not result in a performance improvement if the network manager does not change the throughput parameter SCHEDULING_RATE . We are currently investigating a way to dynamically adapt the throughput according to the network and protocol characteristics based on neighbors health state.","title":"Dynamic scheduling rate"},{"location":"IOTA-NECTAR/4.7%20Markers/","text":"4.7 Markers \u00b6 4.7.1 Introduction \u00b6 This section specifies the requirements for the marker tool. A tool as defined here is a feature that adds functionality to the node software but is not an essential component. The marker tool improves the efficiency with which certain properties can be checked or certain metrics calculated. The potential issues addressed by the use of the marker tool are in handling potentially numerically expensive operations. Specifically, the following operations can become numerically expensive: Future- or past cone inclusion . For certain applications it is necessary to know whether a certain message is in the past or future cone of another message. In the default approach the Tangle has to be walked until a given message is found. Approval weight . In order to compute the approval weight of a given message the node software needs to traverse the Tangle from that message to the tips and sum up the active consensus Mana of all the messages in its future cone, see also the section on approval weight . The marker tool allows a node to efficiently determine whether certain markers are in the past or future cone of a given message, by reducing the proportion of the Tangle that needs to be traversed. The marker tool achieves this by defining a parallel internal data structure, consisting of additional metadata applied to specific messages in the Tangle. Specifically, the marker tool \"marks\" certain messages, which form a subDAG which approximates the topological structure of the Tangle. Furthermore, the markers are grouped into sequences (which themselves form yet another DAG), which allow the node to quickly determine which markers reference each other. Note, that we shall require that markers are assigned when booking a message. Thus, for that part of the message DAG that is already booked the corresponding marker DAG does not change anymore. 4.7.2 Definitions \u00b6 The following terms are defined in relation to markers: * UTXO branch: This is a set of outputs that spawn off from a conflict transaction. Each UTXO branch by itself is conflict free. See also Section 5.1 - UTXO and Section 5.2 - Ledger State for a more complete discussion on UTXO and its branches. * Aggregated branch: The aggregation of a combination of several branches. * Branch identifier ( BID ): The unique identifier of a branch or aggregated branch. * Main branch: The part of the UTXO DAG, in which all outputs are considered to be good in the sense that all conflicts in their past have been resolved, either by a given conflict being accepted or rejected. * Rank: The length of the longest directed path in DAG terminating in a given vertex/object. Specifically, if a vertex \\(A\\) directly references only \\(B\\) and \\(C\\) then \\(rank(A)=max(rank(B),rank(C))+1\\) . * Marker: A message that is assigned additional properties locally on the node, and that tracks a particular UTXO branch. * Marker identifier ( MID ): The unique identifier of the marker. * Marker DAG: The collection of all markers. * Marker rank ( MR ): The rank of a marker in the marker DAG. * Marker-sequence: A marker-sequence is a group of markers. Each marker-sequence maps to a UTXO branch; see Section 5.2 - Ledger State . * Marker-sequence identifier ( SID ): A marker-sequence identifier is a number that uniquely identifies a marker-sequence. * Marker-sequence rank ( SR ): The rank of a marker-sequence in the marker-sequence DAG. * Future marker ( FM ): This field in the message metadata is (potentially) updated when a new marker is generated in the future cone of the message, following the rules defined in Section \"Message Metadata\". Essentially it contains the list of markers for which there is no other marker between the marker in question and the message, or in more mathematical terms, the minimal markers in the future cone. * Past marker ( PM ): A past marker of a message is a most recent past marker of the parents (with respect to MR ). The past marker of a marker is set to itself. 4.7.3 The markers \u00b6 A marker consists of the following data: 4.7.3.1 Marker data \u00b6 Variable Type Description MID uint64 Unique identifier of the marker SID uint64 Unique identifier of the marker-sequence MR uint64 Marker rank A new marker shall be created by the marker tool when any of the following conditions are met: * a new UTXO branch is created and the message that would get a marker assigned is not yet booked. This also creates a new marker-sequence. * more than a certain number of messages ( maxMsgPerMarker ) have been received since the last marker. This rule must be applied per marker-sequence. I.e. for each marker-sequence with more than maxMsgPerMarker since the last marker in that marker-sequence, the rule shall be applied independently. * a certain time window ( maxTimePerMarker ) has passed since the last marker. A marker is created with a MID , an this MID must be unique. To set a new marker within a marker-sequence, the marker tool randomly selects from strong tips set a message whose past marker is the last marker in the sequence. The next marker will then reference that transaction. If there is no strong tip with the appropriate past marker, the selection shall be from message in the weak tips set. The rank of the new marker should be one greater than the rank of all the past markers of the message. Since \\(\\texttt{MR}(x)=1+\\max \\limits_{y: x\\text{ references }y}\\texttt{MR}(y)\\) , marker ranks are monotonically non-decreasing such that \\(\\forall x \\in fc(y) \\Rightarrow \\texttt{MR}_x > \\texttt{MR}_y\\) , where \\(fc(y)\\) is the future cone of \\(y\\) . 4.7.4 The marker-sequence \u00b6 Marker-sequences are used to track the UTXO DAG branches. Each branch corresponds to a marker-sequence with a unique SID , and the marker-sequences form a DAG. 4.7.4.1 Marker-sequence data \u00b6 Each marker-sequence is associated with the following data: Variable Type Description SID unit64 The marker-sequence identifier SR unit64 The rank of a marker-sequence in the marker-sequence DAG MRMax unit64 The highest MR in the marker-sequence MRMin unit64 The lowest MR in the marker-sequence ParentReferences map[ Marker ] Marker Relationship map from parent marker-sequences to markers (*) *The field ParentReferences models the relationship between marker-sequences. This maps which marker in this marker-sequence references which other markers from other marker-sequences. Whenever a new marker is added that is a member of a given marker-sequence, MR_max and ParentReferences for that marker-sequence shall be updated. 4.7.4.2 Creation of marker-sequences \u00b6 A new marker-sequence shall be created when: 1. there's a transaction that creates a new conflict, i.e. creates a new UTXO branch. 2. the UTXO branches are aggregated. 3. UTXO branches are merged. Each new marker-sequence shall start with a new marker. Hence, with the creation of a new marker-sequence also a new marker must be assigned to the message that caused one of the three above events. Whenever a new marker-sequence is created, the marker tool shall assign: - a new SID , created by the rule \\(\\mbox{new }\\texttt{SID}=1+\\mbox{last } \\texttt{SID}\\) . A new created SID must be unique. - a new \\(\\texttt{SR}=1+max(\\text{referenced }\\texttt{SR})\\) . To prevent assigning a new SID when combining the same marker-sequences at different times, the marker tool shall build parent-child relationships in a map whenever a new marker-sequence is created. For further details about the UTXO model, please refer to the section on UTXO . 4.7.5 Message Metadata \u00b6 For each message in the Tangle, the marker tool shall maintain metadata that provides information about the markers that are closest in the past or future cone of that message, as well as whether the message itself is a marker and what rank the message has. The following message metadata shall be defined in the marker tool to support that requirement: Variable Type Description IsMarker bool A flag to indicate whether a message is a marker. PastMarkers map[ SID ] MID A list of the closest markers from different marker-sequences in the past cone of the message. FutureMarkers map[ SID ] MID A list of the closest markers from different marker-sequences in the future cone of the message. MarkerBranchID BID The branch ID to which the marker is mapped, or nil if the message is no marker. PayloadBranchID BID The branch ID to which the Payload is mapped in case it is a conflict, or nil otherwise. IndividualBranchID BID The branch ID if there is need for mapping the message individually to a branch ID, or nil otherwise. The PastMarkers field contains * only the marker identifier of itself, if the message is marked as a marker. * the marker identifier of its closest past markers (PMs), i.e. from each referenced marker-sequence only the markers with the highest marker rank ( MR ). Markers which are referenced by other markers in this list shall be removed. The FutureMarkers list shall be empty at the start and shall be updated when a new marker directly or indirectly references that list. The propagation of a FM to its past cone (i.e. the update of the FutureMarkers list in the encountered messages) shall not continue beyond a message if: FutureMarkers of a message includes a previous marker of the same marker-sequence; the message that includes such a marker shall not get updated. the message is the marker in a different marker-sequence. Then the FutureMarkers shall be updated for that marker only. Through this approach past and future markers do not cross weak parents. It also prevents the lists from growing unboundedly. The fields MarkerBranchID , PayloadBranchID and IndividualBranchID allow for making connections between the marker DAG, the message DAG and the UTXO branch DAG. When a new Sequence is created the MarkerBranchID is set to the branch that creates the sequence. 4.7.5.1 Update of already booked messages on double spends \u00b6 If a transaction arrives that double spends an already booked transaction, a new marker-sequence shall be created for the newly arrived message (containing the transaction), see Section Creation of marker-sequences . For the already booked conflicting transaction no new marker or marker Sequence shall be created. This is because the marker DAG and Sequence DAG shall not be changed post-booking a message. However a new UTXO branch is created. First, assume the existing booked transaction is a Marker itself. Then the marker gets mapped onto the new branch by updating the field MarkerBranchID in the message metadata. Furthermore, the PayloadBranchID is updated to the new branch. For all FM in the same sequence the MarkerBranchID gets updated to the new branch. Furthermore, for every sequence that directly or indirectly references the sequence in which the double-spend occurs, the first marker is remapped to the new branch as well. Second, assume the existing transaction is not a marker. Then all messages between the transaction and the following future markers (including the transaction itself) get mapped individually to the new branch mapping using the field IndividualBranchID . From the future markers onwards, the same applies as in the first scenario. For an example implementation of these scenarios also visit the example here . 4.7.6 Marker Application Description \u00b6 Figure 1 shows an example of how the markers and marker-sequences (here also called Sequence) would look in the Tangle from the perspective of the Message DAG, the marker DAG and the marker-sequence DAG. The purple colored messages are markers: Figure 1: Markers and marker-sequences in the Tangle 4.7.6.1 Example Implementation \u00b6 An illustrative example of the markers tool in action is provided here for the prototype implementation. 4.7.6.2 Approval weight approximation \u00b6 To approximate the approval weight of a message, the markers tool retrieves the approval weight of FutureMarkers . Since a given message is in the past cone of its FMs, the approval weight and thus the finality of the message will be at least the same as the maximum weight of its FMs. This gives a lower bound (which is the \u201csafe\u201d bound), and if the markers are set frequently enough, this provides a good approximation of that bound. 4.7.6.3 Past cone check \u00b6 By comparing the PastMarkers of a message with the FutureMarkers of another message, the markers tool can determine if that message is in the past cone of the other. For example, consider two messages X and Y that are members in the same marker-sequence. Then if PM(X)>FM(Y) , then X is in the future of Y . One way in which this check can be carried out is by traversing the marker DAG while remaining in the bounds of the marker ranks. A potential optimization is that the marker-sequence DAG can be traversed while considering the marker-sequence ranks, prior to any traversal of the marker DAG. It is possible that the marker DAG does not cover certain areas of the message DAG at a given point in time. In this case, a check on this question can return one of the following three values: TRUE FALSE N/A If the check returns a N/A , then the Message DAG must be searched via a search algorithm. For an example implementation of the algorithm for the past cone check visit GoShimmer markers .","title":"4.7 Markers"},{"location":"IOTA-NECTAR/4.7%20Markers/#47-markers","text":"","title":"4.7 Markers"},{"location":"IOTA-NECTAR/4.7%20Markers/#471-introduction","text":"This section specifies the requirements for the marker tool. A tool as defined here is a feature that adds functionality to the node software but is not an essential component. The marker tool improves the efficiency with which certain properties can be checked or certain metrics calculated. The potential issues addressed by the use of the marker tool are in handling potentially numerically expensive operations. Specifically, the following operations can become numerically expensive: Future- or past cone inclusion . For certain applications it is necessary to know whether a certain message is in the past or future cone of another message. In the default approach the Tangle has to be walked until a given message is found. Approval weight . In order to compute the approval weight of a given message the node software needs to traverse the Tangle from that message to the tips and sum up the active consensus Mana of all the messages in its future cone, see also the section on approval weight . The marker tool allows a node to efficiently determine whether certain markers are in the past or future cone of a given message, by reducing the proportion of the Tangle that needs to be traversed. The marker tool achieves this by defining a parallel internal data structure, consisting of additional metadata applied to specific messages in the Tangle. Specifically, the marker tool \"marks\" certain messages, which form a subDAG which approximates the topological structure of the Tangle. Furthermore, the markers are grouped into sequences (which themselves form yet another DAG), which allow the node to quickly determine which markers reference each other. Note, that we shall require that markers are assigned when booking a message. Thus, for that part of the message DAG that is already booked the corresponding marker DAG does not change anymore.","title":"4.7.1 Introduction"},{"location":"IOTA-NECTAR/4.7%20Markers/#472-definitions","text":"The following terms are defined in relation to markers: * UTXO branch: This is a set of outputs that spawn off from a conflict transaction. Each UTXO branch by itself is conflict free. See also Section 5.1 - UTXO and Section 5.2 - Ledger State for a more complete discussion on UTXO and its branches. * Aggregated branch: The aggregation of a combination of several branches. * Branch identifier ( BID ): The unique identifier of a branch or aggregated branch. * Main branch: The part of the UTXO DAG, in which all outputs are considered to be good in the sense that all conflicts in their past have been resolved, either by a given conflict being accepted or rejected. * Rank: The length of the longest directed path in DAG terminating in a given vertex/object. Specifically, if a vertex \\(A\\) directly references only \\(B\\) and \\(C\\) then \\(rank(A)=max(rank(B),rank(C))+1\\) . * Marker: A message that is assigned additional properties locally on the node, and that tracks a particular UTXO branch. * Marker identifier ( MID ): The unique identifier of the marker. * Marker DAG: The collection of all markers. * Marker rank ( MR ): The rank of a marker in the marker DAG. * Marker-sequence: A marker-sequence is a group of markers. Each marker-sequence maps to a UTXO branch; see Section 5.2 - Ledger State . * Marker-sequence identifier ( SID ): A marker-sequence identifier is a number that uniquely identifies a marker-sequence. * Marker-sequence rank ( SR ): The rank of a marker-sequence in the marker-sequence DAG. * Future marker ( FM ): This field in the message metadata is (potentially) updated when a new marker is generated in the future cone of the message, following the rules defined in Section \"Message Metadata\". Essentially it contains the list of markers for which there is no other marker between the marker in question and the message, or in more mathematical terms, the minimal markers in the future cone. * Past marker ( PM ): A past marker of a message is a most recent past marker of the parents (with respect to MR ). The past marker of a marker is set to itself.","title":"4.7.2 Definitions"},{"location":"IOTA-NECTAR/4.7%20Markers/#473-the-markers","text":"A marker consists of the following data:","title":"4.7.3 The markers"},{"location":"IOTA-NECTAR/4.7%20Markers/#4731-marker-data","text":"Variable Type Description MID uint64 Unique identifier of the marker SID uint64 Unique identifier of the marker-sequence MR uint64 Marker rank A new marker shall be created by the marker tool when any of the following conditions are met: * a new UTXO branch is created and the message that would get a marker assigned is not yet booked. This also creates a new marker-sequence. * more than a certain number of messages ( maxMsgPerMarker ) have been received since the last marker. This rule must be applied per marker-sequence. I.e. for each marker-sequence with more than maxMsgPerMarker since the last marker in that marker-sequence, the rule shall be applied independently. * a certain time window ( maxTimePerMarker ) has passed since the last marker. A marker is created with a MID , an this MID must be unique. To set a new marker within a marker-sequence, the marker tool randomly selects from strong tips set a message whose past marker is the last marker in the sequence. The next marker will then reference that transaction. If there is no strong tip with the appropriate past marker, the selection shall be from message in the weak tips set. The rank of the new marker should be one greater than the rank of all the past markers of the message. Since \\(\\texttt{MR}(x)=1+\\max \\limits_{y: x\\text{ references }y}\\texttt{MR}(y)\\) , marker ranks are monotonically non-decreasing such that \\(\\forall x \\in fc(y) \\Rightarrow \\texttt{MR}_x > \\texttt{MR}_y\\) , where \\(fc(y)\\) is the future cone of \\(y\\) .","title":"4.7.3.1 Marker data"},{"location":"IOTA-NECTAR/4.7%20Markers/#474-the-marker-sequence","text":"Marker-sequences are used to track the UTXO DAG branches. Each branch corresponds to a marker-sequence with a unique SID , and the marker-sequences form a DAG.","title":"4.7.4 The marker-sequence"},{"location":"IOTA-NECTAR/4.7%20Markers/#4741-marker-sequence-data","text":"Each marker-sequence is associated with the following data: Variable Type Description SID unit64 The marker-sequence identifier SR unit64 The rank of a marker-sequence in the marker-sequence DAG MRMax unit64 The highest MR in the marker-sequence MRMin unit64 The lowest MR in the marker-sequence ParentReferences map[ Marker ] Marker Relationship map from parent marker-sequences to markers (*) *The field ParentReferences models the relationship between marker-sequences. This maps which marker in this marker-sequence references which other markers from other marker-sequences. Whenever a new marker is added that is a member of a given marker-sequence, MR_max and ParentReferences for that marker-sequence shall be updated.","title":"4.7.4.1 Marker-sequence data"},{"location":"IOTA-NECTAR/4.7%20Markers/#4742-creation-of-marker-sequences","text":"A new marker-sequence shall be created when: 1. there's a transaction that creates a new conflict, i.e. creates a new UTXO branch. 2. the UTXO branches are aggregated. 3. UTXO branches are merged. Each new marker-sequence shall start with a new marker. Hence, with the creation of a new marker-sequence also a new marker must be assigned to the message that caused one of the three above events. Whenever a new marker-sequence is created, the marker tool shall assign: - a new SID , created by the rule \\(\\mbox{new }\\texttt{SID}=1+\\mbox{last } \\texttt{SID}\\) . A new created SID must be unique. - a new \\(\\texttt{SR}=1+max(\\text{referenced }\\texttt{SR})\\) . To prevent assigning a new SID when combining the same marker-sequences at different times, the marker tool shall build parent-child relationships in a map whenever a new marker-sequence is created. For further details about the UTXO model, please refer to the section on UTXO .","title":"4.7.4.2 Creation of marker-sequences"},{"location":"IOTA-NECTAR/4.7%20Markers/#475-message-metadata","text":"For each message in the Tangle, the marker tool shall maintain metadata that provides information about the markers that are closest in the past or future cone of that message, as well as whether the message itself is a marker and what rank the message has. The following message metadata shall be defined in the marker tool to support that requirement: Variable Type Description IsMarker bool A flag to indicate whether a message is a marker. PastMarkers map[ SID ] MID A list of the closest markers from different marker-sequences in the past cone of the message. FutureMarkers map[ SID ] MID A list of the closest markers from different marker-sequences in the future cone of the message. MarkerBranchID BID The branch ID to which the marker is mapped, or nil if the message is no marker. PayloadBranchID BID The branch ID to which the Payload is mapped in case it is a conflict, or nil otherwise. IndividualBranchID BID The branch ID if there is need for mapping the message individually to a branch ID, or nil otherwise. The PastMarkers field contains * only the marker identifier of itself, if the message is marked as a marker. * the marker identifier of its closest past markers (PMs), i.e. from each referenced marker-sequence only the markers with the highest marker rank ( MR ). Markers which are referenced by other markers in this list shall be removed. The FutureMarkers list shall be empty at the start and shall be updated when a new marker directly or indirectly references that list. The propagation of a FM to its past cone (i.e. the update of the FutureMarkers list in the encountered messages) shall not continue beyond a message if: FutureMarkers of a message includes a previous marker of the same marker-sequence; the message that includes such a marker shall not get updated. the message is the marker in a different marker-sequence. Then the FutureMarkers shall be updated for that marker only. Through this approach past and future markers do not cross weak parents. It also prevents the lists from growing unboundedly. The fields MarkerBranchID , PayloadBranchID and IndividualBranchID allow for making connections between the marker DAG, the message DAG and the UTXO branch DAG. When a new Sequence is created the MarkerBranchID is set to the branch that creates the sequence.","title":"4.7.5 Message Metadata"},{"location":"IOTA-NECTAR/4.7%20Markers/#4751-update-of-already-booked-messages-on-double-spends","text":"If a transaction arrives that double spends an already booked transaction, a new marker-sequence shall be created for the newly arrived message (containing the transaction), see Section Creation of marker-sequences . For the already booked conflicting transaction no new marker or marker Sequence shall be created. This is because the marker DAG and Sequence DAG shall not be changed post-booking a message. However a new UTXO branch is created. First, assume the existing booked transaction is a Marker itself. Then the marker gets mapped onto the new branch by updating the field MarkerBranchID in the message metadata. Furthermore, the PayloadBranchID is updated to the new branch. For all FM in the same sequence the MarkerBranchID gets updated to the new branch. Furthermore, for every sequence that directly or indirectly references the sequence in which the double-spend occurs, the first marker is remapped to the new branch as well. Second, assume the existing transaction is not a marker. Then all messages between the transaction and the following future markers (including the transaction itself) get mapped individually to the new branch mapping using the field IndividualBranchID . From the future markers onwards, the same applies as in the first scenario. For an example implementation of these scenarios also visit the example here .","title":"4.7.5.1 Update of already booked messages on double spends"},{"location":"IOTA-NECTAR/4.7%20Markers/#476-marker-application-description","text":"Figure 1 shows an example of how the markers and marker-sequences (here also called Sequence) would look in the Tangle from the perspective of the Message DAG, the marker DAG and the marker-sequence DAG. The purple colored messages are markers: Figure 1: Markers and marker-sequences in the Tangle","title":"4.7.6 Marker Application Description"},{"location":"IOTA-NECTAR/4.7%20Markers/#4761-example-implementation","text":"An illustrative example of the markers tool in action is provided here for the prototype implementation.","title":"4.7.6.1 Example Implementation"},{"location":"IOTA-NECTAR/4.7%20Markers/#4762-approval-weight-approximation","text":"To approximate the approval weight of a message, the markers tool retrieves the approval weight of FutureMarkers . Since a given message is in the past cone of its FMs, the approval weight and thus the finality of the message will be at least the same as the maximum weight of its FMs. This gives a lower bound (which is the \u201csafe\u201d bound), and if the markers are set frequently enough, this provides a good approximation of that bound.","title":"4.7.6.2 Approval weight approximation"},{"location":"IOTA-NECTAR/4.7%20Markers/#4763-past-cone-check","text":"By comparing the PastMarkers of a message with the FutureMarkers of another message, the markers tool can determine if that message is in the past cone of the other. For example, consider two messages X and Y that are members in the same marker-sequence. Then if PM(X)>FM(Y) , then X is in the future of Y . One way in which this check can be carried out is by traversing the marker DAG while remaining in the bounds of the marker ranks. A potential optimization is that the marker-sequence DAG can be traversed while considering the marker-sequence ranks, prior to any traversal of the marker DAG. It is possible that the marker DAG does not cover certain areas of the message DAG at a given point in time. In this case, a check on this question can return one of the following three values: TRUE FALSE N/A If the check returns a N/A , then the Message DAG must be searched via a search algorithm. For an example implementation of the algorithm for the past cone check visit GoShimmer markers .","title":"4.7.6.3 Past cone check"},{"location":"IOTA-NECTAR/5.1%20UTXO/","text":"UTXO model \u00b6 The unspent transaction output (UTXO) model defines a ledger state where balances are not directly associated with addresses but with the outputs of transactions. In this model, transactions specify the outputs of previous transactions as inputs, which are consumed in order to create new outputs. A transaction must consume the entirety of the specified inputs. The section unlocking the inputs is called an unlock block . An unlock block may contain a signature proving ownership of a given input's address and/or other unlock criteria. The following image depicts the flow of funds using UTXO: Transaction Layout \u00b6 A Transaction payload is made up of two parts: 1. The Transaction Essence part contains: version, timestamp, nodeID of the aMana pledge, nodeID of the cMana pledge, inputs, outputs and an optional data payload. 2. The Unlock Blocks which unlock the Transaction Essence 's inputs. In case the unlock block contains a signature, it signs the entire Transaction Essence part. All values are serialized in little-endian encoding (it stores the most significant byte of a word at the largest address and the smallest byte at the smallest address). The serialized form of the transaction is deterministic, meaning the same logical transaction always results in the same serialized byte sequence. The table describing the entirety of a Transaction 's serialized form is presented in the Section 2.3 Standard Payloads Layout . See Message Layout for understanding the table schema. Transaction Essence \u00b6 The Transaction Essence of a Transaction carries a version, timestamp, nodeID of the aMana pledge, nodeID of the cMana pledge, inputs, outputs and an optional data payload. Inputs \u00b6 The Inputs part holds the inputs to consume, that in turn fund the outputs of the Transaction Essence . There is only one supported type of input as of now, the UTXO Input . In the future, more types of inputs may be specified as part of protocol upgrades. Each defined input must be accompanied by a corresponding Unlock Block at the same index in the Unlock Blocks part of the Transaction . If multiple inputs may be unlocked through the same Unlock Block , the given Unlock Block only needs to be specified at the index of the first input that gets unlocked by it. Subsequent inputs that are unlocked through the same data must have a Reference Unlock Block pointing to the previous Unlock Block . This ensures that no duplicate data needs to occur in the same transaction. UTXO Input \u00b6 Name Type Description Input Type uint8 Set to value 0 to denote an UTXO Input . Transaction ID ByteArray[32] The BLAKE2b-256 hash of the transaction from which the UTXO comes from. Transaction Output Index uint16 The index of the output on the referenced transaction to consume. A UTXO Input is an input which references an output of a previous transaction by using the given transaction's BLAKE2b-256 hash + the index of the output on that transaction. A UTXO Input must be accompanied by an Unlock Block for the corresponding type of output the UTXO Input is referencing. Example: If the input references outputs to an Ed25519 address, then the corresponding unlock block must be of type Signature Unlock Block holding an Ed25519 signature. Outputs \u00b6 The Outputs part holds the outputs to create with this Transaction Payload . There are different types of output: * SigLockedSingleOutput * SigLockedAssetOutput SigLockedSingleOutput \u00b6 Name Type Description Output Type uint8 Set to value 0 to denote a SigLockedSingleOutput . Address oneOf Ed25519 Address Name Type Description Address Type uint8 Set to value 0 to denote an Ed25519 Address . Address ByteArray[32] The raw bytes of the Ed25519 address which is a BLAKE2b-256 hash of the Ed25519 public key. BLS Address Name Type Description Address Type uint8 Set to value 1 to denote a BLS Address . Address ByteArray[49] The raw bytes of the BLS address which is a BLAKE2b-256 hash of the BLS public key. Balance uint64 The balance of IOTA tokens to deposit with this SigLockedSingleOutput output. The SigLockedSingleOutput defines an output holding an IOTA balance linked to a single address; it is unlocked via a valid signature proving ownership over the given address. Such output may hold an address of different types. SigLockedAssetOutput \u00b6 Name Type Description Output Type uint8 Set to value 1 to denote a SigLockedAssetOutput . Address oneOf Ed25519 Address Name Type Description Address Type uint8 Set to value 0 to denote an Ed25519 Address . Address ByteArray[32] The raw bytes of the Ed25519 address which is a BLAKE2b-256 hash of the Ed25519 public key. BLS Address Name Type Description Address Type uint8 Set to value 1 to denote a BLS Address . Address ByteArray[49] The raw bytes of the BLS address which is a BLAKE2b-256 hash of the BLS public key. Balances count uint32 The number of individual balances. AssetBalance anyOf Asset Balance The balance of the tokenized asset. Name Type Description AssetID ByteArray[32] The ID of the tokenized asset Balance uint64 The balance of the tokenized asset. The SigLockedAssetOutput defines an output holding a balance for each specified tokenized asset linked to a single address; it is unlocked via a valid signature proving ownership over the given address. Such output may hold an address of different types. The ID of any tokenized asset is defined by the BLAKE2b-256 hash of the OutputID that created the asset. Payload \u00b6 The payload part of a Transaction Essence may hold an optional payload. This payload does not affect the validity of the Transaction Essence . If the transaction is not valid, then the payload shall be discarded. Unlock Blocks \u00b6 The Unlock Blocks part holds the unlock blocks unlocking inputs within a Transaction Essence . There are different types of Unlock Blocks : Name Unlock Type Description Signature Unlock Block 0 An unlock block holding one or more signatures unlocking one or more inputs. Reference Unlock Block 1 An unlock block which must reference a previous unlock block which unlocks also the input at the same index as this Reference Unlock Block . Signature Unlock Block \u00b6 Name Type Description Unlock Type uint8 Set to value 0 to denote a Signature Unlock Block . Signature oneOf BLS Signature Name Type Description Signature Type uint8 Set to value 0 to denote a BLS Signature . Signature ByteArray The signature signing the serialized Transaction Essence . Ed25519 Signature Name Type Description Signature Type uint8 Set to value 1 to denote an Ed25519 Signature . Public key ByteArray[32] The public key of the Ed25519 keypair which is used to verify the signature. Signature ByteArray[64] The signature signing the serialized Transaction Essence . A Signature Unlock Block defines an Unlock Block which holds one or more signatures unlocking one or more inputs. Such a block signs the entire Transaction Essence part of a Transaction Payload including the optional payload. Reference Unlock block \u00b6 Name Type Description Unlock Type uint8 Set to value 1 to denote a Reference Unlock Block . Reference uint16 Represents the index of a previous unlock block. A Reference Unlock Block defines an Unlock Block that references a previous Unlock Block (that must not be another Reference Unlock Block ). It must be used if multiple inputs can be unlocked through the same origin Unlock Block . Example: Consider a Transaction Essence containing UTXO Inputs A, B and C, where A and C are both spending the UTXOs originating from the same Ed25519 address. The Unlock Block part must thereby have the following structure: Index Must Contain 0 A Signature Unlock Block holding the corresponding Ed25519 signature to unlock A and C. 1 A Signature Unlock Block that unlocks B. 2 A Reference Unlock Block that references index 0, since C also gets unlocked by the same signature as A. Validation \u00b6 A Transaction payload has different validation stages since some validation steps can only be executed at the point when certain information has (or has not) been received. We, therefore, distinguish between syntactical and semantic validation. Transaction Syntactical Validation \u00b6 This validation can commence as soon as the transaction data has been received in its entirety. It validates the structure but not the signatures of the transaction. A transaction must be discarded right away if it does not pass this stage. The following criteria define whether the transaction passes the syntactical validation: * Transaction Essence: * Transaction Essence Version value must be 0. * The timestamp of the Transaction Essence must be older than (or equal to) the timestamp of the message containing the transaction by at most 10 minutes. * A Transaction Essence must contain at least one input and output. * Inputs: * Inputs Count must be 0 < x < 128. * At least one input must be specified. * Input Type value must be 0, denoting an UTXO Input . * UTXO Input : * Transaction Output Index must be 0 \u2264 x < 128. * Every combination of Transaction ID + Transaction Output Index must be unique in the inputs set. * Inputs must be in lexicographical order of their serialized form. 1 * Outputs: * Outputs Count must be 0 < x < 128. * At least one output must be specified. * Output Type must be 0, denoting a SigLockedSingleOutput . * SigLockedSingleOutput : * Address Type must either be 0 or 1, denoting an Ed25519 - or BLS address . * The Address must be unique in the set of SigLockedSingleOutputs . * Amount must be > 0. * Outputs must be in lexicographical order by their serialized form. 1 * Accumulated output balance must not exceed the total supply of tokens 2,779,530,283,277,761 . * Payload Length must be 0 (to indicate that there's no payload) or be valid for the specified payload type. * Payload Type must be one of the supported payload types if Payload Length is not 0. * Unlock Blocks Count must match the number of inputs. Must be 0 < x < 128. * Unlock Block Type must either be 0 or 1, denoting a Signature Unlock Block or Reference Unlock block . * Signature Unlock Blocks must define either an Ed25519 - or BLS Signature . * A Signature Unlock Block unlocking multiple inputs must only appear once (be unique) and be positioned at the same index of the first input it unlocks. All other inputs unlocked by the same Signature Unlock Block must have a companion Reference Unlock Block at the same index as the corresponding input that points to the origin Signature Unlock Block . * Reference Unlock Blocks must specify a previous Unlock Block that is not of type Reference Unlock Block . The referenced index must therefore be smaller than the index of the Reference Unlock Block . * Given the type and length information, the Transaction must consume the entire byte array the Payload Length field in the Message defines. 1 ensures that serialization of the transaction becomes deterministic, meaning that libraries always produce the same bytes given the logical transaction. Transaction Semantic Validation \u00b6 The following criteria define whether the transaction passes the semantic validation: 1. All the UTXOs the transaction references are known (booked) and unspent. 1. The transaction is spending the entirety of the funds of the referenced UTXOs to the outputs. 1. The address type of the referenced UTXO must match the signature type contained in the corresponding Signature Unlock Block . 1. The Signature Unlock Blocks are valid, i.e. the signatures prove ownership over the addresses of the referenced UTXOs. If a transaction passes the semantic validation, its referenced UTXOs shall be marked as spent and the corresponding new outputs shall be booked/specified in the ledger. This process is described in Section 5.2 - Ledger state . Transactions that do not pass semantic validation shall be discarded. Their UTXOs are not marked as spent and neither are their outputs booked into the ledger. Moreover, their messages shall be considered invalid.","title":"5.1 UTXO"},{"location":"IOTA-NECTAR/5.1%20UTXO/#utxo-model","text":"The unspent transaction output (UTXO) model defines a ledger state where balances are not directly associated with addresses but with the outputs of transactions. In this model, transactions specify the outputs of previous transactions as inputs, which are consumed in order to create new outputs. A transaction must consume the entirety of the specified inputs. The section unlocking the inputs is called an unlock block . An unlock block may contain a signature proving ownership of a given input's address and/or other unlock criteria. The following image depicts the flow of funds using UTXO:","title":"UTXO model"},{"location":"IOTA-NECTAR/5.1%20UTXO/#transaction-layout","text":"A Transaction payload is made up of two parts: 1. The Transaction Essence part contains: version, timestamp, nodeID of the aMana pledge, nodeID of the cMana pledge, inputs, outputs and an optional data payload. 2. The Unlock Blocks which unlock the Transaction Essence 's inputs. In case the unlock block contains a signature, it signs the entire Transaction Essence part. All values are serialized in little-endian encoding (it stores the most significant byte of a word at the largest address and the smallest byte at the smallest address). The serialized form of the transaction is deterministic, meaning the same logical transaction always results in the same serialized byte sequence. The table describing the entirety of a Transaction 's serialized form is presented in the Section 2.3 Standard Payloads Layout . See Message Layout for understanding the table schema.","title":"Transaction Layout"},{"location":"IOTA-NECTAR/5.1%20UTXO/#transaction-essence","text":"The Transaction Essence of a Transaction carries a version, timestamp, nodeID of the aMana pledge, nodeID of the cMana pledge, inputs, outputs and an optional data payload.","title":"Transaction Essence"},{"location":"IOTA-NECTAR/5.1%20UTXO/#inputs","text":"The Inputs part holds the inputs to consume, that in turn fund the outputs of the Transaction Essence . There is only one supported type of input as of now, the UTXO Input . In the future, more types of inputs may be specified as part of protocol upgrades. Each defined input must be accompanied by a corresponding Unlock Block at the same index in the Unlock Blocks part of the Transaction . If multiple inputs may be unlocked through the same Unlock Block , the given Unlock Block only needs to be specified at the index of the first input that gets unlocked by it. Subsequent inputs that are unlocked through the same data must have a Reference Unlock Block pointing to the previous Unlock Block . This ensures that no duplicate data needs to occur in the same transaction.","title":"Inputs"},{"location":"IOTA-NECTAR/5.1%20UTXO/#utxo-input","text":"Name Type Description Input Type uint8 Set to value 0 to denote an UTXO Input . Transaction ID ByteArray[32] The BLAKE2b-256 hash of the transaction from which the UTXO comes from. Transaction Output Index uint16 The index of the output on the referenced transaction to consume. A UTXO Input is an input which references an output of a previous transaction by using the given transaction's BLAKE2b-256 hash + the index of the output on that transaction. A UTXO Input must be accompanied by an Unlock Block for the corresponding type of output the UTXO Input is referencing. Example: If the input references outputs to an Ed25519 address, then the corresponding unlock block must be of type Signature Unlock Block holding an Ed25519 signature.","title":"UTXO Input"},{"location":"IOTA-NECTAR/5.1%20UTXO/#outputs","text":"The Outputs part holds the outputs to create with this Transaction Payload . There are different types of output: * SigLockedSingleOutput * SigLockedAssetOutput","title":"Outputs"},{"location":"IOTA-NECTAR/5.1%20UTXO/#siglockedsingleoutput","text":"Name Type Description Output Type uint8 Set to value 0 to denote a SigLockedSingleOutput . Address oneOf Ed25519 Address Name Type Description Address Type uint8 Set to value 0 to denote an Ed25519 Address . Address ByteArray[32] The raw bytes of the Ed25519 address which is a BLAKE2b-256 hash of the Ed25519 public key. BLS Address Name Type Description Address Type uint8 Set to value 1 to denote a BLS Address . Address ByteArray[49] The raw bytes of the BLS address which is a BLAKE2b-256 hash of the BLS public key. Balance uint64 The balance of IOTA tokens to deposit with this SigLockedSingleOutput output. The SigLockedSingleOutput defines an output holding an IOTA balance linked to a single address; it is unlocked via a valid signature proving ownership over the given address. Such output may hold an address of different types.","title":"SigLockedSingleOutput"},{"location":"IOTA-NECTAR/5.1%20UTXO/#siglockedassetoutput","text":"Name Type Description Output Type uint8 Set to value 1 to denote a SigLockedAssetOutput . Address oneOf Ed25519 Address Name Type Description Address Type uint8 Set to value 0 to denote an Ed25519 Address . Address ByteArray[32] The raw bytes of the Ed25519 address which is a BLAKE2b-256 hash of the Ed25519 public key. BLS Address Name Type Description Address Type uint8 Set to value 1 to denote a BLS Address . Address ByteArray[49] The raw bytes of the BLS address which is a BLAKE2b-256 hash of the BLS public key. Balances count uint32 The number of individual balances. AssetBalance anyOf Asset Balance The balance of the tokenized asset. Name Type Description AssetID ByteArray[32] The ID of the tokenized asset Balance uint64 The balance of the tokenized asset. The SigLockedAssetOutput defines an output holding a balance for each specified tokenized asset linked to a single address; it is unlocked via a valid signature proving ownership over the given address. Such output may hold an address of different types. The ID of any tokenized asset is defined by the BLAKE2b-256 hash of the OutputID that created the asset.","title":"SigLockedAssetOutput"},{"location":"IOTA-NECTAR/5.1%20UTXO/#payload","text":"The payload part of a Transaction Essence may hold an optional payload. This payload does not affect the validity of the Transaction Essence . If the transaction is not valid, then the payload shall be discarded.","title":"Payload"},{"location":"IOTA-NECTAR/5.1%20UTXO/#unlock-blocks","text":"The Unlock Blocks part holds the unlock blocks unlocking inputs within a Transaction Essence . There are different types of Unlock Blocks : Name Unlock Type Description Signature Unlock Block 0 An unlock block holding one or more signatures unlocking one or more inputs. Reference Unlock Block 1 An unlock block which must reference a previous unlock block which unlocks also the input at the same index as this Reference Unlock Block .","title":"Unlock Blocks"},{"location":"IOTA-NECTAR/5.1%20UTXO/#signature-unlock-block","text":"Name Type Description Unlock Type uint8 Set to value 0 to denote a Signature Unlock Block . Signature oneOf BLS Signature Name Type Description Signature Type uint8 Set to value 0 to denote a BLS Signature . Signature ByteArray The signature signing the serialized Transaction Essence . Ed25519 Signature Name Type Description Signature Type uint8 Set to value 1 to denote an Ed25519 Signature . Public key ByteArray[32] The public key of the Ed25519 keypair which is used to verify the signature. Signature ByteArray[64] The signature signing the serialized Transaction Essence . A Signature Unlock Block defines an Unlock Block which holds one or more signatures unlocking one or more inputs. Such a block signs the entire Transaction Essence part of a Transaction Payload including the optional payload.","title":"Signature Unlock Block"},{"location":"IOTA-NECTAR/5.1%20UTXO/#reference-unlock-block","text":"Name Type Description Unlock Type uint8 Set to value 1 to denote a Reference Unlock Block . Reference uint16 Represents the index of a previous unlock block. A Reference Unlock Block defines an Unlock Block that references a previous Unlock Block (that must not be another Reference Unlock Block ). It must be used if multiple inputs can be unlocked through the same origin Unlock Block . Example: Consider a Transaction Essence containing UTXO Inputs A, B and C, where A and C are both spending the UTXOs originating from the same Ed25519 address. The Unlock Block part must thereby have the following structure: Index Must Contain 0 A Signature Unlock Block holding the corresponding Ed25519 signature to unlock A and C. 1 A Signature Unlock Block that unlocks B. 2 A Reference Unlock Block that references index 0, since C also gets unlocked by the same signature as A.","title":"Reference Unlock block"},{"location":"IOTA-NECTAR/5.1%20UTXO/#validation","text":"A Transaction payload has different validation stages since some validation steps can only be executed at the point when certain information has (or has not) been received. We, therefore, distinguish between syntactical and semantic validation.","title":"Validation"},{"location":"IOTA-NECTAR/5.1%20UTXO/#transaction-syntactical-validation","text":"This validation can commence as soon as the transaction data has been received in its entirety. It validates the structure but not the signatures of the transaction. A transaction must be discarded right away if it does not pass this stage. The following criteria define whether the transaction passes the syntactical validation: * Transaction Essence: * Transaction Essence Version value must be 0. * The timestamp of the Transaction Essence must be older than (or equal to) the timestamp of the message containing the transaction by at most 10 minutes. * A Transaction Essence must contain at least one input and output. * Inputs: * Inputs Count must be 0 < x < 128. * At least one input must be specified. * Input Type value must be 0, denoting an UTXO Input . * UTXO Input : * Transaction Output Index must be 0 \u2264 x < 128. * Every combination of Transaction ID + Transaction Output Index must be unique in the inputs set. * Inputs must be in lexicographical order of their serialized form. 1 * Outputs: * Outputs Count must be 0 < x < 128. * At least one output must be specified. * Output Type must be 0, denoting a SigLockedSingleOutput . * SigLockedSingleOutput : * Address Type must either be 0 or 1, denoting an Ed25519 - or BLS address . * The Address must be unique in the set of SigLockedSingleOutputs . * Amount must be > 0. * Outputs must be in lexicographical order by their serialized form. 1 * Accumulated output balance must not exceed the total supply of tokens 2,779,530,283,277,761 . * Payload Length must be 0 (to indicate that there's no payload) or be valid for the specified payload type. * Payload Type must be one of the supported payload types if Payload Length is not 0. * Unlock Blocks Count must match the number of inputs. Must be 0 < x < 128. * Unlock Block Type must either be 0 or 1, denoting a Signature Unlock Block or Reference Unlock block . * Signature Unlock Blocks must define either an Ed25519 - or BLS Signature . * A Signature Unlock Block unlocking multiple inputs must only appear once (be unique) and be positioned at the same index of the first input it unlocks. All other inputs unlocked by the same Signature Unlock Block must have a companion Reference Unlock Block at the same index as the corresponding input that points to the origin Signature Unlock Block . * Reference Unlock Blocks must specify a previous Unlock Block that is not of type Reference Unlock Block . The referenced index must therefore be smaller than the index of the Reference Unlock Block . * Given the type and length information, the Transaction must consume the entire byte array the Payload Length field in the Message defines. 1 ensures that serialization of the transaction becomes deterministic, meaning that libraries always produce the same bytes given the logical transaction.","title":"Transaction Syntactical Validation"},{"location":"IOTA-NECTAR/5.1%20UTXO/#transaction-semantic-validation","text":"The following criteria define whether the transaction passes the semantic validation: 1. All the UTXOs the transaction references are known (booked) and unspent. 1. The transaction is spending the entirety of the funds of the referenced UTXOs to the outputs. 1. The address type of the referenced UTXO must match the signature type contained in the corresponding Signature Unlock Block . 1. The Signature Unlock Blocks are valid, i.e. the signatures prove ownership over the addresses of the referenced UTXOs. If a transaction passes the semantic validation, its referenced UTXOs shall be marked as spent and the corresponding new outputs shall be booked/specified in the ledger. This process is described in Section 5.2 - Ledger state . Transactions that do not pass semantic validation shall be discarded. Their UTXOs are not marked as spent and neither are their outputs booked into the ledger. Moreover, their messages shall be considered invalid.","title":"Transaction Semantic Validation"},{"location":"IOTA-NECTAR/5.2%20Ledger%20State/","text":"5.2 Ledger State \u00b6 The introduction of a voting-based consensus requires a fast and easy way to determine a node's initial opinion for every received transaction. This includes the ability to both detect double spends and transactions that try to spend non-existing funds. These conditions are fulfilled by the introduction of an Unspent Transaction Output (UTXO) model for record-keeping, which enables the validation of transactions in real time, see also the section on UTXO . The concept of UTXO style transactions is directly linked to the creation of a directed acyclic graph (DAG), in which the vertices are transactions and the links between these are determined by the outputs and inputs of transactions. To deal with double spends and leverage on certain properties of UTXO, we introduce the Realities Ledger State. 5.2.1 Realities Ledger State \u00b6 In the Realities Ledger State, we model the different perceptions of the ledger state that exist in the Tangle. In each \u201creality\u201d on its own there are zero conflicting transactions. Each reality thus forms an in itself consistent UTXO sub-DAG, where every transaction references any other transaction correctly. Since outputs of transactions can only be consumed once, a transaction that double spends outputs creates a persistent branch in a corresponding UTXO DAG. Each branch receives a unique identifier branchID . These branches cannot be merged by any vertices (transactions). A transaction that attempts to merge incompatible branches fails to pass a validity check and is marked as invalid. The composition of all realities defines the Realities Ledger State. From this composition nodes are able to know which possible outcomes for the Tangle exist, where they split, how they relate to each other, if they can be merged and which messages are valid tips. All of this information can be retrieved in a fast and efficient way without having to walk the Tangle. Ultimately, for a set of competing realities, only one reality can survive. It is then up to the consensus protocol to determine which branch is part of the eventually accepted reality. In total the ledger state thus involves three different layers: * the UTXO DAG , * its extension to the corresponding branches and the branch DAG , * the Tangle, which maps the parent relations between messages and thus also transactions. 5.2.2 The UTXO DAG \u00b6 The UTXO DAG models the relationship between transactions, by tracking which outputs have been spent by what transaction, see also the section on UTXO . Since outputs can only be spent once, we use this property to detect double spends. We allow for different versions of the ledger to coexist temporarily. This is enabled by extending the UTXO DAG by the introduction of branches (see the following section). We can then determine which conflicting versions of the ledger state exist in the presence of conflicts. Thus, we allow for different versions of the ledger to coexist temporarily. 5.2.2.1 Conflict sets and detection of double spends \u00b6 For every output we maintain a list of consumers consumerList , and where the consumers have the unique identifier consumerID . For a given output this list keeps track of which transactions have spent that particular output. For every spending transaction we add an element with consumerID=transactionID . Outputs without consumers are considered to be unspent outputs. Transactions that consume an output that have more than one consumer are considered to be double spends. When there are more than one consumer in the consumer list we shall create a conflict set list conflictSet , whose elements have a unique identifier conflictID each. The conflictSet is uniquely identified by the unique identifier conflictSetID . Since the outputID is directly and uniquely linked to the conflict set, we set conflictSetID=outputID . For every transaction that shall be added to the conflict set we add an element with conflictID=transactionID . 5.2.3 Branches \u00b6 The UTXO model and the concept of solidification, see section 4.4 - Solidification , makes all non-conflicting transactions converge to the same ledger state no matter in which order the transactions are received. Messages containing these transactions could always reference each other in the Tangle without limitations. However, every double spend creates a new possible version of the ledger state that will no longer converge. Whenever a double spend is detected (see the previous section), we track the outputs created by the conflicting transactions and all of the transactions that spend these outputs, by creating a container for them in the ledger which we call a branch. More specifically a container branch shall be created for each transaction that double spends one or several outputs, or if messages aggregate those branches. Every transaction that spends directly or indirectly from a transaction that created a branch, i.e. double spent funds, is also contained in this branch or one of its child branches. Note that a branch that was created by a transaction that spends multiple outputs can be part of multiple conflict sets. In other words, a branch is a downward closed, conflict free collection of conflicts. Every branch shall be identified by the unique identifier branchID . We consider two kinds of branches: conflict branches and aggregated branches, which are explained in the following sections. 5.2.3.1 Conflict branches \u00b6 A conflict branch is created by a corresponding double spend transaction. Since the transaction identifier is unique, we choose the transaction id transactionID of the double spending transaction as the branchID . Outputs inside a branch can be double spent again, recursively forming sub-branches. On solidification of a message, we shall store the corresponding branchID together with every output, as well as the transaction metadata to enable instant lookups of this information. Thus, on solidification, a transaction can be immediately associated with a branch. 5.2.3.2 Aggregated branches \u00b6 A transaction that does not create a double spend inherits the branches of the input's branches. In the simplest case, where there is only one input branch the transaction inherits that branch. If outputs from multiple non-conflicting branches are spent in the same transaction, then the transaction and its resulting outputs are part of an aggregated branch. This type of branch is not part of any conflict set. Rather it simply combines the perception that the individual conflict branches associated to the transaction's inputs are the ones that will be accepted by the network. Furthermore, since a message inherits the branches from its parents, it also can create aggregated branches. Each aggregated branch shall have a unique identifier branchID , which is the same type as for conflict branches. Furthermore, the container for an aggregated branch is also of type branch . To calculate the unique identifier of a new aggregated branch, we take the identifiers of the branches that were aggregated, sort them lexicographically and hash the concatenated identifiers once: # AggregatedBranchID returns the identifier for an aggregated branch . FUNCTION aggregatedBranchID = GetAggregatedBranchID ( branchIDs ) sortedBranchIDs = Sort ( branchIDs ) RETURN Hash ( sortedBranchIDs ) An aggregated branch can't aggregate other aggregated branches. However, it can aggregate the conflict branches that are part of the referenced aggregated branch. Thus aggregated branches have no further branches as their children and they remain tips in the branch DAG. Furthermore, the sortation of the branchID s in the function AggregatedBranchID() ensures that even though messages can attach at different points in the Tangle and aggregate different aggregated branches they are treated as if they are in the same aggregated branch if the referenced conflict branches are the same. These properties allow for an efficient reduction of a set of branches. In the following we will require the following fields as part of the branch data: * isConflictBranch is a boolean flat that is TRUE if the branch is a conflict branch or FALSE if its an aggregated branch. * parentBranches contains the list of parent conflict branches of the branch, i.e. the conflict branches that are directly referenced by this branch. Then the following function takes a list of branches (which can be either conflict or aggregated branches) and returns a unique set of conflict branches that these branches represent. This is done by replacing duplicates and extracting the parent conflict branches from aggregated branches. FUNCTION reducedBranches = ReduceBranches ( branches ) FOR branch IN branches IF branch . isConflictBranch IF NOT ( branch IN reducedBranches ) Append ( reducedBranches , branch ) ELSE FOR parentBranch IN branch . parentBranches IF NOT ( parentBranch IN reducedBranches ) Append ( reducedBranches , parentBranch ) RETURN reducedBranches 5.2.3.3 The branch DAG \u00b6 A new branch is created for each transaction that is part of a conflict set, or if a transaction aggregates branches. In the branch DAG, branches constitute the vertices of the DAG. A branch that is created by a transaction that is spending outputs from other branches has edges pointing to those branches. The branch DAG maps the UTXO DAG to a simpler structure that ignores details about relations between transactions inside the branches and instead retains only details about the interrelations of conflicts. The set of all non-conflicting transactions form the master branch. Thus, at its root the branch DAG has the master branch, which consists of non-conflicting transaction and resolved transactions. From this root of the branch DAG the various branches emerge. In other words the conflict branches and the aggregated branches appear as the children of the master branch. 5.2.3.4 Detecting conflicting branches \u00b6 Branches are conflicting if they, or any of their ancestors, are part of the same conflict set. The branch DAG can be used to check if branches are conflicting, by applying an operation called normalization, to a set of input branches. From this information we can identify messages or transactions that are trying to combine branches belonging to conflicting double spends, and thus introduce an invalid perception of the ledger state. Since branches represent the ledger state associated with a double spend and sub-branches implicitly share the perception of their parents, we define a function NormalizeBranches() to normalize a list of branches and that gets rid of all branches that are referenced by other branches in that list. The function returns NULL if the branches are conflicting and can not be merged. In order to explain this function in pseudo code we require the following global variables - seenConflictSets = map[]conflictSetID - traversedBranches = map[]branch - parentsToCheck = map[]branch as well as a function BranchCheck() that performs certain checks and returns TRUE when the branch is conflicting with a previously seen branch. However, we note that this is an implementation detail that must not match the implementation. # reduce list of branches to normalized branches , and return NULL when detecting conflicting branches FUNCTION normalizedBranches = NormalizeBranches ( initialBranches ) IF Len ( initialBranches ) == 0 RETURN masterBranch IF Len ( initialBranches ) == 1 RETURN initialBranches # check original set of branches normalizedBranches = ReduceBranches ( initialBranches ) FOR branch IN normalizedBranches BranchCheck ( branch ) # check every ancestor WHILE Len ( parentsToCheck ) ! = 0 branch = parentsToCheck [ 0 ] Delete ( parentsToCheck , branch ) # delete this branch from the list # remove this ancestor IF branch IN normalizedBranches Delete ( normalizedBranches , branch ) # if branch check fails , i . e . a conflict set was seen twice , return a null list IF BranchCheck ( branch ) RETURN NULL RETURN normalizedBranches The branch check function BranchCheck() checks if the branch was already traversed, i.e. we have handled this branch already. Then it checks if the branch's conflict set has been already seen, which proofs that the current branch conflicts with an already traversed branch. Lastly it adds new branches to the queue of branches that should be traversed. FUNCTION isConflicting = BranchCheck ( branch ) # abort if branch was traversed already IF branch IN traversedBranches RETURN FALSE ELSE Append ( traversedBranches , branch . ID ) # check if conflict set was seen twice IF branch . conflictSetID IN seenConflictSets RETURN TRUE ELSE Append ( seenConflictSets , branch . conflictSetID ) # queue parents to be checked when traversing ancestors FOR parentBranch IN branch . parentBranches IF branch NOT IN parentsToCheck Append ( parentsToCheck , parentBranch ) RETURN FALSE 5.2.3.5 Merging of branches \u00b6 A branch gains approval weight when messages from (previously non-attached) nodeID s attach to messages in the future cone of that branch. Once the approval weight exceeds a certain threshold we consider the branch as confirmed, see also section 6.4 Finality . However, there are two special cases of branches: First the branch that is created by the genesis transaction is called master branch and has the identifier masterBranchID . The masterBranchID is confirmed on creation and thus it is the \"correct\" reality by definition. Once a conflict branch is confirmed, it can be merged into the master branch. Since the approval weight is monotonically increasing for branches from the past to the future, branches are only merged into the master branch. Second, a branch rejectedBranch is created that is rejected by definition, and it has the identifier rejectedBranchID . Messages that are contained in a rejected branch or in one its child branches are booked into the rejectedBranch . 5.2.4 Relation to the Tangle \u00b6 Since messages in the Tangle are dependent on the fate of the messages they approve, we shall create dependencies between payloads, messages, and branches. The branch ID of a message or of a transaction represents all the conflicts upon which that object depends. Specifically, we associate a branch to a payload and to a message in the following way. The branch of a non-value payload is always the master branch. The branch of a transaction is assigned in one of two ways: If the transaction is a conflict, then a new branch is created whose branchID is that transactionID. The transaction gets assigned to this new branch. Otherwise, the transaction is assigned to the aggregated branch of all its inputs. The branch of a message is the aggregate of The branch of its payload The branches of each strong parent The branches of the payloads of the weak parents. This assignments captures the essence of weak and strong parents, see Section 4.3 - Tip Selection Specification . Strong arrows pick up the dependencies of the whole past cone, where as the weak arrows only penetrate to the paylaod of the parent, ignoring the history of the parent. We that a message \\(M\\) (resp. transaction \\(X\\) ) belongs to a branch \\(B\\) if the branch \\(A\\) of \\(M\\) (resp. \\(X\\) ) is in the branch past of \\(B\\) . Thus, branches, represent certain coherent sections of the Tangle which are then ordered by inclusion. After a message is solidified, it and its payload are both assigned to their branch. During this check, the message is flagged as invalid if: - The payload is a transaction, and the node cannot aggregate branchIDs of the transaction's input into a valid branchID. - The branchIF of the message cannot be aggregated. If these branchID's cannot be computed, then the message contains a pair of its history, and thus does not support a coherent view of the ledger.","title":"5.2 Ledger State"},{"location":"IOTA-NECTAR/5.2%20Ledger%20State/#52-ledger-state","text":"The introduction of a voting-based consensus requires a fast and easy way to determine a node's initial opinion for every received transaction. This includes the ability to both detect double spends and transactions that try to spend non-existing funds. These conditions are fulfilled by the introduction of an Unspent Transaction Output (UTXO) model for record-keeping, which enables the validation of transactions in real time, see also the section on UTXO . The concept of UTXO style transactions is directly linked to the creation of a directed acyclic graph (DAG), in which the vertices are transactions and the links between these are determined by the outputs and inputs of transactions. To deal with double spends and leverage on certain properties of UTXO, we introduce the Realities Ledger State.","title":"5.2 Ledger State"},{"location":"IOTA-NECTAR/5.2%20Ledger%20State/#521-realities-ledger-state","text":"In the Realities Ledger State, we model the different perceptions of the ledger state that exist in the Tangle. In each \u201creality\u201d on its own there are zero conflicting transactions. Each reality thus forms an in itself consistent UTXO sub-DAG, where every transaction references any other transaction correctly. Since outputs of transactions can only be consumed once, a transaction that double spends outputs creates a persistent branch in a corresponding UTXO DAG. Each branch receives a unique identifier branchID . These branches cannot be merged by any vertices (transactions). A transaction that attempts to merge incompatible branches fails to pass a validity check and is marked as invalid. The composition of all realities defines the Realities Ledger State. From this composition nodes are able to know which possible outcomes for the Tangle exist, where they split, how they relate to each other, if they can be merged and which messages are valid tips. All of this information can be retrieved in a fast and efficient way without having to walk the Tangle. Ultimately, for a set of competing realities, only one reality can survive. It is then up to the consensus protocol to determine which branch is part of the eventually accepted reality. In total the ledger state thus involves three different layers: * the UTXO DAG , * its extension to the corresponding branches and the branch DAG , * the Tangle, which maps the parent relations between messages and thus also transactions.","title":"5.2.1 Realities Ledger State"},{"location":"IOTA-NECTAR/5.2%20Ledger%20State/#522-the-utxo-dag","text":"The UTXO DAG models the relationship between transactions, by tracking which outputs have been spent by what transaction, see also the section on UTXO . Since outputs can only be spent once, we use this property to detect double spends. We allow for different versions of the ledger to coexist temporarily. This is enabled by extending the UTXO DAG by the introduction of branches (see the following section). We can then determine which conflicting versions of the ledger state exist in the presence of conflicts. Thus, we allow for different versions of the ledger to coexist temporarily.","title":"5.2.2 The UTXO DAG"},{"location":"IOTA-NECTAR/5.2%20Ledger%20State/#5221-conflict-sets-and-detection-of-double-spends","text":"For every output we maintain a list of consumers consumerList , and where the consumers have the unique identifier consumerID . For a given output this list keeps track of which transactions have spent that particular output. For every spending transaction we add an element with consumerID=transactionID . Outputs without consumers are considered to be unspent outputs. Transactions that consume an output that have more than one consumer are considered to be double spends. When there are more than one consumer in the consumer list we shall create a conflict set list conflictSet , whose elements have a unique identifier conflictID each. The conflictSet is uniquely identified by the unique identifier conflictSetID . Since the outputID is directly and uniquely linked to the conflict set, we set conflictSetID=outputID . For every transaction that shall be added to the conflict set we add an element with conflictID=transactionID .","title":"5.2.2.1 Conflict sets and detection of double spends"},{"location":"IOTA-NECTAR/5.2%20Ledger%20State/#523-branches","text":"The UTXO model and the concept of solidification, see section 4.4 - Solidification , makes all non-conflicting transactions converge to the same ledger state no matter in which order the transactions are received. Messages containing these transactions could always reference each other in the Tangle without limitations. However, every double spend creates a new possible version of the ledger state that will no longer converge. Whenever a double spend is detected (see the previous section), we track the outputs created by the conflicting transactions and all of the transactions that spend these outputs, by creating a container for them in the ledger which we call a branch. More specifically a container branch shall be created for each transaction that double spends one or several outputs, or if messages aggregate those branches. Every transaction that spends directly or indirectly from a transaction that created a branch, i.e. double spent funds, is also contained in this branch or one of its child branches. Note that a branch that was created by a transaction that spends multiple outputs can be part of multiple conflict sets. In other words, a branch is a downward closed, conflict free collection of conflicts. Every branch shall be identified by the unique identifier branchID . We consider two kinds of branches: conflict branches and aggregated branches, which are explained in the following sections.","title":"5.2.3 Branches"},{"location":"IOTA-NECTAR/5.2%20Ledger%20State/#5231-conflict-branches","text":"A conflict branch is created by a corresponding double spend transaction. Since the transaction identifier is unique, we choose the transaction id transactionID of the double spending transaction as the branchID . Outputs inside a branch can be double spent again, recursively forming sub-branches. On solidification of a message, we shall store the corresponding branchID together with every output, as well as the transaction metadata to enable instant lookups of this information. Thus, on solidification, a transaction can be immediately associated with a branch.","title":"5.2.3.1 Conflict branches"},{"location":"IOTA-NECTAR/5.2%20Ledger%20State/#5232-aggregated-branches","text":"A transaction that does not create a double spend inherits the branches of the input's branches. In the simplest case, where there is only one input branch the transaction inherits that branch. If outputs from multiple non-conflicting branches are spent in the same transaction, then the transaction and its resulting outputs are part of an aggregated branch. This type of branch is not part of any conflict set. Rather it simply combines the perception that the individual conflict branches associated to the transaction's inputs are the ones that will be accepted by the network. Furthermore, since a message inherits the branches from its parents, it also can create aggregated branches. Each aggregated branch shall have a unique identifier branchID , which is the same type as for conflict branches. Furthermore, the container for an aggregated branch is also of type branch . To calculate the unique identifier of a new aggregated branch, we take the identifiers of the branches that were aggregated, sort them lexicographically and hash the concatenated identifiers once: # AggregatedBranchID returns the identifier for an aggregated branch . FUNCTION aggregatedBranchID = GetAggregatedBranchID ( branchIDs ) sortedBranchIDs = Sort ( branchIDs ) RETURN Hash ( sortedBranchIDs ) An aggregated branch can't aggregate other aggregated branches. However, it can aggregate the conflict branches that are part of the referenced aggregated branch. Thus aggregated branches have no further branches as their children and they remain tips in the branch DAG. Furthermore, the sortation of the branchID s in the function AggregatedBranchID() ensures that even though messages can attach at different points in the Tangle and aggregate different aggregated branches they are treated as if they are in the same aggregated branch if the referenced conflict branches are the same. These properties allow for an efficient reduction of a set of branches. In the following we will require the following fields as part of the branch data: * isConflictBranch is a boolean flat that is TRUE if the branch is a conflict branch or FALSE if its an aggregated branch. * parentBranches contains the list of parent conflict branches of the branch, i.e. the conflict branches that are directly referenced by this branch. Then the following function takes a list of branches (which can be either conflict or aggregated branches) and returns a unique set of conflict branches that these branches represent. This is done by replacing duplicates and extracting the parent conflict branches from aggregated branches. FUNCTION reducedBranches = ReduceBranches ( branches ) FOR branch IN branches IF branch . isConflictBranch IF NOT ( branch IN reducedBranches ) Append ( reducedBranches , branch ) ELSE FOR parentBranch IN branch . parentBranches IF NOT ( parentBranch IN reducedBranches ) Append ( reducedBranches , parentBranch ) RETURN reducedBranches","title":"5.2.3.2 Aggregated branches"},{"location":"IOTA-NECTAR/5.2%20Ledger%20State/#5233-the-branch-dag","text":"A new branch is created for each transaction that is part of a conflict set, or if a transaction aggregates branches. In the branch DAG, branches constitute the vertices of the DAG. A branch that is created by a transaction that is spending outputs from other branches has edges pointing to those branches. The branch DAG maps the UTXO DAG to a simpler structure that ignores details about relations between transactions inside the branches and instead retains only details about the interrelations of conflicts. The set of all non-conflicting transactions form the master branch. Thus, at its root the branch DAG has the master branch, which consists of non-conflicting transaction and resolved transactions. From this root of the branch DAG the various branches emerge. In other words the conflict branches and the aggregated branches appear as the children of the master branch.","title":"5.2.3.3 The branch DAG"},{"location":"IOTA-NECTAR/5.2%20Ledger%20State/#5234-detecting-conflicting-branches","text":"Branches are conflicting if they, or any of their ancestors, are part of the same conflict set. The branch DAG can be used to check if branches are conflicting, by applying an operation called normalization, to a set of input branches. From this information we can identify messages or transactions that are trying to combine branches belonging to conflicting double spends, and thus introduce an invalid perception of the ledger state. Since branches represent the ledger state associated with a double spend and sub-branches implicitly share the perception of their parents, we define a function NormalizeBranches() to normalize a list of branches and that gets rid of all branches that are referenced by other branches in that list. The function returns NULL if the branches are conflicting and can not be merged. In order to explain this function in pseudo code we require the following global variables - seenConflictSets = map[]conflictSetID - traversedBranches = map[]branch - parentsToCheck = map[]branch as well as a function BranchCheck() that performs certain checks and returns TRUE when the branch is conflicting with a previously seen branch. However, we note that this is an implementation detail that must not match the implementation. # reduce list of branches to normalized branches , and return NULL when detecting conflicting branches FUNCTION normalizedBranches = NormalizeBranches ( initialBranches ) IF Len ( initialBranches ) == 0 RETURN masterBranch IF Len ( initialBranches ) == 1 RETURN initialBranches # check original set of branches normalizedBranches = ReduceBranches ( initialBranches ) FOR branch IN normalizedBranches BranchCheck ( branch ) # check every ancestor WHILE Len ( parentsToCheck ) ! = 0 branch = parentsToCheck [ 0 ] Delete ( parentsToCheck , branch ) # delete this branch from the list # remove this ancestor IF branch IN normalizedBranches Delete ( normalizedBranches , branch ) # if branch check fails , i . e . a conflict set was seen twice , return a null list IF BranchCheck ( branch ) RETURN NULL RETURN normalizedBranches The branch check function BranchCheck() checks if the branch was already traversed, i.e. we have handled this branch already. Then it checks if the branch's conflict set has been already seen, which proofs that the current branch conflicts with an already traversed branch. Lastly it adds new branches to the queue of branches that should be traversed. FUNCTION isConflicting = BranchCheck ( branch ) # abort if branch was traversed already IF branch IN traversedBranches RETURN FALSE ELSE Append ( traversedBranches , branch . ID ) # check if conflict set was seen twice IF branch . conflictSetID IN seenConflictSets RETURN TRUE ELSE Append ( seenConflictSets , branch . conflictSetID ) # queue parents to be checked when traversing ancestors FOR parentBranch IN branch . parentBranches IF branch NOT IN parentsToCheck Append ( parentsToCheck , parentBranch ) RETURN FALSE","title":"5.2.3.4 Detecting conflicting branches"},{"location":"IOTA-NECTAR/5.2%20Ledger%20State/#5235-merging-of-branches","text":"A branch gains approval weight when messages from (previously non-attached) nodeID s attach to messages in the future cone of that branch. Once the approval weight exceeds a certain threshold we consider the branch as confirmed, see also section 6.4 Finality . However, there are two special cases of branches: First the branch that is created by the genesis transaction is called master branch and has the identifier masterBranchID . The masterBranchID is confirmed on creation and thus it is the \"correct\" reality by definition. Once a conflict branch is confirmed, it can be merged into the master branch. Since the approval weight is monotonically increasing for branches from the past to the future, branches are only merged into the master branch. Second, a branch rejectedBranch is created that is rejected by definition, and it has the identifier rejectedBranchID . Messages that are contained in a rejected branch or in one its child branches are booked into the rejectedBranch .","title":"5.2.3.5 Merging of branches"},{"location":"IOTA-NECTAR/5.2%20Ledger%20State/#524-relation-to-the-tangle","text":"Since messages in the Tangle are dependent on the fate of the messages they approve, we shall create dependencies between payloads, messages, and branches. The branch ID of a message or of a transaction represents all the conflicts upon which that object depends. Specifically, we associate a branch to a payload and to a message in the following way. The branch of a non-value payload is always the master branch. The branch of a transaction is assigned in one of two ways: If the transaction is a conflict, then a new branch is created whose branchID is that transactionID. The transaction gets assigned to this new branch. Otherwise, the transaction is assigned to the aggregated branch of all its inputs. The branch of a message is the aggregate of The branch of its payload The branches of each strong parent The branches of the payloads of the weak parents. This assignments captures the essence of weak and strong parents, see Section 4.3 - Tip Selection Specification . Strong arrows pick up the dependencies of the whole past cone, where as the weak arrows only penetrate to the paylaod of the parent, ignoring the history of the parent. We that a message \\(M\\) (resp. transaction \\(X\\) ) belongs to a branch \\(B\\) if the branch \\(A\\) of \\(M\\) (resp. \\(X\\) ) is in the branch past of \\(B\\) . Thus, branches, represent certain coherent sections of the Tangle which are then ordered by inclusion. After a message is solidified, it and its payload are both assigned to their branch. During this check, the message is flagged as invalid if: - The payload is a transaction, and the node cannot aggregate branchIDs of the transaction's input into a valid branchID. - The branchIF of the message cannot be aggregated. If these branchID's cannot be computed, then the message contains a pair of its history, and thus does not support a coherent view of the ledger.","title":"5.2.4 Relation to the Tangle"},{"location":"IOTA-NECTAR/5.3%20Mana/","text":"5.3 Mana \u00b6 Introduction \u00b6 This section introduces access Mana and consensus Mana and determines which modules use each of these two types of Mana. Any permissionless system needs a Sybil protection mechanism. In Coordicide, this is done by forcing every node to create a node identity (see also Section 3.3 - Peer Discovery ). Since the creation of an arbitrarily large number of identities is not an expensive operation, two Difficult-to-obtain resources are linked to each node identity; we call them access Mana ( aMana ) and consensus Mana ( cMana ). Both kinds of Mana can be described as essential resources to multiple parts of the network. They are related to the IOTA token, but are not tokens by themselves and do not interfere with the token balance in any direct way. When a transaction is processed, a certain amount of aMana and cMana\u2014dependent on the amount of IOTAs moved by the transaction\u2014will be pledged to nodes specified in the transaction (their node IDs must be specified as defined in Section 2.3 - Standard Payloads Layout ). The access and consensus Mana pledged to each node ID must be stored as an extension of the ledger state. The only way a node can obtain aMana or cMana is to convince some ken holders to pledge to it. Both kinds of Mana provides adequate Sybil protection because they are difficult and costly to be acquired in arbitrarily large amounts. Access and consensus Mana are used as Sybil protection in different modules, which have different natures and requirements. For this reason, it is natural to use different formulas to calculate the appropriate Mana to each module. Consensus Mana should be seen as the Mana that is responsible for the security of the system, on the other hand, access Mana is used to distribute access to the network during congestion periods. We give a short overview on how each module uses its associated kind of Mana: Section 3.4 - Neighbor Selection : Nodes only establish a connection with nodes of similar consensus Mana. Section 4.6 - Congestion Control : The throughput (in bytes per second) of each node is dependent on the access Mana held. Section 6.3 - Fast Probabilistic Consensus : The selection probability for a node during a voting query is proportional to the consensus Mana held. Section 6.4 - Finalization : Finalization occurs when (among other criteria) a message is approved by nodes holding a certain fraction of the consensus Mana in the network. Section 6.5 - Distributed Random Number Generator : The dRNG committee members must be composed by high consensus Mana nodes. Detailed Design - General \u00b6 Each transaction must have an accessManaNodeID and a consensusManaNodeID field to determine which node to pledge these two types of Mana. Both of these fields consist of a node ID of the node that will receive each kind of Mana. Access Mana and consensus Mana do not have to be pledged to the same node. Both kinds of Mana are exponential moving averages (EMA) of the base Manas (specifically, cMana is the EMA of base cMana, and aMana is the EMA of base aMana). An EMA is a type of moving average that places a greater weight and significance on the most recent data points. More precisely, the weighting for older data decreases exponentially in time, however, never reaching zero. Even though the definition of an EMA should be unique (no matter to which function that you apply it), the general algorithm for the calculation of the EMAs\u2014with the flexibility needed in our case\u2014is not easily implementable. Thus, two different algorithms already customized for each type of Mana are provided in the present document. We define the following parameters: \\(\\gamma\\) - decay factor for base aMana. \\(\\alpha\\) - moving average factor for the cMana. \\(\\beta\\) - moving average factor for the aMana. Additionally, we define four vectors that assign a real value to each node Id: the aMana vector , base aMana vector , cMana vector and base cMana vector . The base aMana vector and the base cMana vector are auxiliary vectors (meaning that they are needed to compute the aMana vector and the cMana vector, even though their values are not directly used in any of the modules). Due to the time dependance of the EMA (and also the base aMana function), the four vectors have a reference time to which they are associated. The Mana vectors are updated in different occasions. Access Mana pledging happens when a transaction is booked on the ledger state. At the same time, entries of the nodes whose aMana is not being modified during the pledging are updated only with respect to the (possibly) newer time reference. In general, updates only due to time (without aMana pledging) happen whenever a node's aMana is being accessed by an external module (as the congestion control, for instance). On the other hand, cMana is updated only relatively to the end of each epoch (see Section 4.2 - Timestamps ). The reason behind this is that epochs are objective, i.e. all nodes agree on which epoch a certain message (or transaction) belongs to. Thus, since nodes agree (with high probability) about transactions with timestamps older than the end of the epoch plus TIMESTAMP_CUTOFF (see Section 4.2 - Timestamps ), they will consequently agree\u2014again, with high probability\u2013about the cMana vector relative to these transactions. Therefore, one can assume that the nodes in sync will (with high probability) agree on values of cMana relative to the set of transactions that have timestamp older than a fixed epoch in the past. On the other hand, aMana will capture recent fluctuations, but nodes are expected to have slightly different perceptions of this quantity. Detailed Design - Consensus Mana \u00b6 The base cMana of a node nodeID at time time is defined as the sum over all unspent outputs at time time of transactions with consensusManaNodeID = nodeID . This means that, when an output is consumed, its cMana pledge is revoked and pledged to a (possibly) different node. See the example below: Example 1: Suppose transaction \\(z\\) was booked and we want to update the base cMana vector accordingly. Additionally, suppose transaction \\(z\\) , \\(x\\) and \\(y\\) pledges cMana to nodes \\(N_z\\) , \\(N_x\\) and \\(N_y\\) , respectively. The update of the base cMana proceeds as follows: Add 300 to the base cMana state of the node \\(N_z\\) . Subtract 100 from the base cMana state of the node \\(N_x\\) . Subtract 200 from the base cMana state of the node \\(N_y\\) . If a transaction \\(T_i\\) with timestamp \\(t_i\\) pledges \\(M_i\\) cMana to a node \\(Z\\) , then the cMana evolution over time relative to this transaction will be given by: \\[ \\text{cMana}_Z^{T_i}(t) = \\begin{cases} 0, \\text{ if } t< t_i \\\\ M_i\\left(1-e^{-\\alpha (t-t_i)}\\right), \\text{ if } t\\geq t_i \\\\ \\end{cases} \\] The total cMana of a node \\(Z\\) will be, then, given by the sum of \\(\\text{cMana}_Z^{T_i}(t)\\) among all the transactions \\(T_i\\) that pledge cMana to node \\(Z\\) . Nevertheless, computing the mana using this equation may be excessively demanding in the case where a node has multiples pledges at different times. For that reason, the cMana shall be computed recursively, updating it based on its last value. This update is customized for three different situations (here, \\(t_0\\) is the reference time of the previous cMana value): pledging of the cMana relative to a transaction with timestamp smaller than \\(t_0\\) . pledging of the cMana relative to a transaction with timestamp larger than \\(t_0\\) . updating the cMana to a time \\(t_1>t_0\\) without any new cMana pledging. In the first case, the reference time of the cMana must not be changed, whereas in the second case, the reference time of the cMana must be changed to the timestamp of the transaction. This means that a node must never update the cMana to a point in the past (relatively to the last cMana calculated). The exact update procedure for each of the cases defined above are defined next. Consensus Mana update procedure \u00b6 Pledging the cMana relative to a transaction with timestamp smaller than the last reference time \u00b6 Suppose that the last reference time is \\(t\\) and the transaction timestamp is \\(t-s\\) . The update must be done in two steps, always in the order specified below: a ) Base cMana update . Just before updating the base cMana vector we must store it, since the last base cMana state (that we call \\(\\text{Old\\_Base\\_cMana}\\) ) and the time relative to the last update are used later for the cMana calculations. This temporary vector can be deleted right after the cMana vector is updated. The update of the base cMana state goes as follows: if a new transaction with \\(n\\) inputs of values \\(x_1, x_2, \\ldots, x_n\\) pledges cMana to a node \\(N\\) , then 1. we add \\(\\sum_{j=1}^{n}x_j\\) to the base cMana of the node \\(N\\) . 2. Each input \\(I_j\\) corresponds to some UTXO (and, consequently, to some transaction) stored in the ledger state. Then, we locate the node Id (let us say, \\(\\text{Node}_j\\) ) to whom the cMana relative to this output was pledged to in the past. Then, we subtract \\(x_j\\) from the base cMana state of the node \\(\\text{Node}_j\\) , for each \\(I_j\\) , \\(j=1,\\dots,n\\) . b ) Pledging and revoking cMana . If the base cMana balance of node \\(i\\) (before we added this transaction) was \\(\\text{Old\\_Base\\_cMana}(\\text{Node}_i)\\) and the new base cMana balance (after the addition of this transaction) is \\(\\text{Base\\_cMana}(\\text{Node}_i)\\) , then we update the cMana vector adding to all nodes' entry the term: \\[ (1-e^{-\\alpha s})[\\text{Base\\_cMana}(\\text{Node}_i)-\\text{Old\\_Base\\_cMana}(\\text{Node}_i)] \\] The term above can be negative\u2014since some nodes have their base cMana revoked\u2014but the resulting cMana must not be. Notice that for most nodes (specifically, for all nodes that did not have their base cMana value changed) the value above is zero. Pledging the cMana relative to a transaction with timestamp larger than the last reference time \u00b6 Suppose that the last reference time is \\(t-s\\) and the transaction timestamp is \\(t\\) . The update must be done in two steps, always in the order specified below: a ) Base cMana update . Just before updating the base cMana vector we must store it, since the last base cMana state (that we call \\(\\text{Old\\_Base\\_cMana}\\) ) and the time relative to the last update are used later for the cMana calculations. This temporary vector can be deleted right after the cMana vector is updated. The update of the base cMana state goes as follows: if a new transaction with \\(n\\) inputs of respective values \\(x_1, x_2, \\ldots, x_n\\) pledges cMana to a node \\(N\\) , then 1. we add \\(\\sum_{j=1}^{n}x_j\\) to the base cMana of the node \\(N\\) . 2. Each input \\(I_j\\) corresponds to some UTXO (and, consequently, to some transaction) stored in the ledger state. Then, we locate the node Id (let us say, \\(\\text{Node}_j\\) ) to whom the cMana relative to this output was pledged to in the past. Then, we subtract \\(x_j\\) from the base cMana state of the node \\(\\text{Node}_j\\) , for each \\(I_j\\) , \\(j=1,\\dots,n\\) . b ) Updating the cMana with respect to time . Suppose that the outdated cMana is \\(\\text{Old\\_cMana}\\) . We update all cMana entries as follows: $$ \\text{cMana}(\\text{Node}_i)=e^{-\\alpha s} \\text{Old_cMana}(\\text{Node}_i)+(1-e^{-\\alpha s})\\text{Old_Base_cMana}(\\text{Node}_i) $$ where \\(\\alpha\\) is the moving average parameter for the cMana. Updating the cMana to a time larger than the last reference time without any new cMana pledging \u00b6 Suppose that the last reference time is \\(t-s\\) , the new one is \\(t\\) and the last cMana vector is \\(\\text{Old\\_cMana}\\) . We update all cMana entries as follows: Suppose that the last reference time is \\(t-s\\) , the new one is \\(t\\) and the last cMana vector is \\(\\text{Old\\_cMana}\\) . We update all cMana entries as follows: $$ \\text{cMana}(\\text{Node}_i)=e^{-\\alpha s} \\text{Old_cMana}(\\text{Node}_i)+(1-e^{-\\alpha s})\\text{Old_Base_cMana}(\\text{Node}_i) $$ where \\(\\alpha\\) is the moving average parameter for the cMana. 4.3.3.2 Active Consensus Mana and Epochs \u00b6 The consensus Mana of a node is only calculated and stored relatively to the end of each epoch (see Section 4.2 - Timestamps ). Only the values of the last MAX_STORED_EPOCHS epochs are stored. Thus, if \\(t_E\\) is the time of the end of epoch \\(E\\) , to update the cMana vector from epoch \\(E-1\\) to \\(E\\) , a node must perform the following algorithm: Update the cMana with respect to time, as described in section 4.3.3.1.3, from time \\(t_{E-1}\\) to \\(t_{E}\\) For each transaction with timestamp in the interval \\([t_{E-1},t_{E})\\) , perform (as described in section 4.3.3.1.1) the base cMana update and the pledge and revoking of cMana, while the reference time \\(t_{E}\\) remains constant. Additionally, we define the active consensus Mana of a node A in epoch E (i.e., relatively to time \\(t_{E}\\) ) as (here, \\(\\text{cMana}\\) is also relative to time \\(t_{E}\\) ): \\[ \\text{Active\\_cMana}(\\text{Node A})=\\begin{cases} \\text{cMana}(\\text{Node A}), \\text{ if there is at least one message from node `node` with timestamp in }[t_{E-1},t_{E}) \\\\ 0, \\text{ otherwise} \\end{cases} \\] Therefore, even if node node has consensus Mana greater than zero at a certain epoch \\(E\\) , it can be considered dormant in case it did not issue any message during the same epoch. All nodes that have active consensus Mana in epoch \\(E\\) will form what we call the active consensus Mana set of that epoch, or ACMS(E) . Both calculations defined above (cMana and active cMana on an epoch \\(E\\) ) can only be carried out when epoch \\(E\\) is finalized\u2014that is, at least TIMESTAMP_CUTOFF (see Section 4.2 - Timestamps ) units of time after \\(t_E\\) \u2014to make sure that no more messages belonging to the epoch will appear in the network. The following data structures and functions must be defined: UpdatecMana(epoch) : updates the base cMana and cMana vectors from the end of epoch-1 to epoch , pledging and revoking the base cMana and cMana relative to all the relevant transactions. GetActiveConsensusMana(time) : returns a mapping between all known nodes and their active cMana, calculated at the end of the epoch that contains time . ManaRank(lowerMana, upperMana, epoch) : returns the node ID of the nodes with active cMana in the interval [lowerMana, upperMana] , relative to epoch . Notice that epoch must be, at least, the current epoch minus MAX_STORED_EPOCHS and, at most, the last epoch. Detailed Design - Access Mana \u00b6 When an output is consumed and funds are consequently transferred, a certain amount of base aMana\u2014dependent on the amount of funds and the age of the output\u2014will be pledged to a node. This pledge is never revoked, as opposed to base cMana. Nevertheless, the base aMana of all nodes will decay over time, which means that all the calculations for aMana will be slightly different than for cMana. The base aMana at time \\(t\\) , relative to an output \\(T_i\\) (of amount \\(M_i\\) ) consumed by a transaction with timestamp \\(t-s\\) and generated by a transaction with timestamp \\(t-s-\\delta\\) is, for \\(s,\\delta>0\\) \\[ \\text{Base\\_aMana}^{T_i}(t)= M (1-e^{-\\gamma \\delta}) e^{-\\gamma s}, \\text{ if } t\\geq t-s \\] If this same output pledges aMana to a node \\(Z\\) , then the aMana evolution over time (again, for \\(s,\\delta>0\\) ) relative to it will be given by: \\[ \\text{aMana}_Z^{T_i}(t) = \\begin{cases} M_i(1-e^{-\\gamma\\delta})\\dfrac{\\beta e^{-\\beta s}}{\\beta-\\gamma}\\left(e^{(\\beta-\\gamma)s}-1\\right), \\text{ if }\\beta\\neq \\gamma\\\\ M_i(1-e^{-\\gamma\\delta})\\gamma s e^{-\\gamma s}, \\text{ if } \\beta= \\gamma\\\\ \\end{cases} \\] The base aMana of a node nodeID at time time is defined as the sum of the individual base aMana generated by all already consumed outputs \\(T_i\\) of transactions with accessManaNodeID = nodeID and timestamp smaller or equal than time . Nevertheless, as in the cMana case, computing the aMana using this equation can be excessively demanding. For that reason, the aMana shall computed recursively, updating it based on its last value. This update is customized for three different situations (here, \\(t_0\\) is the reference time of the last aMana value): pledging of the aMana relative to a transaction with timestamp smaller than \\(t_0\\) ; pledging of the aMana relative to a transaction with timestamp larger than \\(t_0\\) ; updating the aMana to a time \\(t_1>t_0\\) without any new aMana pledging. In the first case, the reference time of the aMana must not be changed, whereas in the second case, the reference time of the cMana must be changed to the timestamp of the transaction. This means that a node must never update the aMana to a point in the past (relatively to the last aMana calculated). The exact update procedure for each of the cases defined above are defined next. Access Mana update procedure \u00b6 Pledging the aMana relative to a transaction with timestamp smaller than the last reference time \u00b6 Suppose that the last reference time is \\(t\\) and the transaction timestamp is \\(t-s\\) . The update must be done in two steps, always in the order specified below: Base aMana pledging . Suppose that the new transaction consists of \\(m\\) inputs \\(I_1, I_2, \\ldots, I_m\\) of value \\(x_1, x_2, \\ldots, x_m\\) \u2014respectively\u2014and pledges aMana to a node \\(N\\) . We update the base aMana of node \\(N\\) by adding to its base aMana the value $$ d=e^{-\\gamma s} \\sum_{j=1} {m}x_j(1-e }) $$ where \\(\\delta_{j}>0\\) is the difference between \\(t\\) and the timestamps of the transaction that generated \\(I_j\\) and \\(\\gamma\\) is the decay factor. This value \\(d\\) has to be temporarily stored, since it will be used in the aMana update. Pledging aMana . We update the aMana vector adding to node \\(N\\) 's entry the term: $$ \\begin{cases} \\frac{e^{-\\gamma s}-e^{-\\beta s}}{(\\beta-\\gamma)e^{-\\gamma s}}\\beta d,\\text{ if }\\beta\\neq\\gamma;\\ s \\beta d,\\text{ if }\\beta=\\gamma,\\ \\end{cases} $$ where the term \\(d\\) is the same it was added when updating the base aMana vector. Pledging the aMana relative to a transaction with timestamp larger than the last reference time \u00b6 Suppose that the last reference time is \\(t-s\\) and the transaction timestamp is \\(t\\) . The update must be done in three steps, always in the order specified below: Base aMana update with respect to time . Suppose that the last base aMana is \\(\\text{Old\\_Base\\_aMana}\\) . We update all base aMana entries as follows: \\[ \\text{Base\\_aMana}(\\text{Node}_i) = e^{-\\gamma s}\\text{Old\\_Base\\_aMana}(\\text{Node}_i) \\] Base aMana pledging . Suppose that the new transaction consists of \\(m\\) inputs \\(I_1, I_2, \\ldots, I_m\\) of value \\(x_1, x_2, \\ldots, x_m\\) , respectively, and pledges aMana to a node \\(N\\) . We update the base aMana of node \\(N\\) by adding to its base aMana the value $$ d=\\sum_{j=1} {m}x_j(1-e }) $$ where \\(\\delta_{j}>0\\) is the difference between \\(t\\) and the timestamps of the transaction that generated \\(I_j\\) and \\(\\gamma\\) is the decay factor. This value \\(d\\) has to be temporarily stored, since it will be used in the aMana update. Updating the aMana with respect to time . We update all aMana entries as follows: \\[ \\text{ aMana}(\\text{Node}_i)=\\begin{cases} e^{-\\beta s} \\text{Old\\_aMana}(\\text{Node}_i)+\\frac{e^{-\\gamma s}-e^{-\\beta s}}{(\\beta-\\gamma)e^{-\\gamma s}} \\beta\\text{Base\\_aMana}(\\text{Node}_i),\\text{ if }\\beta\\neq\\gamma;\\\\ e^{-\\beta s} \\text{Old\\_aMana}(\\text{Node}_i)+s\\beta\\text{Base\\_aMana}(\\text{Node}_i),\\text{ if }\\beta=\\gamma,\\\\ \\end{cases} \\] where \\(\\beta\\) is the moving average parameter for the aMana and \\(\\gamma\\) is the base aMana decay factor. Notice that, here, the value of \\(\\text{Base\\_aMana(Node}_i)\\) used is the one already updated. Updating the aMana to a time larger than the last reference time without any new aMana pledging. \u00b6 Suppose that the last reference time is \\(t-s\\) and new one is \\(t\\) . The update must be done in two steps, always in the order specified below: Base aMana update with respect to time . Suppose that the outdated base aMana is \\(\\text{Old\\_Base\\_aMana}\\) . We update the base aMana entries as follows: \\[ \\text{Base\\_aMana}(\\text{Node}_i) = e^{-\\gamma s}\\text{Old\\_Base\\_aMana}(\\text{Node}_i) \\] Updating the aMana with respect to time . We update all the aMana entries as follows: \\[ \\text{aMana}(\\text{Node}_i)=\\begin{cases} e^{-\\beta s} \\text{Old\\_aMana}(\\text{Node}_i)+\\frac{e^{-\\gamma s}-e^{-\\beta s}}{(\\beta-\\gamma)e^{-\\gamma s}} \\beta\\text{Base\\_aMana}(\\text{Node}_i),\\text{ if }\\beta\\neq\\gamma;\\\\ e^{-\\beta s} \\text{Old\\_aMana}(\\text{Node}_i)+s\\beta\\text{Base\\_aMana}(\\text{Node}_i),\\text{ if }\\beta=\\gamma,\\\\ \\end{cases} \\] where \\(\\beta\\) is the moving average parameter for the aMana and \\(\\gamma\\) is the base aMana decay factor. Notice that, here, the value of \\(\\text{Base\\_aMana(Node}_i)\\) used is the one already updated. The following data structures and functions must be defined: GetAccessMana() : returns a mapping between all known nodes and their access Mana, calculated at currentTime (which means that the aMana is updated to currentTime when this function is called). UpdateaMana(transaction) : whenever a transaction transaction is added to the ledger state, it updates the aMana vector in order to add the aMana relative to transaction and to the (possibly) new reference time. Initialization \u00b6 The Mana is an extension of the ledger state, hence its calculation depends on the ledger state perception of the node. Snapshotting is the mechanism that stores older ledger states and prunes unnecessary messages. Together with the ledger state, aMana and cMana vectors (and the reference time relative to them) are also saved, since a certain ledger state reflects a certain aMana and cMana distribution in the network. Thus, when a node joins the network, it will query other nodes to get their snapshot file, containing a aMana Snapshot Vector , a cMana Snapshot Vector , and two ACMS (one for each of the last two snapshotted epochs) that will be used as initialization data. Algorithm \u00b6 Parameter Values \u00b6 The following parameters will be used by default, and all nodes must know them. We do not have explicit rules to punish nodes that clearly do not use these parameters, but we expect that they would be eventually ignored, due to other implicit mechanisms. For instance, even if the Mana vectors of a certain node are significantly different from the other nodes' view (causing a divergence from the majority's opinion in the voting protocol), with a very high probability its opinion will not affect the final outcome of the voting. For other modules (like congestion control), a node with a significantly different perception of Mana will be blacklisted and will not harm the network. Thus, the nodes have plenty of incentives to follow the rules. Table 4.3.1 List of Parameters Name Type Description Observation DECAY float decay factor for base aMana Called \\(\\gamma\\) in the last sections. For a half life of ~6 hours we need \\(\\gamma=0.00192541 \\frac{1}{\\text{min}}\\) . C_MANA_EMA_COEFF float moving average factor for the cMana Called \\(\\alpha\\) in the last sections. Set as the same value as \\(\\gamma\\) . A_MANA_EMA_COEFF float moving average factor for the aMana Called \\(\\beta\\) in the last sections. Set as the same value as \\(\\gamma\\) . Local Variables and Built-in Functions \u00b6 Table 4.3.2 Local Variables and Built-in Functions Name Type Description object.cManaNode nodeID Id of the node to which object 's cMana was pledged object.amount double Amount moved by object object.aManaNode nodeID Id of the node to which object 's aMana was pledged transaction.inputs list of inputs IDs List of inputs consumed by transaction transaction.time time Timestamp of transaction nodes list of nodeIDs List of known nodes. epoch.finalTime time Final time of epoch epoch.initialTime time Initial time of epoch epoch.transactions list of TxIds Set of transactions with timestamps in the interval [epoch.initialTime,epoch.finalTime) input.time time Timestamp of the transaction that generated the output relative to input Pseudocode - cMana Update \u00b6 In this section, for the sake of clarity, we introduce an example of code of the functions defined above. UpdateBasecManaTr(transaction) \u00b6 The function UpdateBasecManaTr(transaction) updates the vector basecMana , pledging and revoking the base cMana relative to a transaction transaction . FUNCTION UpdateBasecManaTr ( transaction ) basecMana [ transaction . cManaNode ] = basecMana [ transaction . cManaNode ]+ transaction . amount FOR input in transaction . inputs basecMana [ input . cManaNode ] = basecMana [ input . cManaNode ]- input . amount UpdatecManaTime(epoch) \u00b6 The function UpdatecManaTime(epoch) updates the vector cMana , changing its reference time from the end of epoch-1 to the end of epoch . FUNCTION UpdatecManaTime ( epoch ) n = epoch . finalTime - epoch . initialTime FOR node in nodes cMana [ node ] = exp ( - C_MANA_EMA_COEFF * n ) * cMana [ node ] + ( 1 - exp ( - C_MANA_EMA_COEFF * n )) * basecMana [ node ] UpdatecManaTr(epoch,transaction) \u00b6 The function UpdatecManaTr(epoch,transaction) updates the vector cMana , pledging and revoking the cMana relative to a transaction transaction . FUNCTION UpdatecManaTr ( epoch , transaction ) n = epoch . finalTime - transaction . time FOR node in nodes IF basecMana [ node ] ! = basecManaOld [ node ] cMana [ node ] = cMana [ node ]+ ( 1 - ( 1 - C_MANA_EMA_COEFF ) ** n ) * ( basecMana [ node ]- basecManaOld [ node ] ) UpdatecMana(epoch) \u00b6 The function UpdatecMana(epoch) updates the vectors cMana and basecMana , from the end of epoch-1 to epoch , pledging and revoking the base cMana and cMana relative to all the relevant transactions. FUNCTION UpdatecMana ( epoch ): UpdatecManaTime ( epoch ) IF epoch . transactions ! = NULL : FOR transaction in epoch . transactions : basecManaOld = basecMana UpdateBasecManaTr ( transaction ) UpdatecManaTr ( epoch , transaction ) Pseudocode - aMana Update \u00b6 In this section, for the sake of clarity, we introduce an example of code of the functions defined above. UpdateBaseaManaTime(t) \u00b6 The function UpdateBaseaManaTime(t) updates the vector baseaMana , changing its reference time from lastUpdateTime to t . FUNCTION UpdateBaseaManaTime ( t ) n = t - lastUpdateTime FOR each node i baseaMana [ i ] = baseaMana [ i ]* exp ( - DECAY * n ) UpdateaManaTime(t) \u00b6 The function UpdateaManaTime(t) updates the vector aMana , changing its reference time from lastUpdateTime to t . FUNCTION UpdateaManaTime ( t ) n = t - lastUpdateTime IF DECAY ! = A_MANA_EMA_COEFF FOR each node i aMana [ i ] = exp ( - A_MANA_EMA_COEFF * n ) * aMana [ i ]+ ( 1 - exp (( DECAY - A_MANA_EMA_COEFF ) * n )) / ( A_MANA_EMA_COEFF - DECAY )) * A_MANA_EMA_COEFF * baseaMana [ i ] ELSE FOR each node i aMana [ i ] = exp ( - A_MANA_EMA_COEFF * n ) * aMana [ i ]+ DECAY * A_MANA_EMA_COEFF * baseaMana [ i ] UpdateBaseaManaTr(transaction) \u00b6 The function UpdateBaseaManaTr(t,transaction) updates the vector baseaMana , pledging the base aMana relative to a transaction transaction . FUNCTION UpdateBaseaManaTr ( transaction ) FOR input in transaction . inputs baseaMana [ transaction . aManaNode ] = baseaMana [ transaction . aManaNode ]+ exp ( - DECAY * ( MAX ( transaction . time , lastUpdateTime ) - transaction . time )) * input . amount * ( 1 - exp ( - DECAY * ( transaction . time - input . time ))) UpdateaManaTr(transaction) \u00b6 The function UpdateaManaTr(transaction) updates the vector aMana , pledging the aMana relative to a transaction transaction . FUNCTION UpdateaManaTr ( transaction ): n = lastUpdateTime - transaction . time IF DECAY ! = A_MANA_EMA_COEFF aMana [ transaction . aManaNode ] = aMana [ transaction . aManaNode ]+ ( exp ( - DECAY * n ) - exp ( - A_MANA_EMA_COEFF * n )) / ( A_MANA_EMA_COEFF - DECAY )) * A_MANA_EMA_COEFF * ( baseaMana [ transaction . aManaNode ]- baseaManaOld [ transaction . aManaNode ] ) ELSE aMana [ aManaNode ( transaction ) ] = aMana [ transaction . aManaNode ]+ exp ( - DECAY * n ) * DECAY * A_MANA_EMA_COEFF * ( baseaMana [ transaction . aManaNode ]- baseaManaOld [ transaction . aManaNode ] ) UpdateaMana(transaction) \u00b6 The function UpdateaMana(transaction) updates the vectors aMana and baseaMana , from lastUpdateTime to MAX(lastUpdateTime, transaction.time) , pledging the base aMana and aMana relative to transaction . FUNCTION UpdateaMana ( transaction ): # if the tx is not old , add it and update the vector to t IF transaction . time > lastUpdateTime : UpdateBaseaManaTime ( transaction . time ) UpdateaManaTime ( transaction . time ) UpdateBaseaManaTr ( transaction ) lastUpdateTime = transaction . time # add a transaction in the past IF transaction . time < lastUpdateTime : baseaManaOld = baseaMana UpdateBaseaManaTr ( transaction ) UpdateaManaTr ( transaction )","title":"5.3 Mana"},{"location":"IOTA-NECTAR/5.3%20Mana/#53-mana","text":"","title":"5.3 Mana"},{"location":"IOTA-NECTAR/5.3%20Mana/#introduction","text":"This section introduces access Mana and consensus Mana and determines which modules use each of these two types of Mana. Any permissionless system needs a Sybil protection mechanism. In Coordicide, this is done by forcing every node to create a node identity (see also Section 3.3 - Peer Discovery ). Since the creation of an arbitrarily large number of identities is not an expensive operation, two Difficult-to-obtain resources are linked to each node identity; we call them access Mana ( aMana ) and consensus Mana ( cMana ). Both kinds of Mana can be described as essential resources to multiple parts of the network. They are related to the IOTA token, but are not tokens by themselves and do not interfere with the token balance in any direct way. When a transaction is processed, a certain amount of aMana and cMana\u2014dependent on the amount of IOTAs moved by the transaction\u2014will be pledged to nodes specified in the transaction (their node IDs must be specified as defined in Section 2.3 - Standard Payloads Layout ). The access and consensus Mana pledged to each node ID must be stored as an extension of the ledger state. The only way a node can obtain aMana or cMana is to convince some ken holders to pledge to it. Both kinds of Mana provides adequate Sybil protection because they are difficult and costly to be acquired in arbitrarily large amounts. Access and consensus Mana are used as Sybil protection in different modules, which have different natures and requirements. For this reason, it is natural to use different formulas to calculate the appropriate Mana to each module. Consensus Mana should be seen as the Mana that is responsible for the security of the system, on the other hand, access Mana is used to distribute access to the network during congestion periods. We give a short overview on how each module uses its associated kind of Mana: Section 3.4 - Neighbor Selection : Nodes only establish a connection with nodes of similar consensus Mana. Section 4.6 - Congestion Control : The throughput (in bytes per second) of each node is dependent on the access Mana held. Section 6.3 - Fast Probabilistic Consensus : The selection probability for a node during a voting query is proportional to the consensus Mana held. Section 6.4 - Finalization : Finalization occurs when (among other criteria) a message is approved by nodes holding a certain fraction of the consensus Mana in the network. Section 6.5 - Distributed Random Number Generator : The dRNG committee members must be composed by high consensus Mana nodes.","title":"Introduction"},{"location":"IOTA-NECTAR/5.3%20Mana/#detailed-design-general","text":"Each transaction must have an accessManaNodeID and a consensusManaNodeID field to determine which node to pledge these two types of Mana. Both of these fields consist of a node ID of the node that will receive each kind of Mana. Access Mana and consensus Mana do not have to be pledged to the same node. Both kinds of Mana are exponential moving averages (EMA) of the base Manas (specifically, cMana is the EMA of base cMana, and aMana is the EMA of base aMana). An EMA is a type of moving average that places a greater weight and significance on the most recent data points. More precisely, the weighting for older data decreases exponentially in time, however, never reaching zero. Even though the definition of an EMA should be unique (no matter to which function that you apply it), the general algorithm for the calculation of the EMAs\u2014with the flexibility needed in our case\u2014is not easily implementable. Thus, two different algorithms already customized for each type of Mana are provided in the present document. We define the following parameters: \\(\\gamma\\) - decay factor for base aMana. \\(\\alpha\\) - moving average factor for the cMana. \\(\\beta\\) - moving average factor for the aMana. Additionally, we define four vectors that assign a real value to each node Id: the aMana vector , base aMana vector , cMana vector and base cMana vector . The base aMana vector and the base cMana vector are auxiliary vectors (meaning that they are needed to compute the aMana vector and the cMana vector, even though their values are not directly used in any of the modules). Due to the time dependance of the EMA (and also the base aMana function), the four vectors have a reference time to which they are associated. The Mana vectors are updated in different occasions. Access Mana pledging happens when a transaction is booked on the ledger state. At the same time, entries of the nodes whose aMana is not being modified during the pledging are updated only with respect to the (possibly) newer time reference. In general, updates only due to time (without aMana pledging) happen whenever a node's aMana is being accessed by an external module (as the congestion control, for instance). On the other hand, cMana is updated only relatively to the end of each epoch (see Section 4.2 - Timestamps ). The reason behind this is that epochs are objective, i.e. all nodes agree on which epoch a certain message (or transaction) belongs to. Thus, since nodes agree (with high probability) about transactions with timestamps older than the end of the epoch plus TIMESTAMP_CUTOFF (see Section 4.2 - Timestamps ), they will consequently agree\u2014again, with high probability\u2013about the cMana vector relative to these transactions. Therefore, one can assume that the nodes in sync will (with high probability) agree on values of cMana relative to the set of transactions that have timestamp older than a fixed epoch in the past. On the other hand, aMana will capture recent fluctuations, but nodes are expected to have slightly different perceptions of this quantity.","title":"Detailed Design - General"},{"location":"IOTA-NECTAR/5.3%20Mana/#detailed-design-consensus-mana","text":"The base cMana of a node nodeID at time time is defined as the sum over all unspent outputs at time time of transactions with consensusManaNodeID = nodeID . This means that, when an output is consumed, its cMana pledge is revoked and pledged to a (possibly) different node. See the example below: Example 1: Suppose transaction \\(z\\) was booked and we want to update the base cMana vector accordingly. Additionally, suppose transaction \\(z\\) , \\(x\\) and \\(y\\) pledges cMana to nodes \\(N_z\\) , \\(N_x\\) and \\(N_y\\) , respectively. The update of the base cMana proceeds as follows: Add 300 to the base cMana state of the node \\(N_z\\) . Subtract 100 from the base cMana state of the node \\(N_x\\) . Subtract 200 from the base cMana state of the node \\(N_y\\) . If a transaction \\(T_i\\) with timestamp \\(t_i\\) pledges \\(M_i\\) cMana to a node \\(Z\\) , then the cMana evolution over time relative to this transaction will be given by: \\[ \\text{cMana}_Z^{T_i}(t) = \\begin{cases} 0, \\text{ if } t< t_i \\\\ M_i\\left(1-e^{-\\alpha (t-t_i)}\\right), \\text{ if } t\\geq t_i \\\\ \\end{cases} \\] The total cMana of a node \\(Z\\) will be, then, given by the sum of \\(\\text{cMana}_Z^{T_i}(t)\\) among all the transactions \\(T_i\\) that pledge cMana to node \\(Z\\) . Nevertheless, computing the mana using this equation may be excessively demanding in the case where a node has multiples pledges at different times. For that reason, the cMana shall be computed recursively, updating it based on its last value. This update is customized for three different situations (here, \\(t_0\\) is the reference time of the previous cMana value): pledging of the cMana relative to a transaction with timestamp smaller than \\(t_0\\) . pledging of the cMana relative to a transaction with timestamp larger than \\(t_0\\) . updating the cMana to a time \\(t_1>t_0\\) without any new cMana pledging. In the first case, the reference time of the cMana must not be changed, whereas in the second case, the reference time of the cMana must be changed to the timestamp of the transaction. This means that a node must never update the cMana to a point in the past (relatively to the last cMana calculated). The exact update procedure for each of the cases defined above are defined next.","title":"Detailed Design - Consensus Mana"},{"location":"IOTA-NECTAR/5.3%20Mana/#consensus-mana-update-procedure","text":"","title":"Consensus Mana update procedure"},{"location":"IOTA-NECTAR/5.3%20Mana/#pledging-the-cmana-relative-to-a-transaction-with-timestamp-smaller-than-the-last-reference-time","text":"Suppose that the last reference time is \\(t\\) and the transaction timestamp is \\(t-s\\) . The update must be done in two steps, always in the order specified below: a ) Base cMana update . Just before updating the base cMana vector we must store it, since the last base cMana state (that we call \\(\\text{Old\\_Base\\_cMana}\\) ) and the time relative to the last update are used later for the cMana calculations. This temporary vector can be deleted right after the cMana vector is updated. The update of the base cMana state goes as follows: if a new transaction with \\(n\\) inputs of values \\(x_1, x_2, \\ldots, x_n\\) pledges cMana to a node \\(N\\) , then 1. we add \\(\\sum_{j=1}^{n}x_j\\) to the base cMana of the node \\(N\\) . 2. Each input \\(I_j\\) corresponds to some UTXO (and, consequently, to some transaction) stored in the ledger state. Then, we locate the node Id (let us say, \\(\\text{Node}_j\\) ) to whom the cMana relative to this output was pledged to in the past. Then, we subtract \\(x_j\\) from the base cMana state of the node \\(\\text{Node}_j\\) , for each \\(I_j\\) , \\(j=1,\\dots,n\\) . b ) Pledging and revoking cMana . If the base cMana balance of node \\(i\\) (before we added this transaction) was \\(\\text{Old\\_Base\\_cMana}(\\text{Node}_i)\\) and the new base cMana balance (after the addition of this transaction) is \\(\\text{Base\\_cMana}(\\text{Node}_i)\\) , then we update the cMana vector adding to all nodes' entry the term: \\[ (1-e^{-\\alpha s})[\\text{Base\\_cMana}(\\text{Node}_i)-\\text{Old\\_Base\\_cMana}(\\text{Node}_i)] \\] The term above can be negative\u2014since some nodes have their base cMana revoked\u2014but the resulting cMana must not be. Notice that for most nodes (specifically, for all nodes that did not have their base cMana value changed) the value above is zero.","title":"Pledging the cMana relative to a transaction with timestamp smaller than the last reference time"},{"location":"IOTA-NECTAR/5.3%20Mana/#pledging-the-cmana-relative-to-a-transaction-with-timestamp-larger-than-the-last-reference-time","text":"Suppose that the last reference time is \\(t-s\\) and the transaction timestamp is \\(t\\) . The update must be done in two steps, always in the order specified below: a ) Base cMana update . Just before updating the base cMana vector we must store it, since the last base cMana state (that we call \\(\\text{Old\\_Base\\_cMana}\\) ) and the time relative to the last update are used later for the cMana calculations. This temporary vector can be deleted right after the cMana vector is updated. The update of the base cMana state goes as follows: if a new transaction with \\(n\\) inputs of respective values \\(x_1, x_2, \\ldots, x_n\\) pledges cMana to a node \\(N\\) , then 1. we add \\(\\sum_{j=1}^{n}x_j\\) to the base cMana of the node \\(N\\) . 2. Each input \\(I_j\\) corresponds to some UTXO (and, consequently, to some transaction) stored in the ledger state. Then, we locate the node Id (let us say, \\(\\text{Node}_j\\) ) to whom the cMana relative to this output was pledged to in the past. Then, we subtract \\(x_j\\) from the base cMana state of the node \\(\\text{Node}_j\\) , for each \\(I_j\\) , \\(j=1,\\dots,n\\) . b ) Updating the cMana with respect to time . Suppose that the outdated cMana is \\(\\text{Old\\_cMana}\\) . We update all cMana entries as follows: $$ \\text{cMana}(\\text{Node}_i)=e^{-\\alpha s} \\text{Old_cMana}(\\text{Node}_i)+(1-e^{-\\alpha s})\\text{Old_Base_cMana}(\\text{Node}_i) $$ where \\(\\alpha\\) is the moving average parameter for the cMana.","title":"Pledging the cMana relative to a transaction with timestamp larger than the last reference time"},{"location":"IOTA-NECTAR/5.3%20Mana/#updating-the-cmana-to-a-time-larger-than-the-last-reference-time-without-any-new-cmana-pledging","text":"Suppose that the last reference time is \\(t-s\\) , the new one is \\(t\\) and the last cMana vector is \\(\\text{Old\\_cMana}\\) . We update all cMana entries as follows: Suppose that the last reference time is \\(t-s\\) , the new one is \\(t\\) and the last cMana vector is \\(\\text{Old\\_cMana}\\) . We update all cMana entries as follows: $$ \\text{cMana}(\\text{Node}_i)=e^{-\\alpha s} \\text{Old_cMana}(\\text{Node}_i)+(1-e^{-\\alpha s})\\text{Old_Base_cMana}(\\text{Node}_i) $$ where \\(\\alpha\\) is the moving average parameter for the cMana.","title":"Updating the cMana to a time larger than the last reference time without any new cMana pledging"},{"location":"IOTA-NECTAR/5.3%20Mana/#4332-active-consensus-mana-and-epochs","text":"The consensus Mana of a node is only calculated and stored relatively to the end of each epoch (see Section 4.2 - Timestamps ). Only the values of the last MAX_STORED_EPOCHS epochs are stored. Thus, if \\(t_E\\) is the time of the end of epoch \\(E\\) , to update the cMana vector from epoch \\(E-1\\) to \\(E\\) , a node must perform the following algorithm: Update the cMana with respect to time, as described in section 4.3.3.1.3, from time \\(t_{E-1}\\) to \\(t_{E}\\) For each transaction with timestamp in the interval \\([t_{E-1},t_{E})\\) , perform (as described in section 4.3.3.1.1) the base cMana update and the pledge and revoking of cMana, while the reference time \\(t_{E}\\) remains constant. Additionally, we define the active consensus Mana of a node A in epoch E (i.e., relatively to time \\(t_{E}\\) ) as (here, \\(\\text{cMana}\\) is also relative to time \\(t_{E}\\) ): \\[ \\text{Active\\_cMana}(\\text{Node A})=\\begin{cases} \\text{cMana}(\\text{Node A}), \\text{ if there is at least one message from node `node` with timestamp in }[t_{E-1},t_{E}) \\\\ 0, \\text{ otherwise} \\end{cases} \\] Therefore, even if node node has consensus Mana greater than zero at a certain epoch \\(E\\) , it can be considered dormant in case it did not issue any message during the same epoch. All nodes that have active consensus Mana in epoch \\(E\\) will form what we call the active consensus Mana set of that epoch, or ACMS(E) . Both calculations defined above (cMana and active cMana on an epoch \\(E\\) ) can only be carried out when epoch \\(E\\) is finalized\u2014that is, at least TIMESTAMP_CUTOFF (see Section 4.2 - Timestamps ) units of time after \\(t_E\\) \u2014to make sure that no more messages belonging to the epoch will appear in the network. The following data structures and functions must be defined: UpdatecMana(epoch) : updates the base cMana and cMana vectors from the end of epoch-1 to epoch , pledging and revoking the base cMana and cMana relative to all the relevant transactions. GetActiveConsensusMana(time) : returns a mapping between all known nodes and their active cMana, calculated at the end of the epoch that contains time . ManaRank(lowerMana, upperMana, epoch) : returns the node ID of the nodes with active cMana in the interval [lowerMana, upperMana] , relative to epoch . Notice that epoch must be, at least, the current epoch minus MAX_STORED_EPOCHS and, at most, the last epoch.","title":"4.3.3.2 Active Consensus Mana and Epochs"},{"location":"IOTA-NECTAR/5.3%20Mana/#detailed-design-access-mana","text":"When an output is consumed and funds are consequently transferred, a certain amount of base aMana\u2014dependent on the amount of funds and the age of the output\u2014will be pledged to a node. This pledge is never revoked, as opposed to base cMana. Nevertheless, the base aMana of all nodes will decay over time, which means that all the calculations for aMana will be slightly different than for cMana. The base aMana at time \\(t\\) , relative to an output \\(T_i\\) (of amount \\(M_i\\) ) consumed by a transaction with timestamp \\(t-s\\) and generated by a transaction with timestamp \\(t-s-\\delta\\) is, for \\(s,\\delta>0\\) \\[ \\text{Base\\_aMana}^{T_i}(t)= M (1-e^{-\\gamma \\delta}) e^{-\\gamma s}, \\text{ if } t\\geq t-s \\] If this same output pledges aMana to a node \\(Z\\) , then the aMana evolution over time (again, for \\(s,\\delta>0\\) ) relative to it will be given by: \\[ \\text{aMana}_Z^{T_i}(t) = \\begin{cases} M_i(1-e^{-\\gamma\\delta})\\dfrac{\\beta e^{-\\beta s}}{\\beta-\\gamma}\\left(e^{(\\beta-\\gamma)s}-1\\right), \\text{ if }\\beta\\neq \\gamma\\\\ M_i(1-e^{-\\gamma\\delta})\\gamma s e^{-\\gamma s}, \\text{ if } \\beta= \\gamma\\\\ \\end{cases} \\] The base aMana of a node nodeID at time time is defined as the sum of the individual base aMana generated by all already consumed outputs \\(T_i\\) of transactions with accessManaNodeID = nodeID and timestamp smaller or equal than time . Nevertheless, as in the cMana case, computing the aMana using this equation can be excessively demanding. For that reason, the aMana shall computed recursively, updating it based on its last value. This update is customized for three different situations (here, \\(t_0\\) is the reference time of the last aMana value): pledging of the aMana relative to a transaction with timestamp smaller than \\(t_0\\) ; pledging of the aMana relative to a transaction with timestamp larger than \\(t_0\\) ; updating the aMana to a time \\(t_1>t_0\\) without any new aMana pledging. In the first case, the reference time of the aMana must not be changed, whereas in the second case, the reference time of the cMana must be changed to the timestamp of the transaction. This means that a node must never update the aMana to a point in the past (relatively to the last aMana calculated). The exact update procedure for each of the cases defined above are defined next.","title":"Detailed Design - Access Mana"},{"location":"IOTA-NECTAR/5.3%20Mana/#access-mana-update-procedure","text":"","title":"Access Mana update procedure"},{"location":"IOTA-NECTAR/5.3%20Mana/#pledging-the-amana-relative-to-a-transaction-with-timestamp-smaller-than-the-last-reference-time","text":"Suppose that the last reference time is \\(t\\) and the transaction timestamp is \\(t-s\\) . The update must be done in two steps, always in the order specified below: Base aMana pledging . Suppose that the new transaction consists of \\(m\\) inputs \\(I_1, I_2, \\ldots, I_m\\) of value \\(x_1, x_2, \\ldots, x_m\\) \u2014respectively\u2014and pledges aMana to a node \\(N\\) . We update the base aMana of node \\(N\\) by adding to its base aMana the value $$ d=e^{-\\gamma s} \\sum_{j=1} {m}x_j(1-e }) $$ where \\(\\delta_{j}>0\\) is the difference between \\(t\\) and the timestamps of the transaction that generated \\(I_j\\) and \\(\\gamma\\) is the decay factor. This value \\(d\\) has to be temporarily stored, since it will be used in the aMana update. Pledging aMana . We update the aMana vector adding to node \\(N\\) 's entry the term: $$ \\begin{cases} \\frac{e^{-\\gamma s}-e^{-\\beta s}}{(\\beta-\\gamma)e^{-\\gamma s}}\\beta d,\\text{ if }\\beta\\neq\\gamma;\\ s \\beta d,\\text{ if }\\beta=\\gamma,\\ \\end{cases} $$ where the term \\(d\\) is the same it was added when updating the base aMana vector.","title":"Pledging the aMana relative to a transaction with timestamp smaller than the last reference time"},{"location":"IOTA-NECTAR/5.3%20Mana/#pledging-the-amana-relative-to-a-transaction-with-timestamp-larger-than-the-last-reference-time","text":"Suppose that the last reference time is \\(t-s\\) and the transaction timestamp is \\(t\\) . The update must be done in three steps, always in the order specified below: Base aMana update with respect to time . Suppose that the last base aMana is \\(\\text{Old\\_Base\\_aMana}\\) . We update all base aMana entries as follows: \\[ \\text{Base\\_aMana}(\\text{Node}_i) = e^{-\\gamma s}\\text{Old\\_Base\\_aMana}(\\text{Node}_i) \\] Base aMana pledging . Suppose that the new transaction consists of \\(m\\) inputs \\(I_1, I_2, \\ldots, I_m\\) of value \\(x_1, x_2, \\ldots, x_m\\) , respectively, and pledges aMana to a node \\(N\\) . We update the base aMana of node \\(N\\) by adding to its base aMana the value $$ d=\\sum_{j=1} {m}x_j(1-e }) $$ where \\(\\delta_{j}>0\\) is the difference between \\(t\\) and the timestamps of the transaction that generated \\(I_j\\) and \\(\\gamma\\) is the decay factor. This value \\(d\\) has to be temporarily stored, since it will be used in the aMana update. Updating the aMana with respect to time . We update all aMana entries as follows: \\[ \\text{ aMana}(\\text{Node}_i)=\\begin{cases} e^{-\\beta s} \\text{Old\\_aMana}(\\text{Node}_i)+\\frac{e^{-\\gamma s}-e^{-\\beta s}}{(\\beta-\\gamma)e^{-\\gamma s}} \\beta\\text{Base\\_aMana}(\\text{Node}_i),\\text{ if }\\beta\\neq\\gamma;\\\\ e^{-\\beta s} \\text{Old\\_aMana}(\\text{Node}_i)+s\\beta\\text{Base\\_aMana}(\\text{Node}_i),\\text{ if }\\beta=\\gamma,\\\\ \\end{cases} \\] where \\(\\beta\\) is the moving average parameter for the aMana and \\(\\gamma\\) is the base aMana decay factor. Notice that, here, the value of \\(\\text{Base\\_aMana(Node}_i)\\) used is the one already updated.","title":"Pledging the aMana relative to a transaction with timestamp larger than the last reference time"},{"location":"IOTA-NECTAR/5.3%20Mana/#updating-the-amana-to-a-time-larger-than-the-last-reference-time-without-any-new-amana-pledging","text":"Suppose that the last reference time is \\(t-s\\) and new one is \\(t\\) . The update must be done in two steps, always in the order specified below: Base aMana update with respect to time . Suppose that the outdated base aMana is \\(\\text{Old\\_Base\\_aMana}\\) . We update the base aMana entries as follows: \\[ \\text{Base\\_aMana}(\\text{Node}_i) = e^{-\\gamma s}\\text{Old\\_Base\\_aMana}(\\text{Node}_i) \\] Updating the aMana with respect to time . We update all the aMana entries as follows: \\[ \\text{aMana}(\\text{Node}_i)=\\begin{cases} e^{-\\beta s} \\text{Old\\_aMana}(\\text{Node}_i)+\\frac{e^{-\\gamma s}-e^{-\\beta s}}{(\\beta-\\gamma)e^{-\\gamma s}} \\beta\\text{Base\\_aMana}(\\text{Node}_i),\\text{ if }\\beta\\neq\\gamma;\\\\ e^{-\\beta s} \\text{Old\\_aMana}(\\text{Node}_i)+s\\beta\\text{Base\\_aMana}(\\text{Node}_i),\\text{ if }\\beta=\\gamma,\\\\ \\end{cases} \\] where \\(\\beta\\) is the moving average parameter for the aMana and \\(\\gamma\\) is the base aMana decay factor. Notice that, here, the value of \\(\\text{Base\\_aMana(Node}_i)\\) used is the one already updated. The following data structures and functions must be defined: GetAccessMana() : returns a mapping between all known nodes and their access Mana, calculated at currentTime (which means that the aMana is updated to currentTime when this function is called). UpdateaMana(transaction) : whenever a transaction transaction is added to the ledger state, it updates the aMana vector in order to add the aMana relative to transaction and to the (possibly) new reference time.","title":"Updating the aMana to a time larger than the last reference time without any new aMana pledging."},{"location":"IOTA-NECTAR/5.3%20Mana/#initialization","text":"The Mana is an extension of the ledger state, hence its calculation depends on the ledger state perception of the node. Snapshotting is the mechanism that stores older ledger states and prunes unnecessary messages. Together with the ledger state, aMana and cMana vectors (and the reference time relative to them) are also saved, since a certain ledger state reflects a certain aMana and cMana distribution in the network. Thus, when a node joins the network, it will query other nodes to get their snapshot file, containing a aMana Snapshot Vector , a cMana Snapshot Vector , and two ACMS (one for each of the last two snapshotted epochs) that will be used as initialization data.","title":"Initialization"},{"location":"IOTA-NECTAR/5.3%20Mana/#algorithm","text":"","title":"Algorithm"},{"location":"IOTA-NECTAR/5.3%20Mana/#parameter-values","text":"The following parameters will be used by default, and all nodes must know them. We do not have explicit rules to punish nodes that clearly do not use these parameters, but we expect that they would be eventually ignored, due to other implicit mechanisms. For instance, even if the Mana vectors of a certain node are significantly different from the other nodes' view (causing a divergence from the majority's opinion in the voting protocol), with a very high probability its opinion will not affect the final outcome of the voting. For other modules (like congestion control), a node with a significantly different perception of Mana will be blacklisted and will not harm the network. Thus, the nodes have plenty of incentives to follow the rules. Table 4.3.1 List of Parameters Name Type Description Observation DECAY float decay factor for base aMana Called \\(\\gamma\\) in the last sections. For a half life of ~6 hours we need \\(\\gamma=0.00192541 \\frac{1}{\\text{min}}\\) . C_MANA_EMA_COEFF float moving average factor for the cMana Called \\(\\alpha\\) in the last sections. Set as the same value as \\(\\gamma\\) . A_MANA_EMA_COEFF float moving average factor for the aMana Called \\(\\beta\\) in the last sections. Set as the same value as \\(\\gamma\\) .","title":"Parameter Values"},{"location":"IOTA-NECTAR/5.3%20Mana/#local-variables-and-built-in-functions","text":"Table 4.3.2 Local Variables and Built-in Functions Name Type Description object.cManaNode nodeID Id of the node to which object 's cMana was pledged object.amount double Amount moved by object object.aManaNode nodeID Id of the node to which object 's aMana was pledged transaction.inputs list of inputs IDs List of inputs consumed by transaction transaction.time time Timestamp of transaction nodes list of nodeIDs List of known nodes. epoch.finalTime time Final time of epoch epoch.initialTime time Initial time of epoch epoch.transactions list of TxIds Set of transactions with timestamps in the interval [epoch.initialTime,epoch.finalTime) input.time time Timestamp of the transaction that generated the output relative to input","title":"Local Variables and Built-in Functions"},{"location":"IOTA-NECTAR/5.3%20Mana/#pseudocode-cmana-update","text":"In this section, for the sake of clarity, we introduce an example of code of the functions defined above.","title":"Pseudocode - cMana Update"},{"location":"IOTA-NECTAR/5.3%20Mana/#updatebasecmanatrtransaction","text":"The function UpdateBasecManaTr(transaction) updates the vector basecMana , pledging and revoking the base cMana relative to a transaction transaction . FUNCTION UpdateBasecManaTr ( transaction ) basecMana [ transaction . cManaNode ] = basecMana [ transaction . cManaNode ]+ transaction . amount FOR input in transaction . inputs basecMana [ input . cManaNode ] = basecMana [ input . cManaNode ]- input . amount","title":"UpdateBasecManaTr(transaction)"},{"location":"IOTA-NECTAR/5.3%20Mana/#updatecmanatimeepoch","text":"The function UpdatecManaTime(epoch) updates the vector cMana , changing its reference time from the end of epoch-1 to the end of epoch . FUNCTION UpdatecManaTime ( epoch ) n = epoch . finalTime - epoch . initialTime FOR node in nodes cMana [ node ] = exp ( - C_MANA_EMA_COEFF * n ) * cMana [ node ] + ( 1 - exp ( - C_MANA_EMA_COEFF * n )) * basecMana [ node ]","title":"UpdatecManaTime(epoch)"},{"location":"IOTA-NECTAR/5.3%20Mana/#updatecmanatrepochtransaction","text":"The function UpdatecManaTr(epoch,transaction) updates the vector cMana , pledging and revoking the cMana relative to a transaction transaction . FUNCTION UpdatecManaTr ( epoch , transaction ) n = epoch . finalTime - transaction . time FOR node in nodes IF basecMana [ node ] ! = basecManaOld [ node ] cMana [ node ] = cMana [ node ]+ ( 1 - ( 1 - C_MANA_EMA_COEFF ) ** n ) * ( basecMana [ node ]- basecManaOld [ node ] )","title":"UpdatecManaTr(epoch,transaction)"},{"location":"IOTA-NECTAR/5.3%20Mana/#updatecmanaepoch","text":"The function UpdatecMana(epoch) updates the vectors cMana and basecMana , from the end of epoch-1 to epoch , pledging and revoking the base cMana and cMana relative to all the relevant transactions. FUNCTION UpdatecMana ( epoch ): UpdatecManaTime ( epoch ) IF epoch . transactions ! = NULL : FOR transaction in epoch . transactions : basecManaOld = basecMana UpdateBasecManaTr ( transaction ) UpdatecManaTr ( epoch , transaction )","title":"UpdatecMana(epoch)"},{"location":"IOTA-NECTAR/5.3%20Mana/#pseudocode-amana-update","text":"In this section, for the sake of clarity, we introduce an example of code of the functions defined above.","title":"Pseudocode - aMana Update"},{"location":"IOTA-NECTAR/5.3%20Mana/#updatebaseamanatimet","text":"The function UpdateBaseaManaTime(t) updates the vector baseaMana , changing its reference time from lastUpdateTime to t . FUNCTION UpdateBaseaManaTime ( t ) n = t - lastUpdateTime FOR each node i baseaMana [ i ] = baseaMana [ i ]* exp ( - DECAY * n )","title":"UpdateBaseaManaTime(t)"},{"location":"IOTA-NECTAR/5.3%20Mana/#updateamanatimet","text":"The function UpdateaManaTime(t) updates the vector aMana , changing its reference time from lastUpdateTime to t . FUNCTION UpdateaManaTime ( t ) n = t - lastUpdateTime IF DECAY ! = A_MANA_EMA_COEFF FOR each node i aMana [ i ] = exp ( - A_MANA_EMA_COEFF * n ) * aMana [ i ]+ ( 1 - exp (( DECAY - A_MANA_EMA_COEFF ) * n )) / ( A_MANA_EMA_COEFF - DECAY )) * A_MANA_EMA_COEFF * baseaMana [ i ] ELSE FOR each node i aMana [ i ] = exp ( - A_MANA_EMA_COEFF * n ) * aMana [ i ]+ DECAY * A_MANA_EMA_COEFF * baseaMana [ i ]","title":"UpdateaManaTime(t)"},{"location":"IOTA-NECTAR/5.3%20Mana/#updatebaseamanatrtransaction","text":"The function UpdateBaseaManaTr(t,transaction) updates the vector baseaMana , pledging the base aMana relative to a transaction transaction . FUNCTION UpdateBaseaManaTr ( transaction ) FOR input in transaction . inputs baseaMana [ transaction . aManaNode ] = baseaMana [ transaction . aManaNode ]+ exp ( - DECAY * ( MAX ( transaction . time , lastUpdateTime ) - transaction . time )) * input . amount * ( 1 - exp ( - DECAY * ( transaction . time - input . time )))","title":"UpdateBaseaManaTr(transaction)"},{"location":"IOTA-NECTAR/5.3%20Mana/#updateamanatrtransaction","text":"The function UpdateaManaTr(transaction) updates the vector aMana , pledging the aMana relative to a transaction transaction . FUNCTION UpdateaManaTr ( transaction ): n = lastUpdateTime - transaction . time IF DECAY ! = A_MANA_EMA_COEFF aMana [ transaction . aManaNode ] = aMana [ transaction . aManaNode ]+ ( exp ( - DECAY * n ) - exp ( - A_MANA_EMA_COEFF * n )) / ( A_MANA_EMA_COEFF - DECAY )) * A_MANA_EMA_COEFF * ( baseaMana [ transaction . aManaNode ]- baseaManaOld [ transaction . aManaNode ] ) ELSE aMana [ aManaNode ( transaction ) ] = aMana [ transaction . aManaNode ]+ exp ( - DECAY * n ) * DECAY * A_MANA_EMA_COEFF * ( baseaMana [ transaction . aManaNode ]- baseaManaOld [ transaction . aManaNode ] )","title":"UpdateaManaTr(transaction)"},{"location":"IOTA-NECTAR/5.3%20Mana/#updateamanatransaction","text":"The function UpdateaMana(transaction) updates the vectors aMana and baseaMana , from lastUpdateTime to MAX(lastUpdateTime, transaction.time) , pledging the base aMana and aMana relative to transaction . FUNCTION UpdateaMana ( transaction ): # if the tx is not old , add it and update the vector to t IF transaction . time > lastUpdateTime : UpdateBaseaManaTime ( transaction . time ) UpdateaManaTime ( transaction . time ) UpdateBaseaManaTr ( transaction ) lastUpdateTime = transaction . time # add a transaction in the past IF transaction . time < lastUpdateTime : baseaManaOld = baseaMana UpdateBaseaManaTr ( transaction ) UpdateaManaTr ( transaction )","title":"UpdateaMana(transaction)"},{"location":"IOTA-NECTAR/6.1%20Objects%20of%20Consensus/","text":"6.1 Objects of Consensus \u00b6 6.1.1 Preliminaries \u00b6 6.1.1.1 Motivation \u00b6 FPC is a binary voting protocol where each node starts with an initial opinion (a nulled boolean) on an object. Nodes then exchange queries and responses about their opinions during several rounds, until each node terminates with a final boolean value: see specification ??? . FPC votes on two specific objects types: messages, in order to enforce timestamps, and transactions, in order to decide double spends. Additionally, applications can use FPC to query opinions about their opinion on other object types, although there is no guarantee that they will get a response. The FPC is agnostic about the rest of the protocol, particularly the questions being decided voting and how the initial opinions are set. We require a generic way for FPC to interact with data structures in other applications. Specifically, an application needs a way to trigger FPC run. Deciding when FPC should run is a delicate question for two reasons. 1. It is inefficient for FPC to vote on every single transaction. 2. If only a sub set of nodes participate in FPC, they are more vulnerable to attack since the consensus mana held by this collection of nodes is potentially much smaller. Thus, since it cannot vote on everything, it must use subjective criterion to trigger voting which does not leave any group vulnerable to attack. Voting is a two-part process: querying and answering queries. The function QueryStatus determines if a node should query about a particular object, and the function AnswerStatus determines if the node should respond. 6.1.1.2 Summary \u00b6 This specification describes how this binary voting protocol interacts with the rest of the IOTA protocol. Specifically, we define two functions, QueryStatus and AnswerStatus which govern when an object should be included in a query or response respectively. These functions depend on the metatdata opinionField which is also defined in this specification. This specification only includes the format on how applications requiring FPC should interact with it, not how to set initial opinions or, more specifically, opinionField . For this information, see ??? . 6.1.1.3 Dependencies \u00b6 This specification depends on the following specifications + FPC ??? + Opinion Setting ??? 6.1.1.4 Parameters and lists \u00b6 Name Type Description DSMALL duration small estimated network delay, set to 5 seconds votingEnabledObjectTypes list object types which will be voted upon 6.1.2 Detailed design \u00b6 6.1.2.1 Voting Objects list \u00b6 FPC can potentially vote on a variety of matters. The votingEnabledObjectTypes effectively lists which things will be voted upon by listing the object types which must be queried by FPC. Specifically, when FPC prepares a query, it iterates through each object type, and then finds which objects of that type it must include in the query. By default, the object types message and transaction are in the list votingEnabledObjectTypes . However, a second layer application can add other object types to this list, allowing other applications to use FPC. These applications will have no guarantee that they will receive responses with about custom object types, particularly if the application is not widely used. 6.1.2.2 How opinions on objects are stored \u00b6 For every object whose type is in votingEnabledObjectTypes , that the local meta data stored with the object must include an opinionField which is either NULL or the triplet (opinion,level,timeFormed) . The field opinion is a nullable boolean value, level is a number in the list \\(\\{1,2,3\\}\\) , and timeFormed is the time the field was changed from NULL . As will be discussed in a different specification, an opinion field will be NULL until the node has received information allowing it to form an opinion, e.g. detect a conflict. For example, a transaction should have opinion field NULL until a conflict is detected. Such transactions should be considered \"good\", and, in the honest setting, most transactions will have a NULL opinion. 6.1.2.3 Query Status \u00b6 When FPC prepares a query, see the FPC specification, it shall determine which objects to include. Conceptually, for each type in votingEnabledObjectTypes , the node shall iterate through all objects of that type and individually decide if that object is to be included in the query. Clearly, this iteration would be inefficient expensive, and a node can use some method to speed up the process. However, this is an implementation detail and thus beyond the scope of this document. To determine whether or not each object should be included into a query, a node shall apply the following QueryStatus function. If the function returns true, then the object should be included into the query. FUNCTION Bool = QueryStatus ( type , objectID ) IF type not in VotingEnabledObjectTypes RETURN FALSE ELSE IF opinionField ! = NULL AND level = 1 and currentTime > timeFormed + DSMALL RETURN TRUE ELSE RETURN FALSE IF the object does not exist RETURN ` FALSE ` . When FPC succesfully stops voting on an object, it sets in the opinionField the opinion to the final opinion and modifies level to 2 so that QueryStatus returns false. 6.1.2.4 Answer Status \u00b6 Every time FPC receives a query request, it checks whether or not it should reply; see FPC . To do so, it applies the following AnswerStatus function to object in the query request to determine if a response should be made. If AnswerStatus returns FALSE for any object in the query request, a query response will not be prepared. FUNCTION Bool = AnswerStatus ( type , objectID ) If type not in VotingEnabledObjectTypes RETURN FALSE ELSE IF opinionField not = NULL AND ( level = 1 OR level = 2 ) RETURN TRUE ELSE RETURN FALSE Lastly, if the object does not exist, the function should return FALSE . 6.1.3 Rationale and Alternatives \u00b6 The level field indicates the level of knowledge. It tells us information about what other nodes know. * Level 1 means that the node only knows that it holds this opinion. * Level 2 means that the node knows that all nodes have this opinion too (with high probability). * Level 3 means that the node knows that all nodes have level 2 knowledge (with high probability). If a node node only has level 1 knowledge, it needs to vote. However, if it has level 2 knowledge, it does not need to query as it knows that all nodes have the same opinion. With level 3 knowledge, it knows that no other nodes have level 2 knowledge and thus should not send its node queries. Thus, with level 3 knowledge, the node does not need to respond. The level of knowledge is the primary criterion in these functions. Moreover, we should not query about objects whose opinion is NULL . In a similar vein, we need should not query about an object until d time after the opinion was set, so we can be sure that all other nodes have set their opinion too. Alternatively, we can attempt to manage the same system with a series of finality flags. However, this has two problems. First, we either mark objects which we have never voted upon as final, or some objects will never get a finality flag. This leads to some complicated, unintuitive logic. Second, if an attacker can cause only small portions of the network to vote on an object, that vote would be susceptible to an attack. Thus we need consensus about what to vote on. However, if voting is a binary \"yes\" or \"no\", we would need a consensus algorithm to determine when to vote. The levels of knowledge does not treat voting in a binary way, bypassing this problem.","title":"6.1 Objects of Consensus"},{"location":"IOTA-NECTAR/6.1%20Objects%20of%20Consensus/#61-objects-of-consensus","text":"","title":"6.1 Objects of Consensus"},{"location":"IOTA-NECTAR/6.1%20Objects%20of%20Consensus/#611-preliminaries","text":"","title":"6.1.1 Preliminaries"},{"location":"IOTA-NECTAR/6.1%20Objects%20of%20Consensus/#6111-motivation","text":"FPC is a binary voting protocol where each node starts with an initial opinion (a nulled boolean) on an object. Nodes then exchange queries and responses about their opinions during several rounds, until each node terminates with a final boolean value: see specification ??? . FPC votes on two specific objects types: messages, in order to enforce timestamps, and transactions, in order to decide double spends. Additionally, applications can use FPC to query opinions about their opinion on other object types, although there is no guarantee that they will get a response. The FPC is agnostic about the rest of the protocol, particularly the questions being decided voting and how the initial opinions are set. We require a generic way for FPC to interact with data structures in other applications. Specifically, an application needs a way to trigger FPC run. Deciding when FPC should run is a delicate question for two reasons. 1. It is inefficient for FPC to vote on every single transaction. 2. If only a sub set of nodes participate in FPC, they are more vulnerable to attack since the consensus mana held by this collection of nodes is potentially much smaller. Thus, since it cannot vote on everything, it must use subjective criterion to trigger voting which does not leave any group vulnerable to attack. Voting is a two-part process: querying and answering queries. The function QueryStatus determines if a node should query about a particular object, and the function AnswerStatus determines if the node should respond.","title":"6.1.1.1 Motivation"},{"location":"IOTA-NECTAR/6.1%20Objects%20of%20Consensus/#6112-summary","text":"This specification describes how this binary voting protocol interacts with the rest of the IOTA protocol. Specifically, we define two functions, QueryStatus and AnswerStatus which govern when an object should be included in a query or response respectively. These functions depend on the metatdata opinionField which is also defined in this specification. This specification only includes the format on how applications requiring FPC should interact with it, not how to set initial opinions or, more specifically, opinionField . For this information, see ??? .","title":"6.1.1.2 Summary"},{"location":"IOTA-NECTAR/6.1%20Objects%20of%20Consensus/#6113-dependencies","text":"This specification depends on the following specifications + FPC ??? + Opinion Setting ???","title":"6.1.1.3 Dependencies"},{"location":"IOTA-NECTAR/6.1%20Objects%20of%20Consensus/#6114-parameters-and-lists","text":"Name Type Description DSMALL duration small estimated network delay, set to 5 seconds votingEnabledObjectTypes list object types which will be voted upon","title":"6.1.1.4 Parameters and lists"},{"location":"IOTA-NECTAR/6.1%20Objects%20of%20Consensus/#612-detailed-design","text":"","title":"6.1.2 Detailed design"},{"location":"IOTA-NECTAR/6.1%20Objects%20of%20Consensus/#6121-voting-objects-list","text":"FPC can potentially vote on a variety of matters. The votingEnabledObjectTypes effectively lists which things will be voted upon by listing the object types which must be queried by FPC. Specifically, when FPC prepares a query, it iterates through each object type, and then finds which objects of that type it must include in the query. By default, the object types message and transaction are in the list votingEnabledObjectTypes . However, a second layer application can add other object types to this list, allowing other applications to use FPC. These applications will have no guarantee that they will receive responses with about custom object types, particularly if the application is not widely used.","title":"6.1.2.1 Voting Objects list"},{"location":"IOTA-NECTAR/6.1%20Objects%20of%20Consensus/#6122-how-opinions-on-objects-are-stored","text":"For every object whose type is in votingEnabledObjectTypes , that the local meta data stored with the object must include an opinionField which is either NULL or the triplet (opinion,level,timeFormed) . The field opinion is a nullable boolean value, level is a number in the list \\(\\{1,2,3\\}\\) , and timeFormed is the time the field was changed from NULL . As will be discussed in a different specification, an opinion field will be NULL until the node has received information allowing it to form an opinion, e.g. detect a conflict. For example, a transaction should have opinion field NULL until a conflict is detected. Such transactions should be considered \"good\", and, in the honest setting, most transactions will have a NULL opinion.","title":"6.1.2.2 How opinions on objects are stored"},{"location":"IOTA-NECTAR/6.1%20Objects%20of%20Consensus/#6123-query-status","text":"When FPC prepares a query, see the FPC specification, it shall determine which objects to include. Conceptually, for each type in votingEnabledObjectTypes , the node shall iterate through all objects of that type and individually decide if that object is to be included in the query. Clearly, this iteration would be inefficient expensive, and a node can use some method to speed up the process. However, this is an implementation detail and thus beyond the scope of this document. To determine whether or not each object should be included into a query, a node shall apply the following QueryStatus function. If the function returns true, then the object should be included into the query. FUNCTION Bool = QueryStatus ( type , objectID ) IF type not in VotingEnabledObjectTypes RETURN FALSE ELSE IF opinionField ! = NULL AND level = 1 and currentTime > timeFormed + DSMALL RETURN TRUE ELSE RETURN FALSE IF the object does not exist RETURN ` FALSE ` . When FPC succesfully stops voting on an object, it sets in the opinionField the opinion to the final opinion and modifies level to 2 so that QueryStatus returns false.","title":"6.1.2.3 Query Status"},{"location":"IOTA-NECTAR/6.1%20Objects%20of%20Consensus/#6124-answer-status","text":"Every time FPC receives a query request, it checks whether or not it should reply; see FPC . To do so, it applies the following AnswerStatus function to object in the query request to determine if a response should be made. If AnswerStatus returns FALSE for any object in the query request, a query response will not be prepared. FUNCTION Bool = AnswerStatus ( type , objectID ) If type not in VotingEnabledObjectTypes RETURN FALSE ELSE IF opinionField not = NULL AND ( level = 1 OR level = 2 ) RETURN TRUE ELSE RETURN FALSE Lastly, if the object does not exist, the function should return FALSE .","title":"6.1.2.4 Answer Status"},{"location":"IOTA-NECTAR/6.1%20Objects%20of%20Consensus/#613-rationale-and-alternatives","text":"The level field indicates the level of knowledge. It tells us information about what other nodes know. * Level 1 means that the node only knows that it holds this opinion. * Level 2 means that the node knows that all nodes have this opinion too (with high probability). * Level 3 means that the node knows that all nodes have level 2 knowledge (with high probability). If a node node only has level 1 knowledge, it needs to vote. However, if it has level 2 knowledge, it does not need to query as it knows that all nodes have the same opinion. With level 3 knowledge, it knows that no other nodes have level 2 knowledge and thus should not send its node queries. Thus, with level 3 knowledge, the node does not need to respond. The level of knowledge is the primary criterion in these functions. Moreover, we should not query about objects whose opinion is NULL . In a similar vein, we need should not query about an object until d time after the opinion was set, so we can be sure that all other nodes have set their opinion too. Alternatively, we can attempt to manage the same system with a series of finality flags. However, this has two problems. First, we either mark objects which we have never voted upon as final, or some objects will never get a finality flag. This leads to some complicated, unintuitive logic. Second, if an attacker can cause only small portions of the network to vote on an object, that vote would be susceptible to an attack. Thus we need consensus about what to vote on. However, if voting is a binary \"yes\" or \"no\", we would need a consensus algorithm to determine when to vote. The levels of knowledge does not treat voting in a binary way, bypassing this problem.","title":"6.1.3 Rationale and Alternatives"},{"location":"IOTA-NECTAR/6.2%20Opinion%20Setting/","text":"6.2 Opinion Setting \u00b6 6.2.1 Preliminaries \u00b6 6.2.1.2 Motivation \u00b6 FPC is a binary voting protocol which takes a series of initial boolean values, and outputs a final value: see Section 6.3 - Fast Probabilistic Consensus . This specification describes how to set this initial Boolean value. Specification 6.1 - Object of Consensus describes how FPC interacts with other modules in the protocol, specifically how the functions QueryStatus and AnswerStatus react to the metadata opinionField . Moreover, the FPC specification, Section 6.3 - Fast Probabilistic Consensus , describes how the opinionField is updated when FPC terminates. We need to describe how to set the initial opinion and how to trigger FPC voting. Specifically, we need to describe how the metadata opinionField is initially set. Since the outcome of FPC respects a supermajority of initial opinions, it is important that the initial opinion is set correctly. For example, if 90% of nodes (weighted by active consensus mana) initially want to accept a transaction, the transaction is accepted with very high probablity. Recall from specification Section 6.1 - Object of Consensus , that opinionField consists of fields, opinion which is a boolean, level which is either 1,2, or 3, and timeFormed which is a time. In this specification, we describe how these three fields are set for both messages and transactions. 6.2.1.3 Summary \u00b6 In this specification, we describe how the Opinion Setter, see Section 2.4 - Data Flow , initially sets opinionField metadata for every object being voted upon. Specifically, the opinion setter writes: + The initial opinion, i.e. the initial boolean value. + The level of knowledge which dictates when FPC will be triggered. + The time the opinion was formed. See Section 6.1 - Object of Consensus for a detailed explanation of these fields. As discussed in Section 6.1 - Object of Consensus , FPC can potentially vote on two main object types: + transactions in order to resolve conflicts + timestamps in order to judge timestamps We split this specification into two main sections: the first dealing with setting the opinion on messages and their timestamps, and the second on setting the opinion on transactions. With regards to timestamps, we vote on whether or not the timestamp is \"too old\" when the message arrives to the node. As with voting on transactions, we can reset this opinion using the approval weight even if the node is out of sync. We judge transactions based on the FCoB rule, which stands for Fast Consensus of Barcelona, in honor of the research summit where the rule was first defined. A transaction X satisfied the FCoB rule if the node has not received any transactions conflicting with X before arrivalTime(X)+C where C is the FCoB parameter. Recall from Section 6.4 - Finalization that two transactions conflict if they consume the same UTXO outputs. Intuitively, the FCoB rule only accepts a transaction if it has arrived significantly before any other conflict. The FCoB rule guarantees that if one transaction is liked by a significant number of nodes (weighted by consensus mana), that all other conflicting transactions will be initially disliked by a supermajority of nodes, and thus rejected by FPC, guaranteeing that no two conflicting messages will be approved by FPC. 6.2.1.4 Dependencies \u00b6 This part of the specification depends on the following specifications: + Section 4.2 - Timestamps + Section 5.2 - Ledger State + Section 6.1 - Object of Consensus + Section 6.4 - Finalization 6.2.1.4 Parameters and Lists \u00b6 Name Type Description DLARGE duration Gratuitous network delay estimate; set to 15 seconds W duration Time window, set to 1 minute. Require W>2DLARGE DSMALL duration Small estimated network delay, set to 5 seconds C duration FCoB parameter=DSMALL 6.2.2 Timestamps \u00b6 The timestamp defines the time when the message was created. Voting on timestamps ensures that nodes are issuing messages with correct timestamps, where correct means that the offset with current time is lower than a certain parameter W . This time window is large to account for the network delay. In order to have consensus on the accuracy of the timestamp, and hence the eligibility of the message, we use FPC voting, along with the levels of knowledge. Clearly, in order to have a correct perception of the timestamp quality, we assume the node is in sync (see section Not in Sync otherwise). Voting on timestamps should not occur for every message. Specifically, only for those that arrive with an offset close to W , i.e. within DLARGE . 6.2.2.1 Setting the initial opinion \u00b6 In this section, we describe how the opinionField is set for messages, and how we achieve consensus on the correctness of timestamps. The opinion of timestamp is stored according to the rules laid out in the Object of Consensus specification. The opinion is set by the module called the OpinionManager : see Section 2.4 - Data Flow . Refer to the FPC specification to see how the voting actually takes place. The node shall set messageID.opinionField=timestampOpinion(messageID) , using the function defined below. The initial opinion and level of knowledge are set according to the following rule: FUNCTION ( bool , level , time ) = timestampOpinion ( messageID ) time = CurrentTime () IF messageID . arrivalTime + w >= CurrentTime () opinion = TRUE ELSE opinion = DISLIKE IF | messageID . arrivalTime + W - CurrentTime () | >= DLARGE level = 2 ELSE IF | messageID . arrivalTime + W - CurrentTime () | >= 2 * DLARGE level = 3 ELSE level = 1 Recall that the arrivalTime.messageID is the time that the message was received by the node: see Section 2.2 - Message Layout . The initial opinion is set based on the question \"did the transaction arrive before currentTime - W ?\". The level of knowledge is then set by the margin as a factor of the delay time. Specifically, under the assumption that all messages are delivered to all nodes within time DLARGE after the arrive (with high probability), then: + If |arrivalTime +W - currentTime | < DLARGE , then the node can make any conclusions about the arrival times of the message, and hence it has only level of knowledge 1. + If one node has |arrivalTime +W - currentTime | >= DLARGE , then all nodes must have the same opinion, and hence that node has level of knowledge at least 2. + If one node has |arrivalTime +W - currentTime | >= 2*DLARGE , then all nodes must have |arrivalTime +W - currentTime | => DLARGE guaranteeing level of knowledge 3. For example, let us set w and D to 1 minute and 15 seconds respectively. Let's assume that the current time is 12:00:00 and we have to evaluate a new message with timestamp set at 11:59:45. Since 11:59:45 +1 minute>12:00:00, the node will set the opinion to LIKE . Moreover, since |11:59:45+1 minute-12:00:00| is greater than 15 seconds, and also grater than 2*15 seconds, the node will set the level of knowledge for this opinion to 3 (i.e., the supermajority of the network should already have the same opinion). Consider now a new message with timestamp 11:59:10. Since 11:59:10+1 minute>12:00:00, the node will set the opinion to TRUE . However, since |11:59:10+1 minute-12:00:00| is lower than 15 seconds, the node will set the level of knowledge for to 1, meaning that this message will be voted upon by FPC. In general, timestamps with level of knowledge 1 will be input into FPC, that will eventually trigger the finalized event, after which we may set a message as eligible or as discarded, depending on the outcome. If instead, the timestamp the node is considering has already level of knowledge larger or equal than 2, the node does not need to vote, but has to reply to queries. Either it is eligible (marked as liked) or it is marked as disliked. If the timestamp has level of knowledge 3, the node does not reply to FPC queries. With high probability, we can be sure that for any time t , no node can issue a message with timestamp t after t + W + 2*DLARGE , because after this time, the message would be considered to be bad with level of knowledge 3. Thus, assuming the node is in sync, see Section 6.4 - Finalization , after approximately 1.5 minutes, the number of messages of a particular timestamp cannot be altered. 6.2.3 Transactions and FCoB \u00b6 In this section, we discuss how to set the opinionField on transactions through the so-called FCoB rule. Recall that a transaction X satisfies the FCoB rule if the node has not received any transactions conflicting with X before arrivalTime(X)+C . 6.2.3.1 FCoB function \u00b6 We now define the function FCOB which decides the opinion of the transaction. When setting the opinion, the node simply sets opinionField=FCOB(transactionID) . FUNCTION ( bool , level , time ) = FCOB ( transactionID ) time = currentTime IF transactionID IS NOT a conflict bool = TRUE IF currentTime <= transactionID . arrivalTime + C + DSMALL level = 1 ELSE IF currentTime <= transactionID . arrivalTime + C + 2 * DSMALL level = 2 ELSE level = 3 ELSE FOR x IN conflict with transactionID IF x . arrivalTime >= transactionID . arrivalTime + C OR ( x . opinionField . opinion == FALSE AND x . opinionField . level == 2 OR 3 ) bool = TRUE level = 1 ELSE conflictTime = MIN ( x . arrivalTime FORALL x conflicting with transactionID ) IF transaction . arrivalTime + C <= conflictTime bool = TRUE ELSE bool = FALSE If | transaction . arrivalTime + C - conflictTime | <= DSMALL level = 1 ELSE IF | transaction . arrivalTime + C - conflictTime | <= 2D SMALL level = 2 ELSE level = 3 RETURN ( bool , level , timeFormed ) We now will explain the logical behind this function. There are three cases which are treated: 1. No conflicts have been detected 2. Conflicts have been detected but have been rejected 3. Conflicts have been detected are either pending or have been confirmed Case 3 is the simplest case: since conflicts have been detected, we set the opinion according to the FCOB rule. Then level is set according to the difference of transaction.arrivalTime + C and conflictTime , the oldest arrival time of a conflicting transaction. Essentially, the level measures how many network delays there are between these two values. In Case 1 is the most common because conflicts will never arrive for most transactions. Without conflicts, the opinion can be only set provisionally since it might change if a conflict arrives later. The opinion is set to true, but the level is set as if a conflict arrived at that time. For example, after C + DSMALL time has elapsed since arrival time, if a conflict does arrive the opinion will remain true with level at least 2. Lastly, Case 2 is an important special case of the FCoB rule. To see the need for this modification consider the following example. Suppose someone issues a pair of conflicting transactions where both transactions are rejected by FPC. Then, if someone ever issues a new transaction consuming those funds, FCoB, strictly speaking would reject the new transaction, since it would conflict with a previous transaction. Thus, if a pair of double spends are rejected, the funds would be locked. This is undesirable and impractical behavior: an honest but malfunctioning wallet can issue double spends. Moreover, tracking the locked funds would be onerous. To prevent the FCoB rule from locking funds, we modify it to the following: a transaction X satisfied the FCoB rule if all transactions Y conflicting with X before arrivalTime(X)+C has been rejected, i.e. has has opinion false and level 2 or 3. With this rule, any conflicts which are rejected will not affect the opinion on future conflicts. For simplicity case, all transactions falling under this case are treated as level 1. 6.2.3.2 When to set the opinion \u00b6 The protocol is actually flexible on when the opinion field of a transaction is set. However, the node must do the following. + The opinion of a transaction must be set after it is booked. When the transaction is booked, the node searches for conflicts, and if a conflict exists the node either creates a new conflict set or else it adds the transaction to an old conflict sets. If the FCoB function is called before the transaction is booked, it will be impossible to tell what conflicts exist. + The opinion field is NULL only if no conflicts have been detected + Fore very valid transactionID , the transactionID.opinionField is either NULL or \"correct\" at the times transactionID.arrivalTime + C + DSMALL and transactionID.arrivalTime + C + 2DSMALL , i.e. the opinion field would be unchanged if reset at that those two times. There are a plethora of ways this could be implemented. We give two examples. First, after a message is booked, its transaction, say transactionID is added to a timed queue. At transactionID.arrivalTime + C + DSMall the opinion is set, and then either the transaction is rejected (i.e. bad with level 2 or 3), voted upon (level 1), or goes to tip selection (good level 2). If no conflict has been detected, the transaction (i.e. the transaction is good level 2), the transaction is put in another timed queue. At time transactionID.arrivalTime + C + 2DSMall the opinion is reset. Note, once a conflict is detected the opinion field would not change, and so only transactions which are not part of conflict sets need to enter the second timed queue. Second, while a transaction is being booked, conflict detection can immediately trigger setting the opinion field for all the new conflicts. This would include the transaction itself and any members of its conflict set which previously had a NULL opinion field. This implementation has a few caveats: + Any transaction with a NULL opinion field must be treated as a \"good\" transaction. At any time, the appropriate level of knowledge could be computed by looking at the arrival time. + Before the monotonically liked flag is set, the transaction must be at least transactionID.arrivalTime + C + DSMall and have either opinion field NULL or (good, level 2 or 3). Although this is an implementation detail, we remark that after a transaction is booked, it is easy to see if a message is a conflict or not. Indeed, when a conflict is detected, a new branch is created, and the ID of that new branch is the same as the transactionID . Thus a transaction is a conflict if and only if transactionID = transactionID.branchID . See Section 5.2 - Ledger State .","title":"6.2 Opinion Setting"},{"location":"IOTA-NECTAR/6.2%20Opinion%20Setting/#62-opinion-setting","text":"","title":"6.2 Opinion Setting"},{"location":"IOTA-NECTAR/6.2%20Opinion%20Setting/#621-preliminaries","text":"","title":"6.2.1 Preliminaries"},{"location":"IOTA-NECTAR/6.2%20Opinion%20Setting/#6212-motivation","text":"FPC is a binary voting protocol which takes a series of initial boolean values, and outputs a final value: see Section 6.3 - Fast Probabilistic Consensus . This specification describes how to set this initial Boolean value. Specification 6.1 - Object of Consensus describes how FPC interacts with other modules in the protocol, specifically how the functions QueryStatus and AnswerStatus react to the metadata opinionField . Moreover, the FPC specification, Section 6.3 - Fast Probabilistic Consensus , describes how the opinionField is updated when FPC terminates. We need to describe how to set the initial opinion and how to trigger FPC voting. Specifically, we need to describe how the metadata opinionField is initially set. Since the outcome of FPC respects a supermajority of initial opinions, it is important that the initial opinion is set correctly. For example, if 90% of nodes (weighted by active consensus mana) initially want to accept a transaction, the transaction is accepted with very high probablity. Recall from specification Section 6.1 - Object of Consensus , that opinionField consists of fields, opinion which is a boolean, level which is either 1,2, or 3, and timeFormed which is a time. In this specification, we describe how these three fields are set for both messages and transactions.","title":"6.2.1.2 Motivation"},{"location":"IOTA-NECTAR/6.2%20Opinion%20Setting/#6213-summary","text":"In this specification, we describe how the Opinion Setter, see Section 2.4 - Data Flow , initially sets opinionField metadata for every object being voted upon. Specifically, the opinion setter writes: + The initial opinion, i.e. the initial boolean value. + The level of knowledge which dictates when FPC will be triggered. + The time the opinion was formed. See Section 6.1 - Object of Consensus for a detailed explanation of these fields. As discussed in Section 6.1 - Object of Consensus , FPC can potentially vote on two main object types: + transactions in order to resolve conflicts + timestamps in order to judge timestamps We split this specification into two main sections: the first dealing with setting the opinion on messages and their timestamps, and the second on setting the opinion on transactions. With regards to timestamps, we vote on whether or not the timestamp is \"too old\" when the message arrives to the node. As with voting on transactions, we can reset this opinion using the approval weight even if the node is out of sync. We judge transactions based on the FCoB rule, which stands for Fast Consensus of Barcelona, in honor of the research summit where the rule was first defined. A transaction X satisfied the FCoB rule if the node has not received any transactions conflicting with X before arrivalTime(X)+C where C is the FCoB parameter. Recall from Section 6.4 - Finalization that two transactions conflict if they consume the same UTXO outputs. Intuitively, the FCoB rule only accepts a transaction if it has arrived significantly before any other conflict. The FCoB rule guarantees that if one transaction is liked by a significant number of nodes (weighted by consensus mana), that all other conflicting transactions will be initially disliked by a supermajority of nodes, and thus rejected by FPC, guaranteeing that no two conflicting messages will be approved by FPC.","title":"6.2.1.3 Summary"},{"location":"IOTA-NECTAR/6.2%20Opinion%20Setting/#6214-dependencies","text":"This part of the specification depends on the following specifications: + Section 4.2 - Timestamps + Section 5.2 - Ledger State + Section 6.1 - Object of Consensus + Section 6.4 - Finalization","title":"6.2.1.4 Dependencies"},{"location":"IOTA-NECTAR/6.2%20Opinion%20Setting/#6214-parameters-and-lists","text":"Name Type Description DLARGE duration Gratuitous network delay estimate; set to 15 seconds W duration Time window, set to 1 minute. Require W>2DLARGE DSMALL duration Small estimated network delay, set to 5 seconds C duration FCoB parameter=DSMALL","title":"6.2.1.4 Parameters and Lists"},{"location":"IOTA-NECTAR/6.2%20Opinion%20Setting/#622-timestamps","text":"The timestamp defines the time when the message was created. Voting on timestamps ensures that nodes are issuing messages with correct timestamps, where correct means that the offset with current time is lower than a certain parameter W . This time window is large to account for the network delay. In order to have consensus on the accuracy of the timestamp, and hence the eligibility of the message, we use FPC voting, along with the levels of knowledge. Clearly, in order to have a correct perception of the timestamp quality, we assume the node is in sync (see section Not in Sync otherwise). Voting on timestamps should not occur for every message. Specifically, only for those that arrive with an offset close to W , i.e. within DLARGE .","title":"6.2.2 Timestamps"},{"location":"IOTA-NECTAR/6.2%20Opinion%20Setting/#6221-setting-the-initial-opinion","text":"In this section, we describe how the opinionField is set for messages, and how we achieve consensus on the correctness of timestamps. The opinion of timestamp is stored according to the rules laid out in the Object of Consensus specification. The opinion is set by the module called the OpinionManager : see Section 2.4 - Data Flow . Refer to the FPC specification to see how the voting actually takes place. The node shall set messageID.opinionField=timestampOpinion(messageID) , using the function defined below. The initial opinion and level of knowledge are set according to the following rule: FUNCTION ( bool , level , time ) = timestampOpinion ( messageID ) time = CurrentTime () IF messageID . arrivalTime + w >= CurrentTime () opinion = TRUE ELSE opinion = DISLIKE IF | messageID . arrivalTime + W - CurrentTime () | >= DLARGE level = 2 ELSE IF | messageID . arrivalTime + W - CurrentTime () | >= 2 * DLARGE level = 3 ELSE level = 1 Recall that the arrivalTime.messageID is the time that the message was received by the node: see Section 2.2 - Message Layout . The initial opinion is set based on the question \"did the transaction arrive before currentTime - W ?\". The level of knowledge is then set by the margin as a factor of the delay time. Specifically, under the assumption that all messages are delivered to all nodes within time DLARGE after the arrive (with high probability), then: + If |arrivalTime +W - currentTime | < DLARGE , then the node can make any conclusions about the arrival times of the message, and hence it has only level of knowledge 1. + If one node has |arrivalTime +W - currentTime | >= DLARGE , then all nodes must have the same opinion, and hence that node has level of knowledge at least 2. + If one node has |arrivalTime +W - currentTime | >= 2*DLARGE , then all nodes must have |arrivalTime +W - currentTime | => DLARGE guaranteeing level of knowledge 3. For example, let us set w and D to 1 minute and 15 seconds respectively. Let's assume that the current time is 12:00:00 and we have to evaluate a new message with timestamp set at 11:59:45. Since 11:59:45 +1 minute>12:00:00, the node will set the opinion to LIKE . Moreover, since |11:59:45+1 minute-12:00:00| is greater than 15 seconds, and also grater than 2*15 seconds, the node will set the level of knowledge for this opinion to 3 (i.e., the supermajority of the network should already have the same opinion). Consider now a new message with timestamp 11:59:10. Since 11:59:10+1 minute>12:00:00, the node will set the opinion to TRUE . However, since |11:59:10+1 minute-12:00:00| is lower than 15 seconds, the node will set the level of knowledge for to 1, meaning that this message will be voted upon by FPC. In general, timestamps with level of knowledge 1 will be input into FPC, that will eventually trigger the finalized event, after which we may set a message as eligible or as discarded, depending on the outcome. If instead, the timestamp the node is considering has already level of knowledge larger or equal than 2, the node does not need to vote, but has to reply to queries. Either it is eligible (marked as liked) or it is marked as disliked. If the timestamp has level of knowledge 3, the node does not reply to FPC queries. With high probability, we can be sure that for any time t , no node can issue a message with timestamp t after t + W + 2*DLARGE , because after this time, the message would be considered to be bad with level of knowledge 3. Thus, assuming the node is in sync, see Section 6.4 - Finalization , after approximately 1.5 minutes, the number of messages of a particular timestamp cannot be altered.","title":"6.2.2.1 Setting the initial opinion"},{"location":"IOTA-NECTAR/6.2%20Opinion%20Setting/#623-transactions-and-fcob","text":"In this section, we discuss how to set the opinionField on transactions through the so-called FCoB rule. Recall that a transaction X satisfies the FCoB rule if the node has not received any transactions conflicting with X before arrivalTime(X)+C .","title":"6.2.3 Transactions and FCoB"},{"location":"IOTA-NECTAR/6.2%20Opinion%20Setting/#6231-fcob-function","text":"We now define the function FCOB which decides the opinion of the transaction. When setting the opinion, the node simply sets opinionField=FCOB(transactionID) . FUNCTION ( bool , level , time ) = FCOB ( transactionID ) time = currentTime IF transactionID IS NOT a conflict bool = TRUE IF currentTime <= transactionID . arrivalTime + C + DSMALL level = 1 ELSE IF currentTime <= transactionID . arrivalTime + C + 2 * DSMALL level = 2 ELSE level = 3 ELSE FOR x IN conflict with transactionID IF x . arrivalTime >= transactionID . arrivalTime + C OR ( x . opinionField . opinion == FALSE AND x . opinionField . level == 2 OR 3 ) bool = TRUE level = 1 ELSE conflictTime = MIN ( x . arrivalTime FORALL x conflicting with transactionID ) IF transaction . arrivalTime + C <= conflictTime bool = TRUE ELSE bool = FALSE If | transaction . arrivalTime + C - conflictTime | <= DSMALL level = 1 ELSE IF | transaction . arrivalTime + C - conflictTime | <= 2D SMALL level = 2 ELSE level = 3 RETURN ( bool , level , timeFormed ) We now will explain the logical behind this function. There are three cases which are treated: 1. No conflicts have been detected 2. Conflicts have been detected but have been rejected 3. Conflicts have been detected are either pending or have been confirmed Case 3 is the simplest case: since conflicts have been detected, we set the opinion according to the FCOB rule. Then level is set according to the difference of transaction.arrivalTime + C and conflictTime , the oldest arrival time of a conflicting transaction. Essentially, the level measures how many network delays there are between these two values. In Case 1 is the most common because conflicts will never arrive for most transactions. Without conflicts, the opinion can be only set provisionally since it might change if a conflict arrives later. The opinion is set to true, but the level is set as if a conflict arrived at that time. For example, after C + DSMALL time has elapsed since arrival time, if a conflict does arrive the opinion will remain true with level at least 2. Lastly, Case 2 is an important special case of the FCoB rule. To see the need for this modification consider the following example. Suppose someone issues a pair of conflicting transactions where both transactions are rejected by FPC. Then, if someone ever issues a new transaction consuming those funds, FCoB, strictly speaking would reject the new transaction, since it would conflict with a previous transaction. Thus, if a pair of double spends are rejected, the funds would be locked. This is undesirable and impractical behavior: an honest but malfunctioning wallet can issue double spends. Moreover, tracking the locked funds would be onerous. To prevent the FCoB rule from locking funds, we modify it to the following: a transaction X satisfied the FCoB rule if all transactions Y conflicting with X before arrivalTime(X)+C has been rejected, i.e. has has opinion false and level 2 or 3. With this rule, any conflicts which are rejected will not affect the opinion on future conflicts. For simplicity case, all transactions falling under this case are treated as level 1.","title":"6.2.3.1 FCoB function"},{"location":"IOTA-NECTAR/6.2%20Opinion%20Setting/#6232-when-to-set-the-opinion","text":"The protocol is actually flexible on when the opinion field of a transaction is set. However, the node must do the following. + The opinion of a transaction must be set after it is booked. When the transaction is booked, the node searches for conflicts, and if a conflict exists the node either creates a new conflict set or else it adds the transaction to an old conflict sets. If the FCoB function is called before the transaction is booked, it will be impossible to tell what conflicts exist. + The opinion field is NULL only if no conflicts have been detected + Fore very valid transactionID , the transactionID.opinionField is either NULL or \"correct\" at the times transactionID.arrivalTime + C + DSMALL and transactionID.arrivalTime + C + 2DSMALL , i.e. the opinion field would be unchanged if reset at that those two times. There are a plethora of ways this could be implemented. We give two examples. First, after a message is booked, its transaction, say transactionID is added to a timed queue. At transactionID.arrivalTime + C + DSMall the opinion is set, and then either the transaction is rejected (i.e. bad with level 2 or 3), voted upon (level 1), or goes to tip selection (good level 2). If no conflict has been detected, the transaction (i.e. the transaction is good level 2), the transaction is put in another timed queue. At time transactionID.arrivalTime + C + 2DSMall the opinion is reset. Note, once a conflict is detected the opinion field would not change, and so only transactions which are not part of conflict sets need to enter the second timed queue. Second, while a transaction is being booked, conflict detection can immediately trigger setting the opinion field for all the new conflicts. This would include the transaction itself and any members of its conflict set which previously had a NULL opinion field. This implementation has a few caveats: + Any transaction with a NULL opinion field must be treated as a \"good\" transaction. At any time, the appropriate level of knowledge could be computed by looking at the arrival time. + Before the monotonically liked flag is set, the transaction must be at least transactionID.arrivalTime + C + DSMall and have either opinion field NULL or (good, level 2 or 3). Although this is an implementation detail, we remark that after a transaction is booked, it is easy to see if a message is a conflict or not. Indeed, when a conflict is detected, a new branch is created, and the ID of that new branch is the same as the transactionID . Thus a transaction is a conflict if and only if transactionID = transactionID.branchID . See Section 5.2 - Ledger State .","title":"6.2.3.2 When to set the opinion"},{"location":"IOTA-NECTAR/6.3%20Fast%20Probabilistic%20Consensus/","text":"6.3 Fast Probabilistic Consensus \u00b6 The functionality defined in this part of the specification allows nodes to find consensus on whether a given object is elgible or not. This protocol, called Fast Probabilistic Consensus (FPC), is triggered if the eligibility of an object is uncertain. These objects can be messages or transactions. Please refer to Section 6.1 - Object of Consensus for details on the object of consensus and to Section 6.2 - Opinion Setting for more details how initial opinions on the objects are formed. Once FPC is triggered every node must establish an initial opinion on the eligibility of the object, as described in Section 6.1. The node must then start to query other nodes about their opinions on the given object and must update its opinion according to the rules specified in this section. This procedure shall terminate locally if a node has not changed its opinion over a specified period of time or if some maximal amount of rounds is reached. Unlike other voting-based consensus protocols, FPC uses a sequence of global random thresholds. This randomness makes FPC robust even in Byzantine environments. We refer to FPC-BI: Fast Probabilistic Consensus within Byzantine Infrastructures , Robustness and efficiency of leaderless probabilistic consensus protocols within Byzantine infrastructures , and Fast Probabilistic Consensus with Weighted Votes for more details on FPC. FPC Protocol \u00b6 The FPC protocol attempts to determine consensus on the eligibility of an object objectID . Every node has an initial opinion opinion on this object. These opinions are updated in rounds until the protocol terminates using a local stopping rule. FPC parameters \u00b6 Table 5.1.1 gives a list of all parameters required for FPC. Table 5.1.1 Parameters Required for FPC Name Type Description TOTAL_ROUNDS_FINALIZATION integer Number of consecutive rounds before FPC auto-terminates TOTAL_ROUNDS_ENDING_THRESHOLD integer Number of consecutive rounds with non-random threshold FIRST_ROUND_THRESHOLD double Threshold of the proportion of opinions in the first round SUBSEQUENT_LOWER_THRESHOLD double Lower random threshold bound in subsequent rounds SUBSEQUENT_UPPER_THRESHOLD double Upper random threshold bound in subsequent rounds ENDING_THRESHOLD double Threshold for termination phase DRNG_WAITING_TIME duration Maximal waiting time (in seconds) to receive dRNG number MAX_ROUND integer Maximum number of rounds before querying stops QUERY_SIZE integer Quorum size, number of nodes that are queried ROUND_LENGTH double Duration (in seconds) of a round TIME_OUT duration Maximal waiting time (in seconds) to receive answers for FPC queries MIN_MANA_PROPORTION double Minimal amount of mana of received answers that allow to update opinion. If this amount is not reached the current round is not counted. MAX_SAMPLE_SIZE integer Maximal size of sample. The proposed values of the parameters are (Table 5.1.2): Table 5.1.2 FPC Parameter Default Values Parameter Value TOTAL_ROUNDS_FINALIZATION 10 TOTAL_ROUNDS_ENDING_THRESHOLD 3 FIRST_ROUND_THRESHOLD 0.67 SUBSEQUENT_LOWER_THRESHOLD 0.50 SUBSEQUENT_UPPER_THRESHOLD 0.67 ENDING_THRESHOLD 0.50 DRNG_WAITING_TIME 0.20 MAX_ROUND 100 QUERY_SIZE 21 ROUND_LENGTH 10 TIME_OUT 6.5 MIN_MANA_PROPORTION 0.50 MAX_SAMPLE_SIZE 100 Local variables \u00b6 Local variables are those which may be defined at the application developer's discretion and do not form a mandatory part of the protocol. They are included here to assist in understanding the protocol defined in this section. The kind of information described for these variables must be handled by the node application in some form. Every node shall keep the following variables (Table 5.1.3): Table 5.1.3 Required Node Variables Name Type Description nodeList list of nodeIDs List of known nodes consensusManaList list of nodeIDs List of active consensus mana of known nodes ownMana double Active consensus mana of ownNode rn double Random number provided by dRNG module rnCycle double Random number instance queryList list of nodeIDs List of nodes to query queryMax integer Maximal number of queries per round opinionQuery list of Opinions List of opinions of nodes in queryList , non-replies are encoded with NA objectIDs list of objectIDs List of objectIDs that are under vote Note that consensusManaList is a list of active consensus Mana of all known nodes. As this Mana changes over time this list has to be updated over time. Such an update is expressed with the function GetActiveConsensusMana(time) that returns the list of active consensus Mana at time time . For each objectID that is under vote a node shall keep the following variables (Table 5.1.4): Table 5.1.4 Variables Required for objectID Under Vote Name Type Description opinion nulled boolean Opinion of the eligibility the objectID ; TRUE corresponds to LIKE and FALSE to DISLIKE cnt integer Counter of the number of consecutive rounds with unchanged opinion queryStatus boolean Status if actively querying answerStatus boolean TRUE if answering queries, otherwise FALSE round integer Counter for the number of rounds in FPC reachedMaxRound boolean Indicator whether protocol reached MAX_ROUND before auto-termination, default value FALSE FPC protocol description \u00b6 FPC Protocol Operation for One Object ID \u00b6 This section describes how FPC works for one objectID . Once FPC is triggered on the eligibility of the object objectID a node establishes an initial opinion opinion on objectID , see Section 6.2 Opinion Setting . In particular, the variables queryStatus and answerStatus must be affected using the functions QueryStatus and AnswerStatus . The exchange and update of opinions must be done in rounds of length ROUND_LENGTH . Rounds end and start at times (in seconds) that are multiple of ROUND_LENGTH . 1. At the beginning of each round a node must select a random sample of the other nodes and either send a query request or check if the sampled nodes published their opinions on the Tangle. 2. After TIME_OUT the node must calculate the proportion of the LIKE s in the received opinions. 3. At the end of the round it must set a threshold to confirm or modify its own opinion. In the first round this threshold is FIRST_ROUND_THRESHOLD while in the subsequent rounds a node must retrieve a random threshold from the dRNG. If the random threshold from the dRNG is not available a node must use ( SUBSEQUENT_LOWER_THRESHOLD + SUBSEQUENT_UPPER_THRESHOLD )/2 as threshold. If the proportion is below this obtained threshold it must set its opinion to DISLIKE , otherwise it must set its opinion to LIKE . In the case that the opinion did not change, the variable cnt must be incremented by 1, otherwise it must be set to 0. If a node did not receive enough answers, i.e., the proportion of mana of the received opinions is less than MIN_MANA_PROPORTION of the total mana of the queried nodes, the round is not counted, i.e., neither opinion nor cnt are changed. 4. This continues until cnt = TOTAL_ROUNDS_FINALIZATION - TOTAL_ROUNDS_ENDING_THRESHOLD . FPC then enters in the \"termination phase\" and continues for TOTAL_ROUNDS_ENDING_THRESHOLD rounds using the ENDING_THRESHOLD instead of the random threshold. If during this phase a node changes its opinion it must set cnt =0 and use the random threshold again. The node shall stop querying if cnt = TOTAL_ROUNDS_ENDING_THRESHOLD or cnt = reachedMaxRound . In case that cnt = reachedMaxRound a node must set the final opinion to DISLIKE . 5. Once FPC terminates (for the given objectID ) a node must update the metadata opinionField of objectID with the outcome of FPC as opinion and level=2 . 6. A node must continue to respond to queries as long as AnswerStatus(type, objectID)=TRUE , where type is the type of the objectID . If AnswerStatus(type, objectID)=FALSE the variable answerStatus must be updated accordingly. High consensus Mana nodes will be queried more often than nodes with low consensus Mana, since the sampling using consensus Mana as weights. Every node is given the possibility to publish their opinions in a statement on the Tangle. These messages are called FPC statements. Nodes who decide to issue FPC statements may close the port reserved for FPC queries. A close port can therefore be an indication that a node decided to disseminate its opinions through statements. Every node shall keep a list of nodes that are not answering direct queries but publish their opinions on the Tangle. If a node issues two or more conflicting FPC statements in a round, every other node shall not take these messages into account, i.e., they do not count for the Mana of received opinions neither are used for the calculation of the proportion. FPC Protocol Operation for Multiple Object IDs \u00b6 It is possible that there are more than one object to vote on. In this case, a node shall sample once per round and obtain the opinions for all objects from this one sample. Malicious or faulty nodes may not respond in a consistent way. In particular, in the case of a double-spending, a malicious node may respond LIKE for two or more conflicting objects. These malicious messages shall be filtered after having received the responses of the queries. Therefore, upon receival of the opinions, a node shall check for every sampled node if its answers are consistent, i.e., all liked objects must form a valid ledger state. Nodes that replied inconsistently shall be filtered out and their answer shall be considered as not received, i.e., they do not count for the Mana of received opinions neither are used for the calculation of the proportion. Note that since consensus Mana changes over time, FPC may use different consensus Mana values for different objectID s that are voted on at the same time. For an objectID , FPC must use the active consensus Mana of epoch Epoch X-2 , where Epoch X contains the timestamp of the objectID . We refer to Section 5.3 - Mana for the specification of active consensus Mana. We use a generic function GetActiveConsensusMana(time) that retrieves the active consensus Mana with respect to a given timestamp time . FPC Pseudocode Description \u00b6 The following presents some pseudo-code for a better understanding of the details of the FPC protocol. The function GetRN(a, b, time) retrieves a uniform random number between a and b from the dRNG module of a given time time . If the dRNG is not retrieved in time a node must use ( SUBSEQUENT_LOWER_THRESHOLD SUBSEQUENT_UPPER_THRESHOLD )/2 instead. In each round a node must query a random sample of other nodes. The random sample is obtained using weighted (by active consensus Mana) sampling with replacement until QUERY_SIZE distinct elements are chosen, or until a maximum sample size of MAX_SAMPLE_SIZE is reached. GetSample \u00b6 This function chooses a sample of nodeIDs for FPC queries. FUNCTION queryList = GetSample ( nodeList , manaList ) queryList = [] WHILE ( queryList does not contain QUERY_SIZE different elements ) newSample = SAMPLE ( nodeList , weight = manaList ) queryList = APPEND ( queryList , newSample ) RETURN queryList The function SAMPLE(nodeList, weight=manaList) chooses a random element from nodeList with weights corresponding to their Mana, i.e., the probability that a nodeID is chosen is proportional to manaList[nodeID] . Once the list queryList of nodes to query is chosen a node must obtain their opinions about the objects under voting. As there are two possibilities for nodes to communicate their opinions, via direct answers or via FPC statements, a node shall keep information on this behavior up to date. The message layout of the FPC statements is specified in Section 2.3 - Standard Payloads Layout . At the beginning of each round every node must prepare a query and send it to those nodes in queryList that replies directly (i.e., do not publish FPC statements). The queries must follow the layout that follows. QueryRequest \u00b6 Name Type Description Version uint8 The message version. The schema specified in this RFC is for version 1 only. Tx count uint8 The number of TransactionIDs. TransactionIDs Tx count TransactionID, ordered by hash ASC Name Type Description TransactionID ByteArray[32] The ID of the transaction . Msg count uint8 The number of MessageIDs. MessageIDs Msg count MessageID, ordered by hash ASC Name Type Description MessageID ByteArray[32] The ID of the message . The respond to a QueryRequest must take follow the following form QueryResponse \u00b6 Name Type Description Version uint8 The message version. The schema specified in this RFC is for version 1 only. Obj count uint8 The number of objectIDs. Must equal to Tx count + Msg count of the received QueryRequest Opinions Obj count ObjectIDs, in the same order as in received QueryRequest Name Type Description Opinion Byte The opinion on objectID . In the case that a certain objectID is unknwon to the node, it must respond with NULL . If the objectID is currently treated by FPC a node must respond with the current opinion, otherwise, retrieve the opinion from the opinionField of the objectID . If the opinionField is NULL the node must respond with NULL . Note that since the order of the opinions in QueryResponse is important a node may have to produce different messages QueryResponse for different querying nodes. QueryRequest and QueryResponse must be signed by the sending node. The communication channel for these messages is specified in the field \"services\" in the DiscoveryRequest. We write respond[node, objectIDs] for the respond, per direct QueryResponse or FPC statement, of the node on the objectID s. A node shall only respond to queries if all included objectsID have status answerQuery=TRUE . GetOpinion \u00b6 This function sends queries to all nodes of queryList and obtains their opinion either through QueryResponse messages of from FPC statements on the Tangle. FUNCTION opinionQuery = GetOpinion ( objectIDs , queryList ) SEND QueryRequest messages WAIT UNTIL TIME_OUT FOR ( node IN queryList ) IF ( node replied ) opinionQuery [ node , objectIDs ] = respond [ node , objectIDs ] ELSE IF ( node publishes on Tangle ) opinionQuery [ node , objectIDs ] = GetOpinionFromTangle [ node , objectID ] ELSE opinionQuery [ node , objectIDs ] = NA RETURN ( opinionQuery ) A node must receive a sufficient amount of replies to validate a given round; otherwise the ongoing FPC round is skipped. More precisely, the consensus Mana of the received opinions must be larger than MIN_MANA_PROPORTION times the sum of the consensus Mana of the sampled nodes. Once a node receives a FPC query it must prepare a response message as specified above, and shall sent the response as soon as possible. If a node decides to publish its opinions on the Tangle, it must create a so-called FPC statement message and issue it on the Tangle at the beginning of each round. At the end of each round, i.e., after the TIME_OUT expires, a node must update its opinion if CheckQuerySuccessful is TRUE. The node must calculate the proportion of the LIKE s in the obtained opinions and compare it to a certain threshold. The value of the threshold depends on the phase FPC is in. In the first round, a node must use FIRST_ROUND_THRESHOLD as a threshold, while in the subsequent rounds the node must use a random threshold obtained by GetRN() . Moreover, if cnt > TOTAL_ROUNDS_FINALIZATION - TOTAL_ROUNDS_ENDING_THRESHOLD the node must use ENDING_THRESHOLD for the threshold. The following pseudo-code describes the update of the opinion of one given objectID . It uses queryList and opinionQuery obtained by the functions GetSample and GetOpinion . The variable opinion describes the current opinion on objectID . OpinionUpdate \u00b6 This function updates the opinion of a node on objectID . FUNCTION opinion = OpinionUpdate ( objectID , opinion , queryList , opinionQuery , round ) manaList = GetActiveConsensusMana ( timeObjectID ) answerMana = ownMana queriedMana etaStar = 0 FOR node in queryList queriedMana += manaList [ node ] IF opinionQuery [ node , objectID ] ! = NA answerMana += manaList [ node ] IF opinionQuery [ node , objectID ] = LIKE etaStar ++ IF answerMana <= MIN_MANA_PROPORTION * queriedMana opinionNew = opinion # ELSE eta = etaStar / LENGTH ( queryList ) IF opinion = LIKE eta = ( ownMana + etaStar * ( answerMana - ownMana )) / answerMana ELSE IF opinion = DISLIKE eta = ( etaStar * ( answerMana - ownMana )) / answerMana WAIT UNTIL CurrentTime / ROUND_LENGTH IS INTEGER IF round = 1 threshold = FIRST_ROUND_THRESHOLD ELSE IF round <= TOTAL_ROUNDS_FINALIZATION - TOTAL_ROUNDS_ENDING_THRESHOLD WAIT DRNG_WAITING_TIME threshold = getRN ( SUBSEQUENT_LOWER_THRESHOLD , SUBSEQUENT_UPPER_THRESHOLD , CurrentTime ) IF threshold = NIL threshold = ( SUBSEQUENT_LOWER_THRESHOLD + SUBSEQUENT_UPPER_THRESHOLD ) / 2 ELSE threshold = ENDING_THRESHOLD IF eta < threshold opinionNew = DISLIKE ELSE opinionNew = LIKE RETURN opinioNew MainFPC \u00b6 This function describes the FPC for one objectID . It is triggered once queryStatus of an object is set to TRUE . FUNCTION opinion = MainFPC ( objectId , queryStatus ) IF queryStatus = TRUE opinion = GetInitialOpinion ( objectID ) cnt = 0 } WAIT UNTIL CurrentTime / ROUND_LENGTH IS INTEGER round = 1 WHILE queryStatus = TRUE queryList = GetSample ( nodeList , manaList ) opinionQuery = GetOpinion ( objectID , queryList ) opinionNew = OpinionUpdate ( objectID , opinion , queryList , opinionQuery , round ) IF opinion = opinionNew cnt ++ ELSE cnt = 1 opinion = opinionNew round ++ IF cnt = TOTAL_ROUNDS_FINALIZATION queryStatus = FALSE IF round >= MAX_ROUND queryStatus = FALSE opinion = 1 RETURN opinion Optimizations Suggestions \u00b6 The design given above exemplifies all the mandatory elements of the FPC protocol. There are several possible ways to optimize the performance of FPC. For example: FPC possibly exposes the public IP adresses of all the IOTA nodes. This can be limited by publishing statements on Tangle. However, if all nodes decide to publish their statements this may have a negative effect on the scalability of the protocol. Please refer to Fast Probabilistic Consensus with Weighted Votes for more discussions on how to optimize the message overhead. Monotonicity and consistency rules may be applied to reduce the sizes of the messages. The choice of the FPC parameters could be optimized. The optimal choice depends on the actual mana distribution and network latency.","title":"6.3 Fast Probabilistic Consensus"},{"location":"IOTA-NECTAR/6.3%20Fast%20Probabilistic%20Consensus/#63-fast-probabilistic-consensus","text":"The functionality defined in this part of the specification allows nodes to find consensus on whether a given object is elgible or not. This protocol, called Fast Probabilistic Consensus (FPC), is triggered if the eligibility of an object is uncertain. These objects can be messages or transactions. Please refer to Section 6.1 - Object of Consensus for details on the object of consensus and to Section 6.2 - Opinion Setting for more details how initial opinions on the objects are formed. Once FPC is triggered every node must establish an initial opinion on the eligibility of the object, as described in Section 6.1. The node must then start to query other nodes about their opinions on the given object and must update its opinion according to the rules specified in this section. This procedure shall terminate locally if a node has not changed its opinion over a specified period of time or if some maximal amount of rounds is reached. Unlike other voting-based consensus protocols, FPC uses a sequence of global random thresholds. This randomness makes FPC robust even in Byzantine environments. We refer to FPC-BI: Fast Probabilistic Consensus within Byzantine Infrastructures , Robustness and efficiency of leaderless probabilistic consensus protocols within Byzantine infrastructures , and Fast Probabilistic Consensus with Weighted Votes for more details on FPC.","title":"6.3 Fast Probabilistic Consensus"},{"location":"IOTA-NECTAR/6.3%20Fast%20Probabilistic%20Consensus/#fpc-protocol","text":"The FPC protocol attempts to determine consensus on the eligibility of an object objectID . Every node has an initial opinion opinion on this object. These opinions are updated in rounds until the protocol terminates using a local stopping rule.","title":"FPC Protocol"},{"location":"IOTA-NECTAR/6.3%20Fast%20Probabilistic%20Consensus/#fpc-parameters","text":"Table 5.1.1 gives a list of all parameters required for FPC. Table 5.1.1 Parameters Required for FPC Name Type Description TOTAL_ROUNDS_FINALIZATION integer Number of consecutive rounds before FPC auto-terminates TOTAL_ROUNDS_ENDING_THRESHOLD integer Number of consecutive rounds with non-random threshold FIRST_ROUND_THRESHOLD double Threshold of the proportion of opinions in the first round SUBSEQUENT_LOWER_THRESHOLD double Lower random threshold bound in subsequent rounds SUBSEQUENT_UPPER_THRESHOLD double Upper random threshold bound in subsequent rounds ENDING_THRESHOLD double Threshold for termination phase DRNG_WAITING_TIME duration Maximal waiting time (in seconds) to receive dRNG number MAX_ROUND integer Maximum number of rounds before querying stops QUERY_SIZE integer Quorum size, number of nodes that are queried ROUND_LENGTH double Duration (in seconds) of a round TIME_OUT duration Maximal waiting time (in seconds) to receive answers for FPC queries MIN_MANA_PROPORTION double Minimal amount of mana of received answers that allow to update opinion. If this amount is not reached the current round is not counted. MAX_SAMPLE_SIZE integer Maximal size of sample. The proposed values of the parameters are (Table 5.1.2): Table 5.1.2 FPC Parameter Default Values Parameter Value TOTAL_ROUNDS_FINALIZATION 10 TOTAL_ROUNDS_ENDING_THRESHOLD 3 FIRST_ROUND_THRESHOLD 0.67 SUBSEQUENT_LOWER_THRESHOLD 0.50 SUBSEQUENT_UPPER_THRESHOLD 0.67 ENDING_THRESHOLD 0.50 DRNG_WAITING_TIME 0.20 MAX_ROUND 100 QUERY_SIZE 21 ROUND_LENGTH 10 TIME_OUT 6.5 MIN_MANA_PROPORTION 0.50 MAX_SAMPLE_SIZE 100","title":"FPC parameters"},{"location":"IOTA-NECTAR/6.3%20Fast%20Probabilistic%20Consensus/#local-variables","text":"Local variables are those which may be defined at the application developer's discretion and do not form a mandatory part of the protocol. They are included here to assist in understanding the protocol defined in this section. The kind of information described for these variables must be handled by the node application in some form. Every node shall keep the following variables (Table 5.1.3): Table 5.1.3 Required Node Variables Name Type Description nodeList list of nodeIDs List of known nodes consensusManaList list of nodeIDs List of active consensus mana of known nodes ownMana double Active consensus mana of ownNode rn double Random number provided by dRNG module rnCycle double Random number instance queryList list of nodeIDs List of nodes to query queryMax integer Maximal number of queries per round opinionQuery list of Opinions List of opinions of nodes in queryList , non-replies are encoded with NA objectIDs list of objectIDs List of objectIDs that are under vote Note that consensusManaList is a list of active consensus Mana of all known nodes. As this Mana changes over time this list has to be updated over time. Such an update is expressed with the function GetActiveConsensusMana(time) that returns the list of active consensus Mana at time time . For each objectID that is under vote a node shall keep the following variables (Table 5.1.4): Table 5.1.4 Variables Required for objectID Under Vote Name Type Description opinion nulled boolean Opinion of the eligibility the objectID ; TRUE corresponds to LIKE and FALSE to DISLIKE cnt integer Counter of the number of consecutive rounds with unchanged opinion queryStatus boolean Status if actively querying answerStatus boolean TRUE if answering queries, otherwise FALSE round integer Counter for the number of rounds in FPC reachedMaxRound boolean Indicator whether protocol reached MAX_ROUND before auto-termination, default value FALSE","title":"Local variables"},{"location":"IOTA-NECTAR/6.3%20Fast%20Probabilistic%20Consensus/#fpc-protocol-description","text":"","title":"FPC protocol description"},{"location":"IOTA-NECTAR/6.3%20Fast%20Probabilistic%20Consensus/#fpc-protocol-operation-for-one-object-id","text":"This section describes how FPC works for one objectID . Once FPC is triggered on the eligibility of the object objectID a node establishes an initial opinion opinion on objectID , see Section 6.2 Opinion Setting . In particular, the variables queryStatus and answerStatus must be affected using the functions QueryStatus and AnswerStatus . The exchange and update of opinions must be done in rounds of length ROUND_LENGTH . Rounds end and start at times (in seconds) that are multiple of ROUND_LENGTH . 1. At the beginning of each round a node must select a random sample of the other nodes and either send a query request or check if the sampled nodes published their opinions on the Tangle. 2. After TIME_OUT the node must calculate the proportion of the LIKE s in the received opinions. 3. At the end of the round it must set a threshold to confirm or modify its own opinion. In the first round this threshold is FIRST_ROUND_THRESHOLD while in the subsequent rounds a node must retrieve a random threshold from the dRNG. If the random threshold from the dRNG is not available a node must use ( SUBSEQUENT_LOWER_THRESHOLD + SUBSEQUENT_UPPER_THRESHOLD )/2 as threshold. If the proportion is below this obtained threshold it must set its opinion to DISLIKE , otherwise it must set its opinion to LIKE . In the case that the opinion did not change, the variable cnt must be incremented by 1, otherwise it must be set to 0. If a node did not receive enough answers, i.e., the proportion of mana of the received opinions is less than MIN_MANA_PROPORTION of the total mana of the queried nodes, the round is not counted, i.e., neither opinion nor cnt are changed. 4. This continues until cnt = TOTAL_ROUNDS_FINALIZATION - TOTAL_ROUNDS_ENDING_THRESHOLD . FPC then enters in the \"termination phase\" and continues for TOTAL_ROUNDS_ENDING_THRESHOLD rounds using the ENDING_THRESHOLD instead of the random threshold. If during this phase a node changes its opinion it must set cnt =0 and use the random threshold again. The node shall stop querying if cnt = TOTAL_ROUNDS_ENDING_THRESHOLD or cnt = reachedMaxRound . In case that cnt = reachedMaxRound a node must set the final opinion to DISLIKE . 5. Once FPC terminates (for the given objectID ) a node must update the metadata opinionField of objectID with the outcome of FPC as opinion and level=2 . 6. A node must continue to respond to queries as long as AnswerStatus(type, objectID)=TRUE , where type is the type of the objectID . If AnswerStatus(type, objectID)=FALSE the variable answerStatus must be updated accordingly. High consensus Mana nodes will be queried more often than nodes with low consensus Mana, since the sampling using consensus Mana as weights. Every node is given the possibility to publish their opinions in a statement on the Tangle. These messages are called FPC statements. Nodes who decide to issue FPC statements may close the port reserved for FPC queries. A close port can therefore be an indication that a node decided to disseminate its opinions through statements. Every node shall keep a list of nodes that are not answering direct queries but publish their opinions on the Tangle. If a node issues two or more conflicting FPC statements in a round, every other node shall not take these messages into account, i.e., they do not count for the Mana of received opinions neither are used for the calculation of the proportion.","title":"FPC Protocol Operation for One Object ID"},{"location":"IOTA-NECTAR/6.3%20Fast%20Probabilistic%20Consensus/#fpc-protocol-operation-for-multiple-object-ids","text":"It is possible that there are more than one object to vote on. In this case, a node shall sample once per round and obtain the opinions for all objects from this one sample. Malicious or faulty nodes may not respond in a consistent way. In particular, in the case of a double-spending, a malicious node may respond LIKE for two or more conflicting objects. These malicious messages shall be filtered after having received the responses of the queries. Therefore, upon receival of the opinions, a node shall check for every sampled node if its answers are consistent, i.e., all liked objects must form a valid ledger state. Nodes that replied inconsistently shall be filtered out and their answer shall be considered as not received, i.e., they do not count for the Mana of received opinions neither are used for the calculation of the proportion. Note that since consensus Mana changes over time, FPC may use different consensus Mana values for different objectID s that are voted on at the same time. For an objectID , FPC must use the active consensus Mana of epoch Epoch X-2 , where Epoch X contains the timestamp of the objectID . We refer to Section 5.3 - Mana for the specification of active consensus Mana. We use a generic function GetActiveConsensusMana(time) that retrieves the active consensus Mana with respect to a given timestamp time .","title":"FPC Protocol Operation for Multiple Object IDs"},{"location":"IOTA-NECTAR/6.3%20Fast%20Probabilistic%20Consensus/#fpc-pseudocode-description","text":"The following presents some pseudo-code for a better understanding of the details of the FPC protocol. The function GetRN(a, b, time) retrieves a uniform random number between a and b from the dRNG module of a given time time . If the dRNG is not retrieved in time a node must use ( SUBSEQUENT_LOWER_THRESHOLD SUBSEQUENT_UPPER_THRESHOLD )/2 instead. In each round a node must query a random sample of other nodes. The random sample is obtained using weighted (by active consensus Mana) sampling with replacement until QUERY_SIZE distinct elements are chosen, or until a maximum sample size of MAX_SAMPLE_SIZE is reached.","title":"FPC Pseudocode Description"},{"location":"IOTA-NECTAR/6.3%20Fast%20Probabilistic%20Consensus/#getsample","text":"This function chooses a sample of nodeIDs for FPC queries. FUNCTION queryList = GetSample ( nodeList , manaList ) queryList = [] WHILE ( queryList does not contain QUERY_SIZE different elements ) newSample = SAMPLE ( nodeList , weight = manaList ) queryList = APPEND ( queryList , newSample ) RETURN queryList The function SAMPLE(nodeList, weight=manaList) chooses a random element from nodeList with weights corresponding to their Mana, i.e., the probability that a nodeID is chosen is proportional to manaList[nodeID] . Once the list queryList of nodes to query is chosen a node must obtain their opinions about the objects under voting. As there are two possibilities for nodes to communicate their opinions, via direct answers or via FPC statements, a node shall keep information on this behavior up to date. The message layout of the FPC statements is specified in Section 2.3 - Standard Payloads Layout . At the beginning of each round every node must prepare a query and send it to those nodes in queryList that replies directly (i.e., do not publish FPC statements). The queries must follow the layout that follows.","title":"GetSample"},{"location":"IOTA-NECTAR/6.3%20Fast%20Probabilistic%20Consensus/#queryrequest","text":"Name Type Description Version uint8 The message version. The schema specified in this RFC is for version 1 only. Tx count uint8 The number of TransactionIDs. TransactionIDs Tx count TransactionID, ordered by hash ASC Name Type Description TransactionID ByteArray[32] The ID of the transaction . Msg count uint8 The number of MessageIDs. MessageIDs Msg count MessageID, ordered by hash ASC Name Type Description MessageID ByteArray[32] The ID of the message . The respond to a QueryRequest must take follow the following form","title":"QueryRequest"},{"location":"IOTA-NECTAR/6.3%20Fast%20Probabilistic%20Consensus/#queryresponse","text":"Name Type Description Version uint8 The message version. The schema specified in this RFC is for version 1 only. Obj count uint8 The number of objectIDs. Must equal to Tx count + Msg count of the received QueryRequest Opinions Obj count ObjectIDs, in the same order as in received QueryRequest Name Type Description Opinion Byte The opinion on objectID . In the case that a certain objectID is unknwon to the node, it must respond with NULL . If the objectID is currently treated by FPC a node must respond with the current opinion, otherwise, retrieve the opinion from the opinionField of the objectID . If the opinionField is NULL the node must respond with NULL . Note that since the order of the opinions in QueryResponse is important a node may have to produce different messages QueryResponse for different querying nodes. QueryRequest and QueryResponse must be signed by the sending node. The communication channel for these messages is specified in the field \"services\" in the DiscoveryRequest. We write respond[node, objectIDs] for the respond, per direct QueryResponse or FPC statement, of the node on the objectID s. A node shall only respond to queries if all included objectsID have status answerQuery=TRUE .","title":"QueryResponse"},{"location":"IOTA-NECTAR/6.3%20Fast%20Probabilistic%20Consensus/#getopinion","text":"This function sends queries to all nodes of queryList and obtains their opinion either through QueryResponse messages of from FPC statements on the Tangle. FUNCTION opinionQuery = GetOpinion ( objectIDs , queryList ) SEND QueryRequest messages WAIT UNTIL TIME_OUT FOR ( node IN queryList ) IF ( node replied ) opinionQuery [ node , objectIDs ] = respond [ node , objectIDs ] ELSE IF ( node publishes on Tangle ) opinionQuery [ node , objectIDs ] = GetOpinionFromTangle [ node , objectID ] ELSE opinionQuery [ node , objectIDs ] = NA RETURN ( opinionQuery ) A node must receive a sufficient amount of replies to validate a given round; otherwise the ongoing FPC round is skipped. More precisely, the consensus Mana of the received opinions must be larger than MIN_MANA_PROPORTION times the sum of the consensus Mana of the sampled nodes. Once a node receives a FPC query it must prepare a response message as specified above, and shall sent the response as soon as possible. If a node decides to publish its opinions on the Tangle, it must create a so-called FPC statement message and issue it on the Tangle at the beginning of each round. At the end of each round, i.e., after the TIME_OUT expires, a node must update its opinion if CheckQuerySuccessful is TRUE. The node must calculate the proportion of the LIKE s in the obtained opinions and compare it to a certain threshold. The value of the threshold depends on the phase FPC is in. In the first round, a node must use FIRST_ROUND_THRESHOLD as a threshold, while in the subsequent rounds the node must use a random threshold obtained by GetRN() . Moreover, if cnt > TOTAL_ROUNDS_FINALIZATION - TOTAL_ROUNDS_ENDING_THRESHOLD the node must use ENDING_THRESHOLD for the threshold. The following pseudo-code describes the update of the opinion of one given objectID . It uses queryList and opinionQuery obtained by the functions GetSample and GetOpinion . The variable opinion describes the current opinion on objectID .","title":"GetOpinion"},{"location":"IOTA-NECTAR/6.3%20Fast%20Probabilistic%20Consensus/#opinionupdate","text":"This function updates the opinion of a node on objectID . FUNCTION opinion = OpinionUpdate ( objectID , opinion , queryList , opinionQuery , round ) manaList = GetActiveConsensusMana ( timeObjectID ) answerMana = ownMana queriedMana etaStar = 0 FOR node in queryList queriedMana += manaList [ node ] IF opinionQuery [ node , objectID ] ! = NA answerMana += manaList [ node ] IF opinionQuery [ node , objectID ] = LIKE etaStar ++ IF answerMana <= MIN_MANA_PROPORTION * queriedMana opinionNew = opinion # ELSE eta = etaStar / LENGTH ( queryList ) IF opinion = LIKE eta = ( ownMana + etaStar * ( answerMana - ownMana )) / answerMana ELSE IF opinion = DISLIKE eta = ( etaStar * ( answerMana - ownMana )) / answerMana WAIT UNTIL CurrentTime / ROUND_LENGTH IS INTEGER IF round = 1 threshold = FIRST_ROUND_THRESHOLD ELSE IF round <= TOTAL_ROUNDS_FINALIZATION - TOTAL_ROUNDS_ENDING_THRESHOLD WAIT DRNG_WAITING_TIME threshold = getRN ( SUBSEQUENT_LOWER_THRESHOLD , SUBSEQUENT_UPPER_THRESHOLD , CurrentTime ) IF threshold = NIL threshold = ( SUBSEQUENT_LOWER_THRESHOLD + SUBSEQUENT_UPPER_THRESHOLD ) / 2 ELSE threshold = ENDING_THRESHOLD IF eta < threshold opinionNew = DISLIKE ELSE opinionNew = LIKE RETURN opinioNew","title":"OpinionUpdate"},{"location":"IOTA-NECTAR/6.3%20Fast%20Probabilistic%20Consensus/#mainfpc","text":"This function describes the FPC for one objectID . It is triggered once queryStatus of an object is set to TRUE . FUNCTION opinion = MainFPC ( objectId , queryStatus ) IF queryStatus = TRUE opinion = GetInitialOpinion ( objectID ) cnt = 0 } WAIT UNTIL CurrentTime / ROUND_LENGTH IS INTEGER round = 1 WHILE queryStatus = TRUE queryList = GetSample ( nodeList , manaList ) opinionQuery = GetOpinion ( objectID , queryList ) opinionNew = OpinionUpdate ( objectID , opinion , queryList , opinionQuery , round ) IF opinion = opinionNew cnt ++ ELSE cnt = 1 opinion = opinionNew round ++ IF cnt = TOTAL_ROUNDS_FINALIZATION queryStatus = FALSE IF round >= MAX_ROUND queryStatus = FALSE opinion = 1 RETURN opinion","title":"MainFPC"},{"location":"IOTA-NECTAR/6.3%20Fast%20Probabilistic%20Consensus/#optimizations-suggestions","text":"The design given above exemplifies all the mandatory elements of the FPC protocol. There are several possible ways to optimize the performance of FPC. For example: FPC possibly exposes the public IP adresses of all the IOTA nodes. This can be limited by publishing statements on Tangle. However, if all nodes decide to publish their statements this may have a negative effect on the scalability of the protocol. Please refer to Fast Probabilistic Consensus with Weighted Votes for more discussions on how to optimize the message overhead. Monotonicity and consistency rules may be applied to reduce the sizes of the messages. The choice of the FPC parameters could be optimized. The optimal choice depends on the actual mana distribution and network latency.","title":"Optimizations Suggestions"},{"location":"IOTA-NECTAR/6.4%20Finalization/","text":"6.4 Approval Weight and Finality \u00b6 6.4.1 Introduction \u00b6 This part of the specifications defines the Approval Weight tool, which allows the notion of Finality . As every node might have slightly different perceptions of the Tangle at a given time, such a notion is necessary to guarantee consensus on the Tangle and its ledger state. The intuition behind the approval weight of a given message is that the more influential messages are approving a given message, the more trustworthy such a message will be for the other nodes, and thus the higher the probability that this message branch will be included in the main branch, i.e., will update the ledger state permanently. More details on branches and ledger state may be found in Section 5.2 - Ledger State . The approval weight tool is inspired by the confirmation confidence tool, initially defined in the legacy Tangle whitepaper . However, unlike confirmation confidence which only considered the weight of the future cone of a message to decide if it was final, the approval weight now considers the proportion of approving active consensus Mana, making the protocol more robust against spam and Sybil attacks. 6.4.2 Definitions \u00b6 To define approval weight, we first need to understand what it means to support a message, we require some concepts of branches from Section 5.2 - Ledger State . - Conflict: Two transactions conflict if they consume the same output. A conflict is a transaction that conflicts with another transaction. A transaction \\(x\\) conflicts with a branch \\(B\\) if the set of conflicts in \\(x\\) 's UTXO past cone and the set of conflicts in \\(B\\) conflict. - Node Approval: We say that a node approves a given message \\(x\\) if it has issued a message \\(y\\) in the strong future cone of \\(x\\) . A node approves a transaction if it approves some message containing that transaction. - Conflict Supporter: A node supports a conflict if: - It issued a message approving a message containing that transaction. - It has not issued a message on a conflicting branch with a more recent timestamp or with the same timestamp but greater message ID. - Branch Supporter: A node supports a branch if it supports all of its conflicts. Equivalently, the supporters of a branch are the intersection of all the supporters of its conflicts. - Message Supporter: The supporters of a message is the intersection of the approvers of the message, and the supporter of its branch. - Active Consensus Mana: The active consensus Mana is defined as the sum of the consensus Mana of all nodes that issued messages during the second last complete epoch cepoch-2 , before the current epoch cepoch . We say that a node that has not issued a message within that epoch has 0 active consensus mana. See Section 5.3 - Mana . To be clear a node cannot be a supporter of two conflicting transactions. If it approves two messages with conflicting transactions, it supports the one it more recently references (with respect to the timestamp). In the case where the node more recently supported an incompatible message in a different conflict set, then it doesn't support any of the messages. When a new message is booked, the node goes to the message's branch in the branch DAG and walks through the branch's history giving support to all the conflicts in its past cone and revoking support from conflicting branches. Here's an example of how the propagation will look like: The green node issued message 1 and attached it to Branch 1.1 + Branch 4.1.1 . Thus, green node is a supporter of Branch 1.1 + Branch 4.1.1 , and it's also a supporter of the parent branches, which are (from top to bottom) Branch 4.1.1 , Branch 1.1 , Branch 4.1 , Branch 1 , and Branch 4 . Later, the green node issued message 2 and attached it to Branch 4.1.2 . This makes the green node a supporter of Branch 4.1.2 , however, Branch 4.1.1 is conflicting with Branch 4.1.2 , which makes green node not a supporter of Branch 4.1.1 , and therefore the support to Branch 1.1 + Branch 4.1.1 is removed as well. Finally, green nodes issued message 3 , which is in Branch 2 . Now the green node is a supporter of Branch 2 , and no longer a supporter of Branch 1 , since Branch 1 is conflicting with Branch 2 . Note that, this supporter removal will propagate to child branches. Thus, green node is removed from Branch 1.1 . Since Branch 3 , 4 , and both of their child branches have nothing to do with this attachment, the supporter status remains. 6.4.2 Approval Weight \u00b6 The approval weight of a conflict (resp. branch or message) is the dot product of the vectors of supporters and the normalized consensus Mana vector (see Section 5.3 - Mana ). Equivalently, the approval weight is the proportion of active consensus Mana that belongs to the supporters of the conflict (resp. branch or message). We will use \\(\\text{AW}(x)\\) to represent the approval weight of a message or branch \\(x\\) . There are several important facts to state about approval weight: - Approval weight range : The approval weight is always between \\(0\\) and \\(1\\) , and thus can be expressed as a percentage. - Approval weight equivalency : For a conflict \\(x\\) attached once in a message \\(m\\) , the following are the same: the approval weight of \\(x\\) , the approval weight of the conflict branch defined by \\(x\\) , and the approval weight of the message \\(m\\) . - Tangle Monotonicity: The approval weight of a message is smaller than its past cone, i.e. if message \\(x\\) approves message \\(y\\) , then \\(\\text{AW}(y)\\geq \\text{AW}(x)\\) . - Branch Monotonicity: The approval weight of a branch is greater than the branches in pastcone on the branch DAG, i.e., if branch \\(B\\) contains branch \\(C\\) , then \\(\\text{AW}(C)\\geq \\text{AW}(B)\\) . - No Time Monotonicity: The approval weight of a fixed message or branch \\(x\\) does not necessarily grow with time because of the nodes' active consensus Mana fluctuates and support can be revoked. - Approval weight inequalities: For any message \\(m\\) and its branch \\(B\\) , we have \\(\\text{AW}(B)\\geq \\text{AW}(m)\\) . Similarly, for any conflict \\(x\\) within a branch, \\(\\text{AW}(x)\\geq \\text{AW}(B)\\) , since any supporter of the branch \\(B\\) is a supporter of \\(x\\) . Observe that the non-monotonicity on time is actually desirable, as otherwise it would not be possible to orphan malicious or non-preferred conflicting messages. 6.4.3 Finality \u00b6 Finality in IOTA 2.0 must always be considered as probabilistic, in the sense that a final message is included in the ledger with a very high probability. Two desired properties in a finality criterion are a fast confirmation rate and a high probability of non-reversibility. We use interchangeably the terms \"finality\" and \"confirmation\". We now present the proposed criterion for finality. Branch Finality/Confirmation: A branch \\(B\\) is considered finalized (or confirmed) if its approval weight is at least \\(0.5\\) higher than any conflicting branch. The master branch is always finalized. Message Finality/Confirmation: A message \\(m\\) is considered finalized (or confirmed) if \\(\\text{AW}(m)>0.5\\) and its branch is finalized. Transaction Finality/Confirmation: A transaction is considered finalized (or confirmed) if both its message and its branch are final (confirmed). Because of the Tangle monotonicity property, if a message is finalised, its entire past cone is finalised as well. 6.4.4 Markers Application to Finality \u00b6 The approval weight of the branch is updated whenever the supporters are updated. However, it is impractical to store the supporters of every message, and even calculating it on demand is unfeasible, since the computational cost of doing a future cone search to determine its approvers is immense. To ease this calculation, we make use of the markers tool, see Section 4.7 - Markers , to approximate the approval of a message weight in an efficient way. Markers are basically chains of indexed messages, and each message is associated with the most recent marker it approves and the oldest marker that approves it. When a new message arrives, the approvers of each marker can be updated by traversing the much smaller marker DAG and, from the Tangle monotonicity property, we know that if the marker achieve a certain value of approval weight, the message it approves will have a higher value. Using those properties, we can define a lightweight criterion which we call Markers Application to Finality: The supporters of any mark are tracked, which is made easier by the metadata associated to each marker, see Section 4.7 - Markers . If any marker reaches message confirmation, we give the \"confirmed\" status to all messages in its past cone, and hence transaction confirmation to all transactions it may contain. If a tracked marker reaches age FinalityMaxAge without achieving confirmation, it will receive the status \"Orphaned\". 6.4.5 Liked and monotonically liked \u00b6 Via finality, the approval weight is also used in conjunction with FPC and to determine which branches should be considered for tip selection. To do this we have the concept of branches and conflicts being \"liked\". - Liked conflict: A conflict is liked (or individually liked) if either: - The opinion of the transaction is true and the level is either 2 or 3 (i.e. FPC has terminated with liked status, see Section 6.1 - Objects of Consensus ) AND it does not conflict with a finalized transaction. - The conflict is finalized. - Individually liked conflict branch: A conflict branch is individually liked if the conflict defining it is liked. - Monotonically liked branch: A branch is monotonically liked if all of its conflicts are liked. Equivalently, a branch is monotonically liked if all of its conflict branches in its branch past cone are individually liked. FPC initially determines which conflicts are liked. However, nodes that are syncing and missed the FPC voting will default to the conflicts which are finalised. Decisions about each conflict set are carried out by FPC individually and so we separate between \"individually liked\" and \"monotonically liked\". Branches that are monotonically liked have their entire history liked and can be included in the strong past cone of messages. Monotonically like branch IDs will thus receive more supporters and thus eventually become finalised. Note : Once a branch gets confirmed, the conflicting ones receive the status \"Rejected\".","title":"6.4 Finalization"},{"location":"IOTA-NECTAR/6.4%20Finalization/#64-approval-weight-and-finality","text":"","title":"6.4 Approval Weight and Finality"},{"location":"IOTA-NECTAR/6.4%20Finalization/#641-introduction","text":"This part of the specifications defines the Approval Weight tool, which allows the notion of Finality . As every node might have slightly different perceptions of the Tangle at a given time, such a notion is necessary to guarantee consensus on the Tangle and its ledger state. The intuition behind the approval weight of a given message is that the more influential messages are approving a given message, the more trustworthy such a message will be for the other nodes, and thus the higher the probability that this message branch will be included in the main branch, i.e., will update the ledger state permanently. More details on branches and ledger state may be found in Section 5.2 - Ledger State . The approval weight tool is inspired by the confirmation confidence tool, initially defined in the legacy Tangle whitepaper . However, unlike confirmation confidence which only considered the weight of the future cone of a message to decide if it was final, the approval weight now considers the proportion of approving active consensus Mana, making the protocol more robust against spam and Sybil attacks.","title":"6.4.1 Introduction"},{"location":"IOTA-NECTAR/6.4%20Finalization/#642-definitions","text":"To define approval weight, we first need to understand what it means to support a message, we require some concepts of branches from Section 5.2 - Ledger State . - Conflict: Two transactions conflict if they consume the same output. A conflict is a transaction that conflicts with another transaction. A transaction \\(x\\) conflicts with a branch \\(B\\) if the set of conflicts in \\(x\\) 's UTXO past cone and the set of conflicts in \\(B\\) conflict. - Node Approval: We say that a node approves a given message \\(x\\) if it has issued a message \\(y\\) in the strong future cone of \\(x\\) . A node approves a transaction if it approves some message containing that transaction. - Conflict Supporter: A node supports a conflict if: - It issued a message approving a message containing that transaction. - It has not issued a message on a conflicting branch with a more recent timestamp or with the same timestamp but greater message ID. - Branch Supporter: A node supports a branch if it supports all of its conflicts. Equivalently, the supporters of a branch are the intersection of all the supporters of its conflicts. - Message Supporter: The supporters of a message is the intersection of the approvers of the message, and the supporter of its branch. - Active Consensus Mana: The active consensus Mana is defined as the sum of the consensus Mana of all nodes that issued messages during the second last complete epoch cepoch-2 , before the current epoch cepoch . We say that a node that has not issued a message within that epoch has 0 active consensus mana. See Section 5.3 - Mana . To be clear a node cannot be a supporter of two conflicting transactions. If it approves two messages with conflicting transactions, it supports the one it more recently references (with respect to the timestamp). In the case where the node more recently supported an incompatible message in a different conflict set, then it doesn't support any of the messages. When a new message is booked, the node goes to the message's branch in the branch DAG and walks through the branch's history giving support to all the conflicts in its past cone and revoking support from conflicting branches. Here's an example of how the propagation will look like: The green node issued message 1 and attached it to Branch 1.1 + Branch 4.1.1 . Thus, green node is a supporter of Branch 1.1 + Branch 4.1.1 , and it's also a supporter of the parent branches, which are (from top to bottom) Branch 4.1.1 , Branch 1.1 , Branch 4.1 , Branch 1 , and Branch 4 . Later, the green node issued message 2 and attached it to Branch 4.1.2 . This makes the green node a supporter of Branch 4.1.2 , however, Branch 4.1.1 is conflicting with Branch 4.1.2 , which makes green node not a supporter of Branch 4.1.1 , and therefore the support to Branch 1.1 + Branch 4.1.1 is removed as well. Finally, green nodes issued message 3 , which is in Branch 2 . Now the green node is a supporter of Branch 2 , and no longer a supporter of Branch 1 , since Branch 1 is conflicting with Branch 2 . Note that, this supporter removal will propagate to child branches. Thus, green node is removed from Branch 1.1 . Since Branch 3 , 4 , and both of their child branches have nothing to do with this attachment, the supporter status remains.","title":"6.4.2 Definitions"},{"location":"IOTA-NECTAR/6.4%20Finalization/#642-approval-weight","text":"The approval weight of a conflict (resp. branch or message) is the dot product of the vectors of supporters and the normalized consensus Mana vector (see Section 5.3 - Mana ). Equivalently, the approval weight is the proportion of active consensus Mana that belongs to the supporters of the conflict (resp. branch or message). We will use \\(\\text{AW}(x)\\) to represent the approval weight of a message or branch \\(x\\) . There are several important facts to state about approval weight: - Approval weight range : The approval weight is always between \\(0\\) and \\(1\\) , and thus can be expressed as a percentage. - Approval weight equivalency : For a conflict \\(x\\) attached once in a message \\(m\\) , the following are the same: the approval weight of \\(x\\) , the approval weight of the conflict branch defined by \\(x\\) , and the approval weight of the message \\(m\\) . - Tangle Monotonicity: The approval weight of a message is smaller than its past cone, i.e. if message \\(x\\) approves message \\(y\\) , then \\(\\text{AW}(y)\\geq \\text{AW}(x)\\) . - Branch Monotonicity: The approval weight of a branch is greater than the branches in pastcone on the branch DAG, i.e., if branch \\(B\\) contains branch \\(C\\) , then \\(\\text{AW}(C)\\geq \\text{AW}(B)\\) . - No Time Monotonicity: The approval weight of a fixed message or branch \\(x\\) does not necessarily grow with time because of the nodes' active consensus Mana fluctuates and support can be revoked. - Approval weight inequalities: For any message \\(m\\) and its branch \\(B\\) , we have \\(\\text{AW}(B)\\geq \\text{AW}(m)\\) . Similarly, for any conflict \\(x\\) within a branch, \\(\\text{AW}(x)\\geq \\text{AW}(B)\\) , since any supporter of the branch \\(B\\) is a supporter of \\(x\\) . Observe that the non-monotonicity on time is actually desirable, as otherwise it would not be possible to orphan malicious or non-preferred conflicting messages.","title":"6.4.2 Approval Weight"},{"location":"IOTA-NECTAR/6.4%20Finalization/#643-finality","text":"Finality in IOTA 2.0 must always be considered as probabilistic, in the sense that a final message is included in the ledger with a very high probability. Two desired properties in a finality criterion are a fast confirmation rate and a high probability of non-reversibility. We use interchangeably the terms \"finality\" and \"confirmation\". We now present the proposed criterion for finality. Branch Finality/Confirmation: A branch \\(B\\) is considered finalized (or confirmed) if its approval weight is at least \\(0.5\\) higher than any conflicting branch. The master branch is always finalized. Message Finality/Confirmation: A message \\(m\\) is considered finalized (or confirmed) if \\(\\text{AW}(m)>0.5\\) and its branch is finalized. Transaction Finality/Confirmation: A transaction is considered finalized (or confirmed) if both its message and its branch are final (confirmed). Because of the Tangle monotonicity property, if a message is finalised, its entire past cone is finalised as well.","title":"6.4.3 Finality"},{"location":"IOTA-NECTAR/6.4%20Finalization/#644-markers-application-to-finality","text":"The approval weight of the branch is updated whenever the supporters are updated. However, it is impractical to store the supporters of every message, and even calculating it on demand is unfeasible, since the computational cost of doing a future cone search to determine its approvers is immense. To ease this calculation, we make use of the markers tool, see Section 4.7 - Markers , to approximate the approval of a message weight in an efficient way. Markers are basically chains of indexed messages, and each message is associated with the most recent marker it approves and the oldest marker that approves it. When a new message arrives, the approvers of each marker can be updated by traversing the much smaller marker DAG and, from the Tangle monotonicity property, we know that if the marker achieve a certain value of approval weight, the message it approves will have a higher value. Using those properties, we can define a lightweight criterion which we call Markers Application to Finality: The supporters of any mark are tracked, which is made easier by the metadata associated to each marker, see Section 4.7 - Markers . If any marker reaches message confirmation, we give the \"confirmed\" status to all messages in its past cone, and hence transaction confirmation to all transactions it may contain. If a tracked marker reaches age FinalityMaxAge without achieving confirmation, it will receive the status \"Orphaned\".","title":"6.4.4 Markers Application to Finality"},{"location":"IOTA-NECTAR/6.4%20Finalization/#645-liked-and-monotonically-liked","text":"Via finality, the approval weight is also used in conjunction with FPC and to determine which branches should be considered for tip selection. To do this we have the concept of branches and conflicts being \"liked\". - Liked conflict: A conflict is liked (or individually liked) if either: - The opinion of the transaction is true and the level is either 2 or 3 (i.e. FPC has terminated with liked status, see Section 6.1 - Objects of Consensus ) AND it does not conflict with a finalized transaction. - The conflict is finalized. - Individually liked conflict branch: A conflict branch is individually liked if the conflict defining it is liked. - Monotonically liked branch: A branch is monotonically liked if all of its conflicts are liked. Equivalently, a branch is monotonically liked if all of its conflict branches in its branch past cone are individually liked. FPC initially determines which conflicts are liked. However, nodes that are syncing and missed the FPC voting will default to the conflicts which are finalised. Decisions about each conflict set are carried out by FPC individually and so we separate between \"individually liked\" and \"monotonically liked\". Branches that are monotonically liked have their entire history liked and can be included in the strong past cone of messages. Monotonically like branch IDs will thus receive more supporters and thus eventually become finalised. Note : Once a branch gets confirmed, the conflicting ones receive the status \"Rejected\".","title":"6.4.5 Liked and monotonically liked"},{"location":"IOTA-NECTAR/6.5%20dRNG/","text":"6.5 Distributed Random Number Generator \u00b6 The module presented in this specification allows for the distributed generation of randomness for the post-Coordicide IOTA network. The distributed random number generator (dRNG) protocol is divided into three phases: COMMITTEE SELECTION: In the first phase, a committee of high Consensus Mana nodes is selected. The procedure is objective i.e., all of the nodes in the network reach a consensus on which nodes should be in the committee. In order for a node to be considered as a candidate to the committee, it needs to declare its willingness to participate, with a special application message . When all of the required application messages are recorded in the Tangle, the committeeNodes top consensus Mana holders among the candidates are selected as the committee. In the case where some of the required messages fail to be produced, the committee selection will consequently fail as well. DKG PHASE: In the second setup phase, the committee members create a collective private key which will be used later to generate the random number, using the \\((t,n)\\) Distributed Key Generation (DKG), that does not rely on centralized, trusted third parties. The participation of the nodes in this phase can be publicly verified since the messages exchange takes place in the Tangle. PUBLICATION PHASE: This last phase consists of the periodical publication of the beacon messages in the Tangle. A single individual beacon message should not be sufficient to reveal the random number; instead, the beacon messages from at least \\(t\\) out of \\(n\\) committee members are needed for the next random number being revealed. Additionally, the committee members publish a collective beacon message, which would contain the random number. A large part of the procedures in this specification is based on the article Committee selection in DAG distributed ledgers and applications , where authors discuss multiple methods of the committee selection and applications. 6.5.1 Dependencies \u00b6 The dRNG module depends on the Section 5.3 - Mana since it uses the Consensus Mana (cMana) vector as a measure of trustworthiness. Specifically, it uses the list of the top cMana holders to select a committee to produce the random numbers. During the committee selection, we do not assume a perfect agreement on the cMana values, i.e., different nodes can have slightly different perceptions of the cMana values of other nodes (due to the different local clocks). Obtaining consensus on the cMana values is the central part of this documentation. The random numbers produced by dRNG are used in Section 6.3 - Fast Probabilistic Consensus . 6.5.2 Parameters \u00b6 Table 6.5.2.1 dRNG parameters Name Type Description Value rnPeriod duration Random number is produced every rnPeriod seconds 20 [sec] committeeNodes integer Number of nodes in the committee 10 [nodes] committeeSeats integer The number of identities (seats) in the top Mana holders committee equals committeeSeats . It is different from committeeNodes because some of the nodes receive double seats in the committee. 15 [seats] sigThreshold integer Signature threshold parameter (number of beacon messages needed to obtain randomness) 8 [messages] ([seats]) committeeUpdate duration Period of committee update 1 [day] = 86400 [sec] applicationWindow duration Time window of the ''application'' message submission 120 [sec] TIMESTAMP_CUTOFF duration Message timestamp cutoff (Assuming the node is in sync, the time after which point the node will receive no new messages with a particular timestamp which will be finalized) 2 DLARGE + W = 90[sec] For more information on the TIMESTAMP_CUTOFF see section Section 4.2 - Timestamps 6.5.3 Committee selection \u00b6 To select the committee based on the cMana, we need to achieve consensus on these values. To solve this problem, we use epochs a reference point which can be used to calculate the cMana values in an objective manner. The willingness to participate in the committee is announced with a special application message, which like any other transactions in the Tangle are equipped with timestamps. Since the nodes following the protocol judge and invalidate messages which timestamps are too off, we can assume that the application messages can reliably give us a list of nodes interested in joining the committee. The committee selection process starts at the time \\(t_S\\) and should be done (assuming no problems occur) at the time \\(t_F\\) . The time \\(t_F\\) is determined by the committee update time, \\(t_S\\) depends also on the applicationWindow and TIMESTAMP_CUTOFF . Only nodes that are in synch with the network should participate in the committee selection. If a node is out of synch ( SyncStatus = FALSE ) it should skip this committee selection. 6.5.3.1 Application messages \u00b6 Any node can issue an application message. Such a message would be processed by the nodes (assuming it passes the congestion control, along with other checks). However, for a low mana node, there is no incentive to apply for the committee, as the probability of being selected is very low; hence, they can decide to not take part in sending application messages. Although it is allowed, sending multiple application messages is pointless and costly due to the congestion control mechanism. For brevity denote TIMESTAMP_CUTOFF by \\(\\Delta_C\\) and applicationWindow by \\(\\Delta_A\\) . Assume that a committee should be formed at the time \\(t_F\\) (which is known to all interested nodes; it is defined on the protocol level). Assume further that the time \\(t_F\\) is in the epoch \\(E\\) i.e., \\(t_F\\) \\(\\in\\) \\([t_{E-1}\\) , \\(t_E]\\) . Then the active consensus Mana vector from the time \\(t_{E-2}\\) is calculated, which is the balance from two epochs before \\(t_F\\) . The committee selection process starts with the opening of the application message window at the time \\(t_S\\) , where \\(t_S\\) = \\(t_F\\) - \\(\\Delta_A\\) -2 \\(\\Delta_C\\) . For as long as the application window is open, nodes can issue application messages. See the subsection \"6.5.3.1 Application message sending - default algorithm\" for the proposed algorithm of issuing application messages (which is not enforceable). 6.5.3.2 Application message sending - default algorithm \u00b6 A node is said to be \\(M_\\ell\\) if its consensus Mana rank is less or equal to \\(\\ell\\) (node is among \\(\\ell\\) top Mana nodes). Computation of node's Mana rank is taking place with respect to the time from two epochs ago i.e., with respect to \\(t_{E-2}\\) under the assumption that \\(t_S \\in [t_{E-1},t_E]\\) . For brevity denote committeeNodes by \\(m\\) . If an interested node \\(x\\) is \\(M_{2m}\\) then it issues an application at the time \\(t_S\\) . Notice that, in general, not all of the \\(2m\\) application messages will be sent (due to for example nodes going offline or malfunction). If less than \\(m\\) strongly valid application messages are sent at \\(T_S\\) , the nodes that are \\(M_{3m}\\) (but not \\(M_{2m}\\) ) issue their application messages at the time \\(T_S- \\Delta_A \\frac{1}{2}\\) and so on. In general, for \\(k>2\\) , if a node \\(x\\) which is \\(M_{m k}\\) but not \\(M_{m (k-1)}\\) , it submits a committee application whenever before the time \\(T_S- \\Delta_A \\frac{k-2}{k-1}\\) there are less than \\(m\\) strongly valid application messages with cMana greater than the cMana of node \\(x\\) . See subsection 6.5.9 Pseudocodes for the pseudocodes of the default application message sending procedure. If at least \\(m\\) of the nodes sent an application message within the time interval, the committee is formed from the top \\(m\\) Mana nodes who applied. Due to the network delay, this can be confirmed only at the time \\(t_S+\\Delta_A+\\Delta_C\\) . If less than \\(m\\) nodes send application messages, then the committee selection will fail. This is confirmed at the time \\(t_S+\\Delta_A+\\Delta_C\\) . In this case, the procedure should be repeated immediately, with new starting time \\(t'_S\\) and finish time \\(t'_F\\) such \\(t'_S =t_S+\\Delta_A+\\Delta_C\\) and \\(t'_F=t_F+\\Delta_A+\\Delta_C\\) . 6.5.4 DKG phase \u00b6 After a successful committee selection, confirmed at the time \\(t_S+\\Delta_C+\\Delta_A\\) with respect to the node's local clock, the DKG phase starts. In this phase, the committee nodes exchange the Deal messages to produce a public/private collective key. There is no time window for the DKG phase and nodes should proceed with the corresponding DKG message exchange as soon as the committee selection is confirmed (time \\(t_S+\\Delta_C+\\Delta_A\\) ). Only DKG messages with this timestamp are accepted. If any of the committee nodes refuse to create a collective key pair by not exchanging the Deal DKG messages, the DKG phase fails. This can be confirmed at the time $t_F= \\(t_S+2\\Delta_C+\\Delta_A\\) . Moreover, since the message exchange occurs on the Tangle, everybody can identify the nodes that caused the failure. In the case of DKG phase failure, the entire committee selection is repeated (including the application phase). New start and finish time are $t'_S = t_F= \\(t_S+2\\Delta_C+\\Delta_A\\) and \\(t'_F= t_F+2\\Delta_C+\\Delta_A\\) . The malicious node is then excluded from the new committee selection - all application messages issued by a malicious node are ignored. Ban on the committee application is lifted after a successful committee selection i.e., the committee produces its first beacon messages. In other words, if a node failed to produce a DKG message (either due to malfunction or maliciousness) it cannot apply to be in the current committee, however, it can apply in the next committee selection process. 6.5.5 Double seats \u00b6 We can increase the security of the dRNG beacon by granting double seats to half of the committee members that have the highest committee Mana. Those nodes would receive two private keys (identities) with which they sign beacon messages in the Tangle. From the technical point of view, the two seats are completely separate, and issued Beacon messages can not be combined (even though they were signed by the same node). This modification increases the amount of Mana required to \"overtake\" the committee, which is understood as gaining sigThreshold of seats in the committee. The number of nodes in the committee with double seats equals \\(\\lfloor m/2 \\rfloor\\) (top half of the committee nodes). The total number of identities in the committee equals \\(m + \\lfloor m/2 \\rfloor\\) . 6.5.6 Publication of the random number \u00b6 The committee will collectively generate a random number based on the set of beacon messages that each node will individually produce. A single beacon message is not sufficient to reveal the random number; instead, sigThreshold or more beacon messages are needed for the next random number to be revealed. 6.5.6.1 Collective beacon message \u00b6 To recover the random number from the individual beacon messages, all nodes in the network would need to perform Lagrange interpolation. To avoid that, we propose that the committee nodes produce a collective beacon message , which contains a pre-computed random number (meaning that the committee nodes perform the Lagrange interpolation on their own). Since the committee size is small and the expected throughput of the network is large, we require all committee members to produce this collective beacon message as soon as they receive sigThreshold individual beacon messages. The cost of getting randomness from the collective beacon would be reduced as only (additionally to the default message checks) the signature verification would be required. 6.5.7 Duties of the old committee \u00b6 An old committee should only stop producing randomness if another committee was successfully selected and started producing random numbers, which will be confirmed when the first collective beacon message is produced by the new committee and can be read directly from the Tangle. 6.5.8 Alternative dRNG and backup options \u00b6 To increase the liveness of the random number production multiple dRNGs may be deployed. Secondary dRNGs can be used if the primary one is not available; it is also possible that users alternate between random numbers from multiple dRNGs. However, this discussion is out of the scope of this specification document. 6.5.9 Pseudocodes \u00b6 Actions after receiving incoming transaction which is an application message: IF ( NOT IsBlacklisted ( IssuingNode ( tx ))) IF ( Mana ( IssuingNode ( tx ), E - 2 ) > Mana ( My_node , E - 2 )) numberValidApplicationMessagesWithManaHigherThanMine ++ Actions of a node interested in committee participation: IF ( thisNodeWantsToParticipateInDRNG ) WaitUntil ( tS ) ell = GetManaRank ( myNode , Epoch - 2 ) ApplicationMessageSend ( ell ) FUNCTION ApplicationMessageSend ( ell ) IF ( ell <= 2 m ) SendApplicationMessage () ELSE WaitUntil ( T_S - applicationWindow *[ 1 - ( floor ( ell / m ) - 2 ) / ( floor ( ell / m ) - 1 ) ] ) IF ( numberValidApplicationMessagesWithManaHigherThanMine < m ) SendApplicationMessage () 6.5.10 Payload layout \u00b6 DRNG payload layout is discussed in Section 2.3 - Standard Payloads Layout .","title":"6.5 dRNG"},{"location":"IOTA-NECTAR/6.5%20dRNG/#65-distributed-random-number-generator","text":"The module presented in this specification allows for the distributed generation of randomness for the post-Coordicide IOTA network. The distributed random number generator (dRNG) protocol is divided into three phases: COMMITTEE SELECTION: In the first phase, a committee of high Consensus Mana nodes is selected. The procedure is objective i.e., all of the nodes in the network reach a consensus on which nodes should be in the committee. In order for a node to be considered as a candidate to the committee, it needs to declare its willingness to participate, with a special application message . When all of the required application messages are recorded in the Tangle, the committeeNodes top consensus Mana holders among the candidates are selected as the committee. In the case where some of the required messages fail to be produced, the committee selection will consequently fail as well. DKG PHASE: In the second setup phase, the committee members create a collective private key which will be used later to generate the random number, using the \\((t,n)\\) Distributed Key Generation (DKG), that does not rely on centralized, trusted third parties. The participation of the nodes in this phase can be publicly verified since the messages exchange takes place in the Tangle. PUBLICATION PHASE: This last phase consists of the periodical publication of the beacon messages in the Tangle. A single individual beacon message should not be sufficient to reveal the random number; instead, the beacon messages from at least \\(t\\) out of \\(n\\) committee members are needed for the next random number being revealed. Additionally, the committee members publish a collective beacon message, which would contain the random number. A large part of the procedures in this specification is based on the article Committee selection in DAG distributed ledgers and applications , where authors discuss multiple methods of the committee selection and applications.","title":"6.5 Distributed Random Number Generator"},{"location":"IOTA-NECTAR/6.5%20dRNG/#651-dependencies","text":"The dRNG module depends on the Section 5.3 - Mana since it uses the Consensus Mana (cMana) vector as a measure of trustworthiness. Specifically, it uses the list of the top cMana holders to select a committee to produce the random numbers. During the committee selection, we do not assume a perfect agreement on the cMana values, i.e., different nodes can have slightly different perceptions of the cMana values of other nodes (due to the different local clocks). Obtaining consensus on the cMana values is the central part of this documentation. The random numbers produced by dRNG are used in Section 6.3 - Fast Probabilistic Consensus .","title":"6.5.1 Dependencies"},{"location":"IOTA-NECTAR/6.5%20dRNG/#652-parameters","text":"Table 6.5.2.1 dRNG parameters Name Type Description Value rnPeriod duration Random number is produced every rnPeriod seconds 20 [sec] committeeNodes integer Number of nodes in the committee 10 [nodes] committeeSeats integer The number of identities (seats) in the top Mana holders committee equals committeeSeats . It is different from committeeNodes because some of the nodes receive double seats in the committee. 15 [seats] sigThreshold integer Signature threshold parameter (number of beacon messages needed to obtain randomness) 8 [messages] ([seats]) committeeUpdate duration Period of committee update 1 [day] = 86400 [sec] applicationWindow duration Time window of the ''application'' message submission 120 [sec] TIMESTAMP_CUTOFF duration Message timestamp cutoff (Assuming the node is in sync, the time after which point the node will receive no new messages with a particular timestamp which will be finalized) 2 DLARGE + W = 90[sec] For more information on the TIMESTAMP_CUTOFF see section Section 4.2 - Timestamps","title":"6.5.2 Parameters"},{"location":"IOTA-NECTAR/6.5%20dRNG/#653-committee-selection","text":"To select the committee based on the cMana, we need to achieve consensus on these values. To solve this problem, we use epochs a reference point which can be used to calculate the cMana values in an objective manner. The willingness to participate in the committee is announced with a special application message, which like any other transactions in the Tangle are equipped with timestamps. Since the nodes following the protocol judge and invalidate messages which timestamps are too off, we can assume that the application messages can reliably give us a list of nodes interested in joining the committee. The committee selection process starts at the time \\(t_S\\) and should be done (assuming no problems occur) at the time \\(t_F\\) . The time \\(t_F\\) is determined by the committee update time, \\(t_S\\) depends also on the applicationWindow and TIMESTAMP_CUTOFF . Only nodes that are in synch with the network should participate in the committee selection. If a node is out of synch ( SyncStatus = FALSE ) it should skip this committee selection.","title":"6.5.3  Committee selection"},{"location":"IOTA-NECTAR/6.5%20dRNG/#6531-application-messages","text":"Any node can issue an application message. Such a message would be processed by the nodes (assuming it passes the congestion control, along with other checks). However, for a low mana node, there is no incentive to apply for the committee, as the probability of being selected is very low; hence, they can decide to not take part in sending application messages. Although it is allowed, sending multiple application messages is pointless and costly due to the congestion control mechanism. For brevity denote TIMESTAMP_CUTOFF by \\(\\Delta_C\\) and applicationWindow by \\(\\Delta_A\\) . Assume that a committee should be formed at the time \\(t_F\\) (which is known to all interested nodes; it is defined on the protocol level). Assume further that the time \\(t_F\\) is in the epoch \\(E\\) i.e., \\(t_F\\) \\(\\in\\) \\([t_{E-1}\\) , \\(t_E]\\) . Then the active consensus Mana vector from the time \\(t_{E-2}\\) is calculated, which is the balance from two epochs before \\(t_F\\) . The committee selection process starts with the opening of the application message window at the time \\(t_S\\) , where \\(t_S\\) = \\(t_F\\) - \\(\\Delta_A\\) -2 \\(\\Delta_C\\) . For as long as the application window is open, nodes can issue application messages. See the subsection \"6.5.3.1 Application message sending - default algorithm\" for the proposed algorithm of issuing application messages (which is not enforceable).","title":"6.5.3.1 Application messages"},{"location":"IOTA-NECTAR/6.5%20dRNG/#6532-application-message-sending-default-algorithm","text":"A node is said to be \\(M_\\ell\\) if its consensus Mana rank is less or equal to \\(\\ell\\) (node is among \\(\\ell\\) top Mana nodes). Computation of node's Mana rank is taking place with respect to the time from two epochs ago i.e., with respect to \\(t_{E-2}\\) under the assumption that \\(t_S \\in [t_{E-1},t_E]\\) . For brevity denote committeeNodes by \\(m\\) . If an interested node \\(x\\) is \\(M_{2m}\\) then it issues an application at the time \\(t_S\\) . Notice that, in general, not all of the \\(2m\\) application messages will be sent (due to for example nodes going offline or malfunction). If less than \\(m\\) strongly valid application messages are sent at \\(T_S\\) , the nodes that are \\(M_{3m}\\) (but not \\(M_{2m}\\) ) issue their application messages at the time \\(T_S- \\Delta_A \\frac{1}{2}\\) and so on. In general, for \\(k>2\\) , if a node \\(x\\) which is \\(M_{m k}\\) but not \\(M_{m (k-1)}\\) , it submits a committee application whenever before the time \\(T_S- \\Delta_A \\frac{k-2}{k-1}\\) there are less than \\(m\\) strongly valid application messages with cMana greater than the cMana of node \\(x\\) . See subsection 6.5.9 Pseudocodes for the pseudocodes of the default application message sending procedure. If at least \\(m\\) of the nodes sent an application message within the time interval, the committee is formed from the top \\(m\\) Mana nodes who applied. Due to the network delay, this can be confirmed only at the time \\(t_S+\\Delta_A+\\Delta_C\\) . If less than \\(m\\) nodes send application messages, then the committee selection will fail. This is confirmed at the time \\(t_S+\\Delta_A+\\Delta_C\\) . In this case, the procedure should be repeated immediately, with new starting time \\(t'_S\\) and finish time \\(t'_F\\) such \\(t'_S =t_S+\\Delta_A+\\Delta_C\\) and \\(t'_F=t_F+\\Delta_A+\\Delta_C\\) .","title":"6.5.3.2 Application message sending - default algorithm"},{"location":"IOTA-NECTAR/6.5%20dRNG/#654-dkg-phase","text":"After a successful committee selection, confirmed at the time \\(t_S+\\Delta_C+\\Delta_A\\) with respect to the node's local clock, the DKG phase starts. In this phase, the committee nodes exchange the Deal messages to produce a public/private collective key. There is no time window for the DKG phase and nodes should proceed with the corresponding DKG message exchange as soon as the committee selection is confirmed (time \\(t_S+\\Delta_C+\\Delta_A\\) ). Only DKG messages with this timestamp are accepted. If any of the committee nodes refuse to create a collective key pair by not exchanging the Deal DKG messages, the DKG phase fails. This can be confirmed at the time $t_F= \\(t_S+2\\Delta_C+\\Delta_A\\) . Moreover, since the message exchange occurs on the Tangle, everybody can identify the nodes that caused the failure. In the case of DKG phase failure, the entire committee selection is repeated (including the application phase). New start and finish time are $t'_S = t_F= \\(t_S+2\\Delta_C+\\Delta_A\\) and \\(t'_F= t_F+2\\Delta_C+\\Delta_A\\) . The malicious node is then excluded from the new committee selection - all application messages issued by a malicious node are ignored. Ban on the committee application is lifted after a successful committee selection i.e., the committee produces its first beacon messages. In other words, if a node failed to produce a DKG message (either due to malfunction or maliciousness) it cannot apply to be in the current committee, however, it can apply in the next committee selection process.","title":"6.5.4 DKG phase"},{"location":"IOTA-NECTAR/6.5%20dRNG/#655-double-seats","text":"We can increase the security of the dRNG beacon by granting double seats to half of the committee members that have the highest committee Mana. Those nodes would receive two private keys (identities) with which they sign beacon messages in the Tangle. From the technical point of view, the two seats are completely separate, and issued Beacon messages can not be combined (even though they were signed by the same node). This modification increases the amount of Mana required to \"overtake\" the committee, which is understood as gaining sigThreshold of seats in the committee. The number of nodes in the committee with double seats equals \\(\\lfloor m/2 \\rfloor\\) (top half of the committee nodes). The total number of identities in the committee equals \\(m + \\lfloor m/2 \\rfloor\\) .","title":"6.5.5 Double seats"},{"location":"IOTA-NECTAR/6.5%20dRNG/#656-publication-of-the-random-number","text":"The committee will collectively generate a random number based on the set of beacon messages that each node will individually produce. A single beacon message is not sufficient to reveal the random number; instead, sigThreshold or more beacon messages are needed for the next random number to be revealed.","title":"6.5.6 Publication of the random number"},{"location":"IOTA-NECTAR/6.5%20dRNG/#6561-collective-beacon-message","text":"To recover the random number from the individual beacon messages, all nodes in the network would need to perform Lagrange interpolation. To avoid that, we propose that the committee nodes produce a collective beacon message , which contains a pre-computed random number (meaning that the committee nodes perform the Lagrange interpolation on their own). Since the committee size is small and the expected throughput of the network is large, we require all committee members to produce this collective beacon message as soon as they receive sigThreshold individual beacon messages. The cost of getting randomness from the collective beacon would be reduced as only (additionally to the default message checks) the signature verification would be required.","title":"6.5.6.1 Collective beacon message"},{"location":"IOTA-NECTAR/6.5%20dRNG/#657-duties-of-the-old-committee","text":"An old committee should only stop producing randomness if another committee was successfully selected and started producing random numbers, which will be confirmed when the first collective beacon message is produced by the new committee and can be read directly from the Tangle.","title":"6.5.7 Duties of the old committee"},{"location":"IOTA-NECTAR/6.5%20dRNG/#658-alternative-drng-and-backup-options","text":"To increase the liveness of the random number production multiple dRNGs may be deployed. Secondary dRNGs can be used if the primary one is not available; it is also possible that users alternate between random numbers from multiple dRNGs. However, this discussion is out of the scope of this specification document.","title":"6.5.8 Alternative dRNG and backup options"},{"location":"IOTA-NECTAR/6.5%20dRNG/#659-pseudocodes","text":"Actions after receiving incoming transaction which is an application message: IF ( NOT IsBlacklisted ( IssuingNode ( tx ))) IF ( Mana ( IssuingNode ( tx ), E - 2 ) > Mana ( My_node , E - 2 )) numberValidApplicationMessagesWithManaHigherThanMine ++ Actions of a node interested in committee participation: IF ( thisNodeWantsToParticipateInDRNG ) WaitUntil ( tS ) ell = GetManaRank ( myNode , Epoch - 2 ) ApplicationMessageSend ( ell ) FUNCTION ApplicationMessageSend ( ell ) IF ( ell <= 2 m ) SendApplicationMessage () ELSE WaitUntil ( T_S - applicationWindow *[ 1 - ( floor ( ell / m ) - 2 ) / ( floor ( ell / m ) - 1 ) ] ) IF ( numberValidApplicationMessagesWithManaHigherThanMine < m ) SendApplicationMessage ()","title":"6.5.9 Pseudocodes"},{"location":"IOTA-NECTAR/6.5%20dRNG/#6510-payload-layout","text":"DRNG payload layout is discussed in Section 2.3 - Standard Payloads Layout .","title":"6.5.10 Payload layout"},{"location":"JTBD/barriers/","text":"Five Barriers To A Predictable Innovation Process \u00b6 Article by Tony Ulwick (Mar 6, 2018) The innovation process has been transformed from an art to a science, yet companies are slow to adopt new thinking. These five barriers may be standing in your way of predictable growth. Any company can master innovation and create products and services that will consistently and predictably win in the marketplace. The process for doing so has been around for decades. Despite this reality, most companies complain of 70-plus percent innovation failure rates. Ironically, as CEO's rank innovation a top priority, and their companies struggle to achieve predictable innovation, they fail to address the obvious problem. The secret to success is really no secret at all. Innovation must be treated like any other business process. If a company wants to excel at lead generation, for example, it must invest in an effective lead generation process. If it wants to excel at customer service, it must invest in an effective customer service process. Innovation is no different. If a company wants to excel at innovation, then it must invest in and follow an effective innovation process \u2014 and this is where companies fall short. We have worked with Fortune 500 companies and other organizations over the past 26 years deploying Outcome-Driven Innovation (ODI), a proven innovation process with an 86 percent success rate. Along the way, we have observed a number of barriers that stand in the way of companies mastering innovation. While innovation champions exist in nearly every company, they encounter organizational antibodies that kill new thinking. From my perspective, there are 5 major barriers companies must overcome before replacing luck with predictable innovation. Across an organization, key managers and stakeholders must: Recognize that innovation is a process. Stop executing the innovation process backwards. Stop cobbling together incompatible innovation tools and methods. Budget the time and money needed to execute the process correctly. Recognize that new market research methods are required. Let\u2019s look at each barrier in more detail. Recognize That Innovation Is A Process \u00b6 Innovation is not a random flash of brilliance. It is not dependent on luck. It is a business process that can be measured and controlled just like any other business process. The problem we often encounter is that many people, including top managers and executives in leading companies, disagree with this thinking \u2014 they honestly believe innovation is an art. Worse yet, they believe that applying process to this art actually stifles innovation. Tldr With an aversion to process and a strong belief that innovation is an art, there is little hope a company will ever consider adopting an effective innovation process. Helping company employees overcome this outdated thinking is not easy, but it can be accomplished through education and exposure to methods and processes such as ODI and Jobs-to-be-Done . If this barrier is not overcome, a company can do little to pursue the goal of predictable innovation. Stop Executing The Innovation Process Backwards \u00b6 Innovation is the process of devising solutions that address unmet customer needs. At a high level, there are only two inputs into this process: solutions and unmet customer needs. Consequently, there are 2 competing approaches to executing the innovation process: Ideas-first approach \u2014 brainstorm lots of ideas and filter them and test them to see which are most attractive to customers. Needs-first approach \u2014 determine the customer\u2019s unmet needs in each segment of the market and then devise solutions that will address them. Many companies employ the ideas-first approach to innovation \u2014 and this is holding them back from achieving predictable innovation. Tldr Companies rely on luck to create winning products when they employ the ideas-first approach to innovation. The chance of randomly devising a solution that addresses the customer\u2019s unmet needs \u2014 when the needs are unknown \u2014 is near zero. The problem with the ideas-first approach is obvious \u2014 a company is highly unlikely to hit a target if it doesn\u2019t know what the target is. While companies often invest in systems and tools that help them generate, store and filter ideas, these investments alone will not contribute to predictable innovation. Companies must recognize that because innovation is the process of devising solutions that address unmet customer needs, the process must begin with a quantified insight into the customer\u2019s unmet needs \u2014 not brainstorming ideas. Stop Cobbling Together Incompatible Tools And Methods \u00b6 Companies invest in many different tools and methods in an effort to achieve predictable innovation. They include design thinking, conjoint analysis, Voice-of-the-Customer, brainstorming, open innovation, collaboration, QFD, lean startup, agile, discovery-driven planning and dozens of others. Tldr The problem with this tool set is that (1) each tool only gets part of the innovation \u201cjob\u201d done, and (2) the tools were not designed to work together to achieve predictable innovation \u2014 so it\u2019s not surprising that they don\u2019t. To excel at innovation, a company must be able to: Uncover all the customer\u2019s needs. Determine which are under/over-served and appropriately-served. Determine if segments of customers exist with their own unique set of under/over/appropriately-served needs. Select which segments and needs to target. Devise solutions that address the targeted segments/needs. The Outcome-Driven Innovation process was designed from the ground up to help companies execute the innovation process in this order. The outputs from one step are the perfect inputs into the next step \u2014 by design. The result is a comprehensive and effective end-to-end innovation process. Cobbling together incompatible parts in an attempt to optimize system performance fails the test of solid systems thinking. Yet this is exactly what many companies are trying to do as they construct their innovation process. Budget The Time And Money Needed To Execute The Process Correctly \u00b6 When I entered the innovation field years ago, it was common to hear people complain that \u201ccompanies can\u2019t afford to get it right the first time, yet somehow, they can afford to go back and fix it over and over again.\u201d Unfortunately, when it comes to innovation, this thinking is still pervasive \u2014 in fact there is now a trendy name for it \u2014 \u201cfailing fast\u201d. While companies budget millions for product development, many fail to budget for an effective product planning effort. In fact, all too often we find that innovation, planning, marketing, and product teams have little or no budget available for product planning. This sets them up for failure. Tldr To succeed at innovation, a product team must know, with precision, just what customer segments and unmet needs to target. This is the essence of strategy. If a company is unwilling to invest the time and money up front to ensure the right strategy is pursued, it should expect a low innovation success rate. Failing fast is not a viable strategy. Instead, companies should \u201clearn fast\u201d and get it right the first time. As Steve Jobs said, \u201cWe had a fundamental belief that doing it right the first time was going to be easier than having to go back and fix it. And I cannot say strongly enough that the repercussions of that attitude are staggering. I\u2019ve seen them again and again throughout my business life.\u201d Recognize That New Market Research Methods Are Required \u00b6 Many of the companies we have worked with employ market researchers with years of experience conducting customer interviews and surveys. While this sounds like it should be an advantage, it is often a barrier to success for the following reasons: First , companies wrongly assume that the same market research methods they have been using for years to quantify solution preferences will also work to quantify the customer\u2019s needs, i.e., determine which are under/over-served and to what degree. Unfortunately, while market research methods that employ max diff, forced choice, paired comparison, conjoint, stated/revealed preference and other techniques may be appropriate in quantifying solution preferences, none of them work when applied to quantifying customer needs. Interestingly, this problem is not widely acknowledged as most companies continue to use the wrong tools to quantify customer needs. Second , the methods required to quantify customer needs violate the artificial constraints that researchers have placed upon themselves for decades. For example, the research methods that we use as part of the ODI process require lengthy surveys (often 30 minutes or so) and ask respondents to rate the importance and satisfaction of up to 150 desired outcome (need) statements. Old thinking rejects this type of survey out-of-hand. While such a survey may seem like overkill, it works to quantify the inputs needed to transform innovation into a predictable process. Lastly , company researchers often act as the gatekeepers of customer information to marketing and development teams. As such, they sometimes feel threatened by new research methods being introduced into the organization and work to ensure they are not adopted. In reality, these new methods represent a growth opportunity for researchers who are interested in making innovation more predictable. If a company is able to overcome these 5 barriers, it will dramatically improve its chances of mastering innovation and creating products and services that will consistently and predictably win in the marketplace. Adopting an innovation process (such as Outcome-Driven Innovation) will help a company overcome these barriers and replace luck with a predictable innovation process.","title":"Five barriers to innovation"},{"location":"JTBD/barriers/#five-barriers-to-a-predictable-innovation-process","text":"Article by Tony Ulwick (Mar 6, 2018) The innovation process has been transformed from an art to a science, yet companies are slow to adopt new thinking. These five barriers may be standing in your way of predictable growth. Any company can master innovation and create products and services that will consistently and predictably win in the marketplace. The process for doing so has been around for decades. Despite this reality, most companies complain of 70-plus percent innovation failure rates. Ironically, as CEO's rank innovation a top priority, and their companies struggle to achieve predictable innovation, they fail to address the obvious problem. The secret to success is really no secret at all. Innovation must be treated like any other business process. If a company wants to excel at lead generation, for example, it must invest in an effective lead generation process. If it wants to excel at customer service, it must invest in an effective customer service process. Innovation is no different. If a company wants to excel at innovation, then it must invest in and follow an effective innovation process \u2014 and this is where companies fall short. We have worked with Fortune 500 companies and other organizations over the past 26 years deploying Outcome-Driven Innovation (ODI), a proven innovation process with an 86 percent success rate. Along the way, we have observed a number of barriers that stand in the way of companies mastering innovation. While innovation champions exist in nearly every company, they encounter organizational antibodies that kill new thinking. From my perspective, there are 5 major barriers companies must overcome before replacing luck with predictable innovation. Across an organization, key managers and stakeholders must: Recognize that innovation is a process. Stop executing the innovation process backwards. Stop cobbling together incompatible innovation tools and methods. Budget the time and money needed to execute the process correctly. Recognize that new market research methods are required. Let\u2019s look at each barrier in more detail.","title":"Five Barriers To A Predictable Innovation Process"},{"location":"JTBD/barriers/#recognize-that-innovation-is-a-process","text":"Innovation is not a random flash of brilliance. It is not dependent on luck. It is a business process that can be measured and controlled just like any other business process. The problem we often encounter is that many people, including top managers and executives in leading companies, disagree with this thinking \u2014 they honestly believe innovation is an art. Worse yet, they believe that applying process to this art actually stifles innovation. Tldr With an aversion to process and a strong belief that innovation is an art, there is little hope a company will ever consider adopting an effective innovation process. Helping company employees overcome this outdated thinking is not easy, but it can be accomplished through education and exposure to methods and processes such as ODI and Jobs-to-be-Done . If this barrier is not overcome, a company can do little to pursue the goal of predictable innovation.","title":"Recognize That Innovation Is A Process"},{"location":"JTBD/barriers/#stop-executing-the-innovation-process-backwards","text":"Innovation is the process of devising solutions that address unmet customer needs. At a high level, there are only two inputs into this process: solutions and unmet customer needs. Consequently, there are 2 competing approaches to executing the innovation process: Ideas-first approach \u2014 brainstorm lots of ideas and filter them and test them to see which are most attractive to customers. Needs-first approach \u2014 determine the customer\u2019s unmet needs in each segment of the market and then devise solutions that will address them. Many companies employ the ideas-first approach to innovation \u2014 and this is holding them back from achieving predictable innovation. Tldr Companies rely on luck to create winning products when they employ the ideas-first approach to innovation. The chance of randomly devising a solution that addresses the customer\u2019s unmet needs \u2014 when the needs are unknown \u2014 is near zero. The problem with the ideas-first approach is obvious \u2014 a company is highly unlikely to hit a target if it doesn\u2019t know what the target is. While companies often invest in systems and tools that help them generate, store and filter ideas, these investments alone will not contribute to predictable innovation. Companies must recognize that because innovation is the process of devising solutions that address unmet customer needs, the process must begin with a quantified insight into the customer\u2019s unmet needs \u2014 not brainstorming ideas.","title":"Stop Executing The Innovation Process Backwards"},{"location":"JTBD/barriers/#stop-cobbling-together-incompatible-tools-and-methods","text":"Companies invest in many different tools and methods in an effort to achieve predictable innovation. They include design thinking, conjoint analysis, Voice-of-the-Customer, brainstorming, open innovation, collaboration, QFD, lean startup, agile, discovery-driven planning and dozens of others. Tldr The problem with this tool set is that (1) each tool only gets part of the innovation \u201cjob\u201d done, and (2) the tools were not designed to work together to achieve predictable innovation \u2014 so it\u2019s not surprising that they don\u2019t. To excel at innovation, a company must be able to: Uncover all the customer\u2019s needs. Determine which are under/over-served and appropriately-served. Determine if segments of customers exist with their own unique set of under/over/appropriately-served needs. Select which segments and needs to target. Devise solutions that address the targeted segments/needs. The Outcome-Driven Innovation process was designed from the ground up to help companies execute the innovation process in this order. The outputs from one step are the perfect inputs into the next step \u2014 by design. The result is a comprehensive and effective end-to-end innovation process. Cobbling together incompatible parts in an attempt to optimize system performance fails the test of solid systems thinking. Yet this is exactly what many companies are trying to do as they construct their innovation process.","title":"Stop Cobbling Together Incompatible Tools And Methods"},{"location":"JTBD/barriers/#budget-the-time-and-money-needed-to-execute-the-process-correctly","text":"When I entered the innovation field years ago, it was common to hear people complain that \u201ccompanies can\u2019t afford to get it right the first time, yet somehow, they can afford to go back and fix it over and over again.\u201d Unfortunately, when it comes to innovation, this thinking is still pervasive \u2014 in fact there is now a trendy name for it \u2014 \u201cfailing fast\u201d. While companies budget millions for product development, many fail to budget for an effective product planning effort. In fact, all too often we find that innovation, planning, marketing, and product teams have little or no budget available for product planning. This sets them up for failure. Tldr To succeed at innovation, a product team must know, with precision, just what customer segments and unmet needs to target. This is the essence of strategy. If a company is unwilling to invest the time and money up front to ensure the right strategy is pursued, it should expect a low innovation success rate. Failing fast is not a viable strategy. Instead, companies should \u201clearn fast\u201d and get it right the first time. As Steve Jobs said, \u201cWe had a fundamental belief that doing it right the first time was going to be easier than having to go back and fix it. And I cannot say strongly enough that the repercussions of that attitude are staggering. I\u2019ve seen them again and again throughout my business life.\u201d","title":"Budget The Time And Money Needed To Execute The Process Correctly"},{"location":"JTBD/barriers/#recognize-that-new-market-research-methods-are-required","text":"Many of the companies we have worked with employ market researchers with years of experience conducting customer interviews and surveys. While this sounds like it should be an advantage, it is often a barrier to success for the following reasons: First , companies wrongly assume that the same market research methods they have been using for years to quantify solution preferences will also work to quantify the customer\u2019s needs, i.e., determine which are under/over-served and to what degree. Unfortunately, while market research methods that employ max diff, forced choice, paired comparison, conjoint, stated/revealed preference and other techniques may be appropriate in quantifying solution preferences, none of them work when applied to quantifying customer needs. Interestingly, this problem is not widely acknowledged as most companies continue to use the wrong tools to quantify customer needs. Second , the methods required to quantify customer needs violate the artificial constraints that researchers have placed upon themselves for decades. For example, the research methods that we use as part of the ODI process require lengthy surveys (often 30 minutes or so) and ask respondents to rate the importance and satisfaction of up to 150 desired outcome (need) statements. Old thinking rejects this type of survey out-of-hand. While such a survey may seem like overkill, it works to quantify the inputs needed to transform innovation into a predictable process. Lastly , company researchers often act as the gatekeepers of customer information to marketing and development teams. As such, they sometimes feel threatened by new research methods being introduced into the organization and work to ensure they are not adopted. In reality, these new methods represent a growth opportunity for researchers who are interested in making innovation more predictable. If a company is able to overcome these 5 barriers, it will dramatically improve its chances of mastering innovation and creating products and services that will consistently and predictably win in the marketplace. Adopting an innovation process (such as Outcome-Driven Innovation) will help a company overcome these barriers and replace luck with a predictable innovation process.","title":"Recognize That New Market Research Methods Are Required"},{"location":"JTBD/brainstorming/","text":"Outcome-Driven Ideation: Brainstorming With The End In Mind Rather than generating hundreds of questionable ideas, devise solutions that explicitly address your customer\u2019s most underserved needs. Tony Ulwick Tony Ulwick Follow Jan 31, 2020 \u00b7 8 min read Ideation is the creative process of generating, developing, and communicating new ideas for products and services; it is the idea generation phase of the innovation process. Many methods and tools exist that can aid in the ideation process, including brainstorming, mind-mapping, lateral thinking, SCAMPER, TRIZ and others. Historically, companies employ ideation methods that disappoint along two fronts. First, managers are often paralyzed by the number of ideas that are generated, as they lack the ability to adequately evaluate and prioritize them. Consequently, they are inundated with hundreds of ideas and have no way to effectively determine which are best. Second, only 17% of new product ideas that are pursued ever succeed in the marketplace, making ideation a highly-inefficient, broken business processes. Outcome-Driven Ideation Overview Strategyn\u2019s Outcome-Driven Innovation\u00ae (ODI) process incorporates its own unique approach to ideation. The ideation process has evolved through hundreds of sessions we have facilitated to help product teams conceptualize breakthrough product and service offerings. The process, which we call Outcome-Driven Ideation\u2122, consistently delivers exceptional results \u2014 and it\u2019s not by chance. The process was designed from the ground up to be outcome-driven \u2014 focused on the outcomes customers and stakeholders are trying to achieve. It results in the conceptualization of feature sets, platform concepts and business models that are certain to deliver significant customer and stakeholder value. Moreover, the approach overcomes the key issues that plague traditional ideation methods. A single day of ideation typically produces market winning, and often patentable, product concepts. In addition, it enables companies to get them to market quickly, as it eliminates much of the second guessing that typically occurs throughout the development process. Outcome-Driven Ideation sessions incorporate many fine-tuned process improvements that collectively lead to exceptional results. They relate to the inputs incorporated into the ideation process, and the manner in which the team uses them. Below are the top 7 unique ideation session characteristics: The session is focused on devising solutions that address specific, unmet customer needs. Rather than asking the ideation team to generate general ideas to help grow the business or to improve a product or service, the team is asked to focus on devising solutions that address a specific set of unmet customer needs. Your team knows that the targeted customer needs are underserved BEFORE the ideation session begins. Using ODI-based qualitative and quantitative research methods, you determine which customer needs (often 100+) are unmet, then quantify the degree to which each is underserved in advance of the ideation session. Therefore, your ideation team focuses only on known opportunities for value creation \u2014 the customer\u2019s most underserved needs. With this heightened focus, your team is more confident that the solutions it generates will be highly valued by customers. In contrast to other methods, irreplaceable time is not wasted brainstorming ideas that are of questionable value. The customer need statements, written in the form of desired outcomes, act as the perfect instruction for concept creation. A desired outcome statement is a specially constructed need statement that is devoid of solutions, stable over time, measurable, controllable, structured for reliable prioritization in a quantitative customer survey, and tied to the underlying \u201cjob\u201d the customer is trying to get done. See Inventing the Perfect Customer Need Statement for more details. A desired outcome statement purposefully communicates what the customer is trying to accomplish and guides the creation of the solution. The statements are also designed for easy translation into product requirements, making them highly actionable and valuable to development teams that operate in a waterfall or agile environment. The use of desired outcome statements is unique to the Outcome-Driven Innovation process. A desired outcome statement also acts as a solid baseline for on-the-spot concept testing. A desired outcome statement includes a metric that is used as a baseline to help you evaluate the potential of a proposed solution during the ideation session. Consequently, the ideation team evaluates each proposed solution against the metric to assess the degree to which it will satisfy the outcome. The solution that generates the greatest level of satisfaction for the least cost, effort and risk is generally selected for pursuit. This streamlines the concept evaluation and testing process. The goal of a session is NOT to generate lots of ideas. Instead, the goal is to build team consensus around one solution that will effectively address each specific underserved need targeted in the ideation session. Rather than generating numerous ideas and hoping some are valuable to customers, your team will devise a solution for each targeted outcome that is certain to create significant customer value. Your team does not mix feature-level ideation with product platform or business model ideation. The reason is simple: generating a mix of ideas that cannot be considered and evaluated against each other is a recipe for confusion and failure. Consequently, if the goal of an ideation session is to generate ideas for a new feature set on an existing platform, two sequential steps will fllow: first, everyone is instructed as to what platform is assumed. Next, they are given directions on how to generate feature ideas that can be implemented on that platform. Sessions for product platform and business model ideation are conducted separately and in a specified order (platform, business model, then feature). The process incorporates a custom set of creativity triggers. We have translated the creativity principles of several popular methods, along with all the TRIZ principles, into 3 sets of actionable creativity triggers. They are specifically designed to help product teams devise (i) new product and service platforms, (ii) new business models, and (iii) new product and service features. These triggers are based on proven principles that have been previously implemented to generate patentable ideas. The set of triggers is unique to the Outcome-Driven Ideation process. NOTES: See the article 81 Creativity Triggers To Energize Your Ideation Process to learn more and go to Strategyn\u2019s Resource Center to obtain the creativity infographics (free) for use in your next ideation session. This collective set of process improvements flips traditional brainstorming on its head: instead of brainstorming hundreds of ideas and hoping some of them will deliver customer value, your team focuses on devising superior solutions that are primed to deliver significant customer value \u2014 because they are solutions that address known and quantified unmet customer desired outcomes. Outcome-Driven Ideation Methods In Practice Although it may be counterintuitive, giving the ideation process a structure enhances creativity because it channels and focuses creative energy exactly where it needs to be. Instead of playing gimmicky games designed to generate hundreds of questionable ideas, this approach results in the creation of breakthrough ideas that your organization can pursue with confidence. We facilitate 3 types of ideation sessions, each with a specific purpose in mind. They are customized to help your team conceptualize: A new product platform. This approach is used when conceptualizing altogether new product offerings and is focused at the system and sub-system level. A new business model. This includes ways to generate revenue, reduce costs and optimize profits. A feature set for a defined product platform. This is the preferred approach when seeking ways to enhance a product offering on a specified platform. The research conducted as part of an Outcome-Driven Innovation project reveals what under/over-served segments represent opportunities for new platforms and business models and what underserved outcomes represent opportunities for a new feature set. Each type of session follows a precise structure. For example, when facilitating an ideation session that is designed to conceptualize a new feature set for a defined product platform, we follow the process depicted below: Outcome-Driven Ideation (for feature ideation) Devising a Feature Set for a Defined Platform In a typical feature set ideation session, which may last a day or more, it is common for a team to devise a solution for 10 to 15 underserved outcomes. Each outcome is addressed in an ideation block that typically lasts 60 to 90 minutes. Follow the same process for each ideation block: Agree on the product platform that will be assumed as part of the solution. In many software companies, there is only one platform. In hardware companies it is common to have multiple platforms in the portfolio. It is also possible to execute feature ideation assuming multiple platforms. Introduce the team to the outcome statement that is the focal point for ideation \u2014 a single, quantified underserved customer desired outcome. Again, only one outcome statement per ideation block. Discuss the root cause of customer dissatisfaction \u2014 and why current solutions fail to address the desired outcome. Assess whether or not solutions offered by competitors or solutions used in other industries successfully address the desired outcome. Assess whether or not solutions in your product pipeline or in R&D successfully address the desired outcome. Determine what creativity triggers, if any, to use as part of the process. Triggers are usually selected from multiple solution pathways, of which there are 8 in total. These pathways represent mutually exclusive approaches to addressing an unmet need. Again, see 81 Creativity Triggers To Energize Your Ideation Process. Instruct the team to construct 3 or 4 alternative concepts and to evaluate them on their ability to increase the level of customer satisfaction. Work as a team to devise the best possible solution \u2014 generally defined as the one that will satisfy the outcome to the greatest degree for the least product cost, development effort and technical risk. If the team devises a solution that satisfies an outcome, but at a significant cost, they are instructed to brainstorm ways to reduce the cost, and so on. Document the feature in detail as a team, ensuring it clearly states what to implement to satisfy the unmet need. Include sketches, graphics, images or diagrams as needed. This becomes the input into the product requirements document or epic, etc. When the ideation session is focused on conceptualizing a new product platform or a new business model, a slightly different process is followed. Briefly, when the goal is to devise a new product platform, the ideation effort is focused on devising a solution that will enable the execution of the entire job on a single platform. In this case, ideation is often conducted at the job step level, not at an outcome level. When the goal is to devise a new business model, the team must have already agreed on the platform level solution. From there the focus is on defining how revenue will be generated and costs will be contained to ensure the solution could be delivered and scaled profitably.","title":"Brainstorming"},{"location":"JTBD/canvas/","text":"The Jobs-to-be-Done Canvas Helping a product team see a market through a Jobs-to-be-Done lens is often a transformational experience. This training canvas can help drive that transformation \u2014 and company growth. Tony Ulwick Tony Ulwick Follow May 8, 2018 \u00b7 7 min read The Jobs-To-Be-Done Canvas Introduction I am sharing the Jobs-To-Be-Done Canvas (links below) with the JTBD Community in an effort to encourage and help product, marketing and strategy teams: Learn the fundamentals of Jobs-to-be-Done Theory and the Outcome-Driven Innovation process. Establish a common language for innovation, thus facilitating agreement on critical process inputs. See their markets through a new lens \u2014 one that aligns them more closely with customers and results in a more predictable approach to innovation. Discover possible opportunities for growth, i.e., where current offerings fail to address a job step, outcomes or related or consumption jobs. My hope is that innovation champions in companies around the world will use the Jobs-To-Be-Done Canvas to accelerate the adoption of new thinking \u2014 and accelerate their growth. Download The Jobs-To-Be-Done Canvas The canvas can be downloaded in multiple formats. You will not be required to enter any data \u2014 the links go directly to the canvas. The latest version is v-1.2. Download the Jobs-To-Be-Done Canvas in .pdf format. Download the Jobs-To-Be-Done Canvas in .png format. A special thanks to Mike Boysen for his contributions to creating the canvas. Please post suggested improvements to the canvas as a response to this article. Supporting Materials And Preparation It is recommened that the canvas be used in a workshop or training setting that is facilitated by an internal innovation champion. In preparation for the workshop, participants should be asked to read (at a minimum) The Customer-Centered Innovation Map (HBR, 2008) in advance. Other short articles that will prepare participants include the following: Turn Customer Input into Innovation (HBR, 2002) Giving Customers a Fair Hearing (MIT Sloan, 2008) If you want workshop participants to be fully educated on the approach before the workshop begins, ask them to download and read a free copy of the book JOBS TO BE DONE: Theory to Practice (Ulwick, 2016) in advance of the session. Workshop facilitators should be well versed in all the content listed above and supplement their learning by reading the white papers located on the Strategyn web site and the articles posted on the JTBD + ODI web site. The use of a canvas in a workshop setting has been made popular by Alexander Osterwalder and others. The canvas culture originated as part of The Toyota Way, where they developed what they called an \u201cA3 Report\u201d \u2014 a one-page report that got its name from the size of the paper. At first glance, A3\u2019s look very simple. But, there is a process behind them. Like the A3 Report, the Jobs-To-Be-Done Canvas is intended as a starting point to develop a hypotheses about a market of interest that can later be refined and validated through a more rigorous execution of the ODI process. Jobs-To-Be-Done Canvas Instructions While the canvas can be used to analyze markets in which products do not yet exist, it is often more pragmatic for an innovation champion to help a product team learn the approach by focusing on a market they are familiar with, e.g., a market they are already in. This ensures the workshop will deliver actionable results that can be implemented quickly, thus building excitement around the process. Using the Jobs-to-be-Done Canvas, product team members \u2014 with the guidance of the facilitator \u2014 will work to gain agreement on: What group of customers to target for growth. What job the customer is trying to get done. All the steps that comprise the customer\u2019s job-to-be-done. Associated consumption, related and emotional jobs. The customer\u2019s desired outcomes (needs) associated with getting the core and consumption jobs done. The canvas is designed to tease out these inputs, all of which are required to make the innovation process more predictable. The training exercise can typically be completed in \u00bd-day workshop. The canvas should be completed in this order, as follows: Job Executor Begin by defining the group of people you want to target for value creation \u2014 those who use your products (and competing products) to get a common functional job done. The job executor is typically the end user \u2014 the person who uses the product or service to get the job done. The job executor does not have to be, and is often not, the buyer. Others involved in the product life cycle, e.g., installers, those who maintain or repair the product, etc., are considered when analyzing the consumption chain jobs. Core Functional Job-to-be-Done Next, define the common underlying process (job) the job executors are trying to get done. A well crafted job statement describes precisely what your targeted group of people are trying to accomplish or achieve. Make sure the job statement is in the proper format: verb + object of the verb + contextual clarifier (optional) Avoid the use of adjectives and adverbs. Do not include emotional jobs or need statements in the core job statement. You may choose to have customers in the training workshop with you to help you define their job. This brings an added dimension of realism to the session. Job Map A job map is a visual depiction of the core functional job, deconstructed into its discreet process steps. Unlike a process map, a job map does not show what the customer is doing (a solution view); rather, it describes what the customer is trying to get done (a needs view). For each stage in the job map, determine the process steps that the customer is trying to execute in order to get the job done. There are often a number of process steps for each stage in the Universal Job Map (which is embedded in the canvas). For example, there may be two or more execution steps or monitoring steps, etc. Define each step in the job map in a way that makes it solution agnostic. Define each step using the proper format: verb + object of the verb + contextual clarifier (optional) Place the steps in the optimal order: one that would eliminate process iterations that waste time and money. Enabling customers to execute the job in the optimal order is often an innovation in and of itself. You can read more about Job Mapping here. Consumption Jobs Consumption chain jobs are the product-related jobs that must get done throughout the product lifecycle. These jobs include installation, set up, and storing, transporting, maintaining, repairing, cleaning, upgrading, and disposing of the product. Some consumption chain jobs may be executed by the core functional job executor. Other consumption jobs may be executed by somebody else, e.g., an installer, etc. Identify all the consumption chain jobs that either the job executor or others must execute throughout the product lifecycle. Check off who it is that must execute the consumption chain job, i.e., the job executor or somebody else (other). In an existing market, the consumption chain jobs are often a given. But one goal of innovation is to create solutions that eliminate or automate the execution of the consumption chain jobs \u2014 thus offering a point of differentiation. Related Jobs List the functional jobs the end user is trying to get done in conjunction with the core functional job. They include jobs they might execute before, during or after the execution of the core job. (See Grow Past The Core: Target Related Jobs-to-be-Done). Emotional Jobs Create a set of statements that describe the way customers want to be perceived by others or feel when executing a core functional job. Again, follow the rules for creating valid emotional job statements as defined in the literature. Desired Outcomes Desired outcomes are the metrics that job executors use to measure the successful execution of the core functional job. Outcomes can be over, under or appropriately served, or table stakes or irrelevant. Define outcomes for several of the steps in the job map. It\u2019s often best (and easiest) to start with the \u201cexecution\u201d steps. Follow the rules for stating good outcome statements per the latest book listed above. Use the required format: direction of improvement + metric + object of control + contextual clarifier (optional). As outcomes are defined, discuss with the team whether they are likely to be under, over or appropriately served, or table stakes or irrelevent (and why). Turn Insights Into Action With the insights posted on the Jobs-To-Be-Done Canvas, the facilitator can lead the team through a variety of discussions, including: How to better position existing products. How to improve existing products at the job, job step and outcome level (see details below on how to use the job map to uncover opportunities for innovation). What new products or complementary services are required to help customers get the entire job done. Additional instructions for using the insights are detailed in the Harvard Business Review article, The Customer-Centered Innovation Map.","title":"Canvas"},{"location":"JTBD/customer/","text":"Customer Needs Through a Jobs-to-be-Done Lens Customer needs become discoverable and actionable when you define them around the job the customer is trying to get done. Tony Ulwick Tony Ulwick Follow Apr 25, 2017 \u00b7 6 min read Innovation appears to be a random, inherently unpredictable process. But what if we could understand the causal factors that contribute variability to the innovation process and learn how to control them? Would that bring predictability to innovation? The answer is yes \u2014 we have proven it can be done, but it requires new thinking. Innovation is the process of devising product/service solutions that address unmet customer needs. There are 2 key inputs into the innovation process: (1) solutions: ideas for new products or product features that use new or existing technology in a new, unique or novel way, and (2) customer needs. It is rare that we see companies struggle to generate ideas \u2014 in fact the opposite is usually true \u2014 they often have more ideas than they know what to do with. The reality is companies struggle with innovation because those responsible for conceptualizing, developing and evaluating ideas for new product/service offerings struggle with the \u201cneeds\u201d side of the equation. Our experience has led us to conclude that companies struggle with 5 key issues related to understanding and processing customer needs. These factors contribute significant variability to the innovation process. In nearly all our consulting engagements, we find that the members of the product team: 1. Do not agree on what a \u201cneed\u201d is or what types of customer needs exist. 2. Do not agree on how a \u201cneed\u201d statement should be constructed to effectively inform the innovation process. 3. Do not know what all the customer\u2019s needs are. 4. Do not know which customer needs are unmet and to what degree. 5. Do not know if segments of customers exist with different sets of unmet needs. Clearly, if these issues cannot be resolved, the chance of devising a solution that effectively addresses the customer\u2019s unmet needs is highly unlikely \u2014 thus making the innovation process appear random. But it doesn\u2019t have to be that way. These issues can be resolved using the research methods we have devised as part of our innovation process, Outcome-Driven Innovation. What types of customer needs exist? Customer inputs must be captured that inform the development team what functions the product should perform, how customers want to interact with the product throughout its lifecycle, the emotional benefits they want to receive, and their financial goals and constraints. These types of inputs are detailed in the Jobs-to-be-Done Needs Framework (Figure 1). Jobs-to-be-Done Needs Framework The customer\u2019s desired outcomes related to the core functional job inform product function. The desired outcomes associated with the consumption chain jobs done inform product lifecycle activities. Related jobs explore additional function that may be desired, while emotional jobs detail the desired emotional benefits. Lastly, the financial outcomes detail the customer\u2019s financial goals and constraints. Each need type is defined in more detail in the book JOBS TO BE DONE: Theory to Practice. 2. How should a \u201cneed\u201d statement be constructed? A need statement must unfortunately be stated in words. Therefore those words must be organized in a sentence that communicates how the customer measures success and value when getting a \u201cjob\u201d done. That same set of words must provide actionable input to the development team \u2014 in other words, it must inform the product function and design. The ideal \u201cneed\u201d statement should also be stable over time and devoid of solutions \u2014 this means they must be associated with the job-to-be-done, not the product. For these reasons, we structure a need statement as follows: Verb (minimize) + metric + object of control + contextual clarifier. For example, \u201cminimize the time it takes to get the songs in the desired order for listening\u201d is a desired outcome associated with the core job of listening to music. For all the details on structuring need statements go to Giving Customers A Fair Hearing (MIT Sloan article). 3. How do you collect all the customer\u2019s needs? Need collection begins with the creation of a job map. A job map breaks down the customer\u2019s core functional job-to-be-done into discrete steps, detailing what the customer is trying to accomplish \u2014 independent of solution. The job map is created through customer interviews and refined throughout the qualitative research process. Additional details on job mapping can be found in the HBR article, The Customer-Centered Innovation Map. The job map bounds the need-gathering process. With a job map in hand the next step is to capture/create a complete set of desired outcome statements related to the core functional job. It is often the case that 5 to 10 outcomes are captured for each job step, and 100 or more desired outcomes statements are collected in total on the core job alone. Other statements (outcomes on consumption chain jobs, and also related and emotional jobs) add to the total. A complete set of outcome statements for the core job will detail (in chronological order) exactly how customers measure success as they go about getting the job done step-by-step, from beginning to end. Outcome statements can be captured through customer interviews and ethnographic research, but they can also be extracted from literature, books or papers written on the subject. 4. How do you determine which needs are unmet? A need is unmet when it is important to customers, but not satisfied with the products/services (or ad hoc solutions) they are using today. Knowing which of the 100 or more desired outcomes are most important and least satisfied pinpoints the opportunities for value creation. Statistically valid quantitative research is required to determine which outcomes are underserved. First we create a survey that includes the 100 or more desired outcome statements. Then we survey anywhere from 120 to 1200 customers (depending on a variety of factors), asking them to tell us the importance of each outcome and their current level of satisfaction. With these inputs we can determine which needs are most underserved (and overserved). See the HBR article Turn Customer Input into Innovation for more details. 5. How do you discover segments of customers with different unmet needs? To discover segments of customers with different unmet needs you must segment the market using unmet needs (desired outcomes) as the bases for segmentation \u2014 not demographic, psychographic or other classification schemes. Companies rarely segment their markets in this manner because they cannot agree on what a need is, what the needs are and which are unmet. This is why so many innovation efforts fail. In nearly every market we\u2019ve analyzed over the past 25 years we discovered segments of customers with different unmet needs. This means that most markets are not homogeneous \u2014 and that a one-size-fits-all solution will rarely win in the marketplace. Outcome-based segmentation is critical to success. We segment markets using the data collected in the quantitative survey. We first run factor analysis to discover which outcomes customers rate differently, and then run cluster analysis to place the customers into a predetermined number of segments. We then profile the segments to determine what unique complexities they face that cause them to have different sets of unmet outcomes. Learn more about our approach to segmentation in this white paper. Once a product team knows precisely what unmet needs exist in an attractive, underserved segment of the market, it can apply its creativity to create a product that will deliver significant value to the customer. With the causal factors under control and a well-defined target in its sights, a product team is more likely to create a winning product. This is how you bring predictability to innovation.","title":"Customer"},{"location":"JTBD/framework/","text":"Jobs Theory provides a framework for categorizing, defining, capturing and organizing the inputs that are required to make innovation predictable. Tony Ulwick Tony Ulwick Follow Jan 6, 2017 \u00b7 7 min read Imagine if all the developers, marketers, strategists and R&D managers in your company shared a common understanding of what a need is and which customer needs are unmet. Such alignment and focus changes everything. So how can this be achieved? Harvard Business School marketing professor Theodore Levitt said, \u201cPeople don\u2019t want to buy a quarter-inch drill. They want a quarter-inch hole!\u201d Clayton Christensen says, \u201cPeople buy products and services to get a job done\u201d. These are the basic constructs of Jobs-to-be-Done Theory, but these constructs are only the tip of the iceberg. The theory has a game-changing implication: Jobs-to-be-Done Theory provides a framework for defining, categorizing, capturing, and organizing all your customers\u2019 needs. Moreover, when using this framework, a complete set of need statements can be captured in days \u2014 rather than months \u2014 and the statements themselves are valid for years \u2014 rather than quickly becoming obsolete. Needless to say, if you are not using Jobs Theory as the foundation for a needs framework, you are arguably missing out on the biggest benefit of the theory\u2019s application. Historically, the primary cause of failed products and services is a misalignment with customer needs. This is not surprising given that 95% of product teams do not agree on what a customer \u201cneed\u201d even is. Using this needs framework, product teams can deeply understand the jobs its customers are trying to get done and the metrics they use to measure success. Armed with knowledge of all the customers\u2019 needs, a product team can: Determine which needs are unmet Discover segments of customers with unique sets of unmet needs Systematically conceptualize breakthrough products Predict which new concepts and offerings will win in the marketplace Align the actions of marketing, development, and R&D to orchestrate the systematic creation of customer value The Jobs-to-be-Done Needs Framework, described in detail below, reveals the 3 types of external customers that companies serve, the 5 types of jobs they are trying to get done, and what types of inputs are required to bring predictability to the innovation process. These are the key inputs into the Outcome-Driven Innovation process. Who are your customers? Before a company can define all its customers\u2019 needs, it must first define all its customers. While a B2C company may find this to be a simple exercise, many B2B companies struggle. Through our consulting work we have conducted exhaustive research; we have concluded that the types of customers a company serves are best grouped into three categories: The job executor: this is the person using the product to get the core functional job done. The product lifecycle support team: this consists of the varying groups of people who support the product throughout its lifecycle. This includes people who install, transport, repair, maintain, upgrade or dispose of the product. They execute consumption chain jobs. The buyer: this is the person responsible for making the financial purchase decision. A toothbrush manufacturer will discover that the consumer typically plays all three roles; the consumer is the product user, the supporter of the product throughout its lifecycle, and the buyer. This situation is common in B2C markets. Conversely, if your company manufactures surgical medical instruments, then the surgeon is the job executor. The product lifecycle support team may consist of nurses, bio-meds and others and the buyer is typically a buying group in hospital administration. This type of complexity is common in B2B companies. While many possibilities exist, the customer types fall nicely into these 3 categories, as can be seen in Figure 1. They form the basis for the Jobs-to-be-Done Needs Framework. This categorization is meaningful as each customer type has a different set of needs. Figure 1: Customer types What types of jobs are they getting done? The Jobs-to-be-Done Needs Framework reveals the 5 types of jobs that the job executor, the product lifecycle support team and the buyer are trying to get done. The job executor is trying to get 3 distinct jobs done: The core functional job: This is defined as the underlying process the job executor is trying to get done in a given situation. It is the focal point around which a market is defined and the reason a market exists. \u201cRepairing a rotator cuff,\u201d \u201cpassing on life lessons to children,\u201d and \u201cprotecting against a cyber attack\u201d are all examples of core functional jobs-to-be-done. The goal of any product is to help get a core functional job done better and more cheaply than competing solutions. Related jobs: These are additional functional jobs the job executor is trying to get done either before, during or following the execution of the core job. With an understanding of these related jobs, and which, if any, are underserved, a company can devise solutions that help its customers get multiple jobs done, making its product more valuable. Emotional jobs: These are statements that describe the way the job executor wants to be perceived or feel when executing the core functional job. Social jobs are included in this categorization. These inputs are valuable when it comes to creating a value proposition that incorporates both functional and emotional components, which strongly connect with customers. Consumption chain jobs: The product lifecycle support team is trying to execute a number of jobs throughout the product lifecycle. These jobs include product installation, set up, and storing, transporting, maintaining, repairing, cleaning, upgrading, and disposing of the product \u2014 all impacting the customer experience. These consumption chain jobs are shown in black in Figure 2. The types of consumption chain jobs that must be considered in a market vary depending on the type of offering under consideration; we have created separate frameworks for hardware, software, service and consumable offerings. The purchase decision job: This is the job that the purchase decision maker executes using a financial lens to try to decide which product or service to acquire. Here we want to know what financial and/or performance metrics are used to make the purchase decision. These metrics are what we call financial desired outcomes. Figure 2: Job types The customer\u2019s desired outcomes The power of Jobs Theory is that the customer\u2019s job-to-be-done is the anchor point for \u201cwhere\u201d to create value. That anchor point, while useful, does not contain enough information to indicate \u201chow\u201d to be successful in a market. For example, knowing that people struggle to \u201cmanage their monthly spending,\u201d does not inform us precisely where in the job they are struggling. To gain a deep understanding of the customer\u2019s job-to-be-done, a company must be able to discover the customer\u2019s \u201cneeds\u201d associated with getting that job done. When looking at a market through a jobs-to-be-done lens, customer needs can be discovered by studying the customer\u2019s core functional job as a process. Tactically, the core functional job can be broken down into steps using what we call a job map as described in the 2008 Harvard Business Review article, The Customer-Centered Innovation Map. With the job map in place, companies can then seek to discover the metrics customers use to measure success as they try to get each step in the job done. These metrics, which we call \u201cdesired outcomes,\u201d bring predictability to innovation. A desired outcome statement is a specially constructed need statement that has a unique set of characteristics: desired outcomes are devoid of solutions, stable over time, measureable, controllable, structured for reliable prioritization in a quantitative customer survey, and are tied to the underlying process (or job) the customer is trying to get done. There are typically 50\u2013150 outcomes that people use to measure the success of a core functional job and 10\u201330 outcomes per relevant consumption chain job. These are the ingredients that come together to bring predictability to innovation. How all the pieces fit together can be seen in the complete Jobs-to-be-Done Needs Framework, shown in Figure 3. Figure 3: The Jobs-to-be-Done Needs Framework What are the implications? The Jobs-to-be-Done Needs Framework is a structured guide for navigating the complexity involved in understanding all the needs in a market. Given the avalanche of customer data that companies consider each day, this framework reveals what inputs are needed, how they should be categorized and organized, why they are captured, and how they should be utilized. Without these essential insights, innovation remains a game of chance and product teams end up guessing on the best path forward. Having the right inputs changes everything. It revolutionizes the way products are conceived, tested, created, marketed and sold. The Jobs-to-be-Done Needs Framework brings order to a historically unstructured, chaotic practice.","title":"Framework"},{"location":"JTBD/jtbd/","text":"What is Jobs-to-be-Done? \u00b6 Article by Tony Ulwick (Mar 1, 2017) What is Jobs-to-be-Done Theory? What is a job-to-be-done? A desired outcome? JOBS-TO-BE-DONE is best defined as a perspective \u2014 a lens through which you can observe markets, customers, needs, competitors, and customer segments differently, and by doing so, make innovation far more predictable and profitable. When Einstein engaged in his thought experiments, he pictured himself riding on a beam of light and traveling through the universe. From this perspective he was able to view the universe through a new lens, enabling him to see things in a different and meaningful way and to develop a theory that others could not. Similarly, when you look at marketing and innovation through a Jobs-to-be-Done lens, everything looks different: The unit of analysis is no longer the customer or the product, it\u2019s the core functional \u201cjob\u201d the customer is trying to get done. Markets aren\u2019t defined around products, they are defined as groups of people trying to get a job done. Customers aren\u2019t buyers, they are job executors. Needs aren\u2019t vague, latent and unknowable, they are the metrics customers use to measure success when getting a job done. Competitors aren\u2019t companies that make products like yours, they are any solution being used to get the job done. Customer segments aren\u2019t based on demographics or psychographics, they are based on how customers struggle differently to get a job done. When a company thinks about a market from this perspective, it is much more likely to create and deliver extraordinary products and services. Why? While products come and go, the customer\u2019s job-to-be-done is stable over time. With a focus on a stable unit of analysis, it becomes possible to define customer needs that are stable over time as well, giving companies unique, robust targets for value creation. In short, jobs-to-be-done offers a new framework and lens through which a company can take its understanding of customer needs to the next level \u2014 and bring predictability to innovation. The first documented success achieved by a company applying this thinking was detailed in the 2002 Harvard Business Review article: Turn Customer Input into Innovation. The article describes how in 1993 Cordis Corporation used this thinking to increase its angioplasty balloon market share from 1 percent to over 20 percent. Jobs-to-be-Done is best defined as a perspective \u2014 a lens through which customer needs can be effectively defined and communicated, making marketing more effective and innovation far more predictable. When looking at marketing and innovation through a jobs-to-be-done lens, a theory begins to emerge. Important JOBS-TO-BE-DONE THEORY is comprised of a group of principles or tenets that form a foundation for making marketing more effective and innovation more predictable by focusing on the customer\u2019s job-to-be-done. The theory is based on the notion that people buy products and services to get a \u201cjob\u201d done. Jobs Theory goes on to say that by understanding in detail what that \u201cjob\u201d entails, companies are far more likely to create and market solutions that will win in the marketplace. The core tenets of Jobs-to-be-Done Theory are summarized as follows: People buy products and services to get a \u201cjob\u201d done. Jobs are functional, with emotional and social components. A Job-to-be-Done is stable over time. A Job-to-be-Done is solution agnostic. Success comes from making the \u201cjob\u201d, rather than the product or the customer, the unit of analysis. A deep understanding of the customer\u2019s \u201cjob\u201d makes marketing more effective and innovation far more predictable. People want products and services that wil help them get a job done better and/or more cheaply People seek out products and services that enable them to get the entire job done on a single platform Customer needs, when tied to the job-to-be-done, make innovation predictable In order to study a job-to-be-done, the job must be correctly defined: Definition A JOB-TO-BE-DONE is a statement that describes, with precision, what a group of people are trying to achieve or accomplish in a given situation. A job-to-be-done could be a task that people are trying to accomplish, a goal or objective they are trying to achieve, a problem they are trying to resolve, something they are trying to avoid, or anything else they are trying to accomplish. A job statement is written as [verb] + [object of the verb] + [contextual clarifier] (optionally). For example, pass on life lessons to children, repair a torn rotator cuff and prevent a shooter from entering a school, are all jobs-to-be-done. To gain a deep understanding of the customer\u2019s job-to-be-done, a company must be able to discover the customer\u2019s \u201cneeds\u201d associated with getting that job done. When looking at a market through a jobs-to-be-done lens, customer needs can be discovered by studying the customer\u2019s core functional job as a process. Tactically, the core functional job can be broken down into steps using what we call a job map as described in the 2008 Harvard Business Review article, The Customer-Centered Innovation Map. With the job map in place, companies can then seek to discover the metrics customers use to measure success as they try to get each step in the job done. These metrics are the perfect way to think about and define the customer\u2019s \u201cneeds.\u201d These need statements, which we call \u201cdesired outcomes,\u201d bring predictability to innovation. Definition A DESIRED OUTCOME STATEMENT is a specially constructed need statement that has a unique set of characteristics: desired outcomes are devoid of solutions, stable over time, measureable, controllable, structured for reliable prioritization in a quantitative customer survey, and are tied to the underlying process (or job) the customer is trying to get done. Since the customer\u2019s job-to-be-done is stable over time, the customer\u2019s needs, when defined as desired outcome statements, are also stable over time. With a stable set of \u201cneeds\u201d in hand, a company is able to: Quantify which needs are under-served and over-served. Discover segments of customers with different unmet needs. Use the metrics as a baseline against which they can test product ideas and concepts before they are developed. Knowing which product or service concept will get the job done best early in the product planning stages (prior to development), is the key to predictable and profitable innovation. This case study shows how Bosch applied Jobs Theory to product innovation. This case study shows how Arm & Hammer applied Jobs Theory to marketing innovation. This case study shows how AMO applied Jobs Theory to service innovation. Jobs-to-be-Done Theory is applicable along many fronts \u00b6 To explain how to put Jobs-to-be-Done Theory into practice, let\u2019s start by asking, \u201cWho are the potential users of Jobs-to-be-Done Theory and what are the jobs they are trying to get done?\u201d Four jobs are of particular interest: (1) market selection (deciding what markets to enter), (2) product planning (deciding what products to create), (3) product development (deciding how to best design a product), and (4) buying process (deciding how to improve the customer\u2019s buying process). 1. Market Selection: deciding what markets to enter \u00b6 First, Jobs-to-be-Done Theory is being embraced by entrepreneurs in startups and managers in corporations and corporate venturing units who are trying to discover, evaluate and select markets that are attractive for them to enter/pursue. When looking through a jobs-to-be-done lens, a market is defined as a group of people (job executors) and the job they are trying to get done. As entrepreneurs and managers engage in the market discovery and selection process, they start by trying to discover a number of unique jobs that job executors are struggling to get done. Their goal is to discover and define the jobs at a level of abstraction that makes the job a uniquely attractive target. Once a number of markets are identified, the next step in the market selection process is to determine which is the most attractive to pursue. A job, for example, that is executed by many people, frequently, and is highly under-served would be a more attractive target than one that is executed by fewer people, infrequently and is already appropriately served. Following, we will show market evaluation tool that includes 42 criteria to help make the market selection decision: (see Figure 2) Figure 2: Jobs-to-be-Done Market Evaluation and Selection Template 2. Product Planning: deciding what products to create \u00b6 Second, Jobs-to-be-Done Theory has been embraced by product, marketing and innovation managers in established companies who are trying to grow and expand their core markets. Their goals are to typically (i) create a value proposition that resonates with customers, (ii) improve existing products, and (iii) conceptualize altogether new products that will address core or adjacent market opportunities. These activities, executed by the product planner, comprise the innovation process. To apply Jobs-to-be-Done Theory to assist in marketing and innovation, Strategyn developed Outcome-Driven Innovation\u00ae (ODI). The innovation process originated in 1991 and has been simplified and improved through hundreds of applications within Fortune 500 companies since. The ODI process is comprised of the following 6 steps (Figure 3): Figure 3: The Outcome-Driven Innovation Process While the first step overlaps a step in the market selection process (market discovery and definition) the remaining steps in the process are different and so are the tools required to execute them. Tip To win at innovation a company must know what a customer need is, what the customer\u2019s needs are, which are unmet and if segments of customers exist with unique sets of unmet needs. With the target well defined, creating a winning solution becomes far more likely. ODI reveals the required insights using unconventional qualitative and quantitative market research techniques. The process uniquely employs predictive data and a sophisticated market segmentation methodology that helps companies discover and prioritize hidden market opportunities. 3. Product Development: deciding how to best design a product \u00b6 The third application involves developers and UI and UX designers who are trying to develop products that have been approved for development (their job-to-be-done). These developers may work in lean or agile environments. Their goal is to ensure that the products they create and the code they write not only delivers on the product specifications, but also guarantees a positive user experience. Those trying to apply Jobs-to-be-Done Theory to the product development process typically have the benefit of knowing what product they are trying to create: the product is already conceptualized and defined as part of the innovation process. What developers and UI and UX designers struggle with are design issues and understanding the customer\u2019s needs that relate to what we call consumption chain jobs, such as learning how to use and interfacing with the product (see Figure 4). Figure 4: Consumption Chain Jobs and Outcomes As an extension of the ODI process, our clients apply steps 2 and 3 of the ODI process (outcome gathering and prioritization) to better understand the outcomes of users as they learn how to use, interface with the product and engage in the remaining consumption chain jobs that must be considered in the design phase. We have collected outcomes in all consumption chain jobs multiple times over the years. If a company uses ODI for the innovation process, developers will have the prioritized outcomes associated with the core functional job. These inputs are needed for development/design as well. These insights can then be communicated to developers or UX and UI designers in the following Job/Outcome Story format: (Figure 5) Figure 5: The Job/Outcome Story for Developers/Designers If a developer does not have access to the customer outcomes associated with the core functional job-to-be-done, then they tend to want to execute the innovation process in conjunction with the development process \u2014 learning more about the required product function as they create the product. Combining the development process with the innovation process creates confusion when using and implementing Jobs-to-be-Done Theory. A product concept should be well defined and proven to win in the marketplace before it is approved for development. The ODI process makes this possible. 4. Buying Process: deciding how to improve the customer\u2019s buying process \u00b6 The forth application of the theory involves marketing team members who are trying to understand the process that customer\u2019s go through when buying a product so they can enhance the customer\u2019s buying experience. Confusion over Jobs-to-be-Done theory results from thinking that understanding the customer purchase decision will somehow inform the innovation and development processes as well, but it does not. The purchase \u201cprocess\u201d is an altogether unique job the customer is trying to get done, and is best studied as a separate job. We have studied the purchase \u201cjob\u201d on a number of occasions over the years, and results show that the purchase process involves the customer working to understand the problem they are trying to solve, and then researching and evaluating possible solutions, selecting the best solution, deciding where to buy it, and finally, engaging in the physical transaction required to acquire the product. Gaining customer insights across this job at the desired outcome level can lead to improvements in the customer\u2019s purchase experience. While each of these four jobs is clearly different, they can all benefit from Jobs-to-be-Done Theory. It\u2019s just a matter of picking the right tool for the job.","title":"What is Jobs-to-be-done"},{"location":"JTBD/jtbd/#what-is-jobs-to-be-done","text":"Article by Tony Ulwick (Mar 1, 2017) What is Jobs-to-be-Done Theory? What is a job-to-be-done? A desired outcome? JOBS-TO-BE-DONE is best defined as a perspective \u2014 a lens through which you can observe markets, customers, needs, competitors, and customer segments differently, and by doing so, make innovation far more predictable and profitable. When Einstein engaged in his thought experiments, he pictured himself riding on a beam of light and traveling through the universe. From this perspective he was able to view the universe through a new lens, enabling him to see things in a different and meaningful way and to develop a theory that others could not. Similarly, when you look at marketing and innovation through a Jobs-to-be-Done lens, everything looks different: The unit of analysis is no longer the customer or the product, it\u2019s the core functional \u201cjob\u201d the customer is trying to get done. Markets aren\u2019t defined around products, they are defined as groups of people trying to get a job done. Customers aren\u2019t buyers, they are job executors. Needs aren\u2019t vague, latent and unknowable, they are the metrics customers use to measure success when getting a job done. Competitors aren\u2019t companies that make products like yours, they are any solution being used to get the job done. Customer segments aren\u2019t based on demographics or psychographics, they are based on how customers struggle differently to get a job done. When a company thinks about a market from this perspective, it is much more likely to create and deliver extraordinary products and services. Why? While products come and go, the customer\u2019s job-to-be-done is stable over time. With a focus on a stable unit of analysis, it becomes possible to define customer needs that are stable over time as well, giving companies unique, robust targets for value creation. In short, jobs-to-be-done offers a new framework and lens through which a company can take its understanding of customer needs to the next level \u2014 and bring predictability to innovation. The first documented success achieved by a company applying this thinking was detailed in the 2002 Harvard Business Review article: Turn Customer Input into Innovation. The article describes how in 1993 Cordis Corporation used this thinking to increase its angioplasty balloon market share from 1 percent to over 20 percent. Jobs-to-be-Done is best defined as a perspective \u2014 a lens through which customer needs can be effectively defined and communicated, making marketing more effective and innovation far more predictable. When looking at marketing and innovation through a jobs-to-be-done lens, a theory begins to emerge. Important JOBS-TO-BE-DONE THEORY is comprised of a group of principles or tenets that form a foundation for making marketing more effective and innovation more predictable by focusing on the customer\u2019s job-to-be-done. The theory is based on the notion that people buy products and services to get a \u201cjob\u201d done. Jobs Theory goes on to say that by understanding in detail what that \u201cjob\u201d entails, companies are far more likely to create and market solutions that will win in the marketplace. The core tenets of Jobs-to-be-Done Theory are summarized as follows: People buy products and services to get a \u201cjob\u201d done. Jobs are functional, with emotional and social components. A Job-to-be-Done is stable over time. A Job-to-be-Done is solution agnostic. Success comes from making the \u201cjob\u201d, rather than the product or the customer, the unit of analysis. A deep understanding of the customer\u2019s \u201cjob\u201d makes marketing more effective and innovation far more predictable. People want products and services that wil help them get a job done better and/or more cheaply People seek out products and services that enable them to get the entire job done on a single platform Customer needs, when tied to the job-to-be-done, make innovation predictable In order to study a job-to-be-done, the job must be correctly defined: Definition A JOB-TO-BE-DONE is a statement that describes, with precision, what a group of people are trying to achieve or accomplish in a given situation. A job-to-be-done could be a task that people are trying to accomplish, a goal or objective they are trying to achieve, a problem they are trying to resolve, something they are trying to avoid, or anything else they are trying to accomplish. A job statement is written as [verb] + [object of the verb] + [contextual clarifier] (optionally). For example, pass on life lessons to children, repair a torn rotator cuff and prevent a shooter from entering a school, are all jobs-to-be-done. To gain a deep understanding of the customer\u2019s job-to-be-done, a company must be able to discover the customer\u2019s \u201cneeds\u201d associated with getting that job done. When looking at a market through a jobs-to-be-done lens, customer needs can be discovered by studying the customer\u2019s core functional job as a process. Tactically, the core functional job can be broken down into steps using what we call a job map as described in the 2008 Harvard Business Review article, The Customer-Centered Innovation Map. With the job map in place, companies can then seek to discover the metrics customers use to measure success as they try to get each step in the job done. These metrics are the perfect way to think about and define the customer\u2019s \u201cneeds.\u201d These need statements, which we call \u201cdesired outcomes,\u201d bring predictability to innovation. Definition A DESIRED OUTCOME STATEMENT is a specially constructed need statement that has a unique set of characteristics: desired outcomes are devoid of solutions, stable over time, measureable, controllable, structured for reliable prioritization in a quantitative customer survey, and are tied to the underlying process (or job) the customer is trying to get done. Since the customer\u2019s job-to-be-done is stable over time, the customer\u2019s needs, when defined as desired outcome statements, are also stable over time. With a stable set of \u201cneeds\u201d in hand, a company is able to: Quantify which needs are under-served and over-served. Discover segments of customers with different unmet needs. Use the metrics as a baseline against which they can test product ideas and concepts before they are developed. Knowing which product or service concept will get the job done best early in the product planning stages (prior to development), is the key to predictable and profitable innovation. This case study shows how Bosch applied Jobs Theory to product innovation. This case study shows how Arm & Hammer applied Jobs Theory to marketing innovation. This case study shows how AMO applied Jobs Theory to service innovation.","title":"What is Jobs-to-be-Done?"},{"location":"JTBD/jtbd/#jobs-to-be-done-theory-is-applicable-along-many-fronts","text":"To explain how to put Jobs-to-be-Done Theory into practice, let\u2019s start by asking, \u201cWho are the potential users of Jobs-to-be-Done Theory and what are the jobs they are trying to get done?\u201d Four jobs are of particular interest: (1) market selection (deciding what markets to enter), (2) product planning (deciding what products to create), (3) product development (deciding how to best design a product), and (4) buying process (deciding how to improve the customer\u2019s buying process).","title":"Jobs-to-be-Done Theory is applicable along many fronts"},{"location":"JTBD/jtbd/#1-market-selection-deciding-what-markets-to-enter","text":"First, Jobs-to-be-Done Theory is being embraced by entrepreneurs in startups and managers in corporations and corporate venturing units who are trying to discover, evaluate and select markets that are attractive for them to enter/pursue. When looking through a jobs-to-be-done lens, a market is defined as a group of people (job executors) and the job they are trying to get done. As entrepreneurs and managers engage in the market discovery and selection process, they start by trying to discover a number of unique jobs that job executors are struggling to get done. Their goal is to discover and define the jobs at a level of abstraction that makes the job a uniquely attractive target. Once a number of markets are identified, the next step in the market selection process is to determine which is the most attractive to pursue. A job, for example, that is executed by many people, frequently, and is highly under-served would be a more attractive target than one that is executed by fewer people, infrequently and is already appropriately served. Following, we will show market evaluation tool that includes 42 criteria to help make the market selection decision: (see Figure 2) Figure 2: Jobs-to-be-Done Market Evaluation and Selection Template","title":"1. Market Selection: deciding what markets to enter"},{"location":"JTBD/jtbd/#2-product-planning-deciding-what-products-to-create","text":"Second, Jobs-to-be-Done Theory has been embraced by product, marketing and innovation managers in established companies who are trying to grow and expand their core markets. Their goals are to typically (i) create a value proposition that resonates with customers, (ii) improve existing products, and (iii) conceptualize altogether new products that will address core or adjacent market opportunities. These activities, executed by the product planner, comprise the innovation process. To apply Jobs-to-be-Done Theory to assist in marketing and innovation, Strategyn developed Outcome-Driven Innovation\u00ae (ODI). The innovation process originated in 1991 and has been simplified and improved through hundreds of applications within Fortune 500 companies since. The ODI process is comprised of the following 6 steps (Figure 3): Figure 3: The Outcome-Driven Innovation Process While the first step overlaps a step in the market selection process (market discovery and definition) the remaining steps in the process are different and so are the tools required to execute them. Tip To win at innovation a company must know what a customer need is, what the customer\u2019s needs are, which are unmet and if segments of customers exist with unique sets of unmet needs. With the target well defined, creating a winning solution becomes far more likely. ODI reveals the required insights using unconventional qualitative and quantitative market research techniques. The process uniquely employs predictive data and a sophisticated market segmentation methodology that helps companies discover and prioritize hidden market opportunities.","title":"2. Product Planning: deciding what products to create"},{"location":"JTBD/jtbd/#3-product-development-deciding-how-to-best-design-a-product","text":"The third application involves developers and UI and UX designers who are trying to develop products that have been approved for development (their job-to-be-done). These developers may work in lean or agile environments. Their goal is to ensure that the products they create and the code they write not only delivers on the product specifications, but also guarantees a positive user experience. Those trying to apply Jobs-to-be-Done Theory to the product development process typically have the benefit of knowing what product they are trying to create: the product is already conceptualized and defined as part of the innovation process. What developers and UI and UX designers struggle with are design issues and understanding the customer\u2019s needs that relate to what we call consumption chain jobs, such as learning how to use and interfacing with the product (see Figure 4). Figure 4: Consumption Chain Jobs and Outcomes As an extension of the ODI process, our clients apply steps 2 and 3 of the ODI process (outcome gathering and prioritization) to better understand the outcomes of users as they learn how to use, interface with the product and engage in the remaining consumption chain jobs that must be considered in the design phase. We have collected outcomes in all consumption chain jobs multiple times over the years. If a company uses ODI for the innovation process, developers will have the prioritized outcomes associated with the core functional job. These inputs are needed for development/design as well. These insights can then be communicated to developers or UX and UI designers in the following Job/Outcome Story format: (Figure 5) Figure 5: The Job/Outcome Story for Developers/Designers If a developer does not have access to the customer outcomes associated with the core functional job-to-be-done, then they tend to want to execute the innovation process in conjunction with the development process \u2014 learning more about the required product function as they create the product. Combining the development process with the innovation process creates confusion when using and implementing Jobs-to-be-Done Theory. A product concept should be well defined and proven to win in the marketplace before it is approved for development. The ODI process makes this possible.","title":"3. Product Development: deciding how to best design a product"},{"location":"JTBD/jtbd/#4-buying-process-deciding-how-to-improve-the-customers-buying-process","text":"The forth application of the theory involves marketing team members who are trying to understand the process that customer\u2019s go through when buying a product so they can enhance the customer\u2019s buying experience. Confusion over Jobs-to-be-Done theory results from thinking that understanding the customer purchase decision will somehow inform the innovation and development processes as well, but it does not. The purchase \u201cprocess\u201d is an altogether unique job the customer is trying to get done, and is best studied as a separate job. We have studied the purchase \u201cjob\u201d on a number of occasions over the years, and results show that the purchase process involves the customer working to understand the problem they are trying to solve, and then researching and evaluating possible solutions, selecting the best solution, deciding where to buy it, and finally, engaging in the physical transaction required to acquire the product. Gaining customer insights across this job at the desired outcome level can lead to improvements in the customer\u2019s purchase experience. While each of these four jobs is clearly different, they can all benefit from Jobs-to-be-Done Theory. It\u2019s just a matter of picking the right tool for the job.","title":"4. Buying Process: deciding how to improve the customer\u2019s buying process"},{"location":"JTBD/management/","text":"Management\u2019s Role In Achieving Predictable Innovation Acknowledging who is ultimately responsible for product innovation \u2014 and ensuring they have the tools to succeed \u2014 can dramatically improve a company\u2019s innovation success rate. Tony Ulwick Tony Ulwick Follow Jun 6, 2018 \u00b7 6 min read When it comes to introducing new products, companies excel: they introduce thousands of new products every year. Unfortunately, most of them fail. This highlights the real issue that plagues companies worldwide: Companies do not struggle to create products. Rather, they struggle to create the right products, i.e., those that are certain to win in the marketplace. This raises an important question: In your company, who is responsible for deciding what products will enter the product development process \u2014 and for making sure they are the right products? As it turns out, innovation is not everybody\u2019s responsibility. Ironically, in most companies just a hand full of people decide what products will enter the product development process. This small group of people (which is likely to include VP\u2019s, directors and other managers) is ultimately responsible for innovation: for ensuring the products they approve for development will be successful in the marketplace. If they approve products that fail to exit the development process or fail in the marketplace, they will have wasted the company\u2019s time, money and resources. Consequently, their ultimate goal is to ensure only winning products enter the product development process \u2014 and reject all others. While this may sound like an impossible task, it is not. But to be successful, this small group of people (let\u2019s call them the Product Oversight Team) must learn to think and act differently. To help a company excel at product innovation, this team must: Acknowledge that they are responsible for innovation \u2014 and work to ensure only winning products enter the development process. Ensure each product team (developers, engineers, scientists, marketers and others) has the information it needs to conceptualize winning solutions, i.e., products and services that get the customer\u2019s \u201cjob\u201d done better and/or more cheaply. Be able to assess, with a high degree of certainty, which proposed solutions will get the \u201cjob\u201d done best and win in the marketplace. This means they must have a fail-safe method in place for deciding which products to invest in. The tools needed to achieve these objectives are available as part of the Outcome-Driven Innovation (ODI) process, but they are rarely utilized by the Product Oversight Team, as they often delegate innovation responsiblities to others in the organization. It\u2019s time for management to lead the innovation effort and to think differently. Management is responsible for the company\u2019s success at innovation Product innovation isn\u2019t everybody\u2019s responsibility. It is management\u2019s responsibility. Management\u2019s failure to recognize and take on this responsibility has contributed greatly to the poor innovation success rates that companies struggle with today. It\u2019s understandable: nobody wants to be responsible for a process that appears to be random and unpredictable. But by delegating the responsibility for innovation to \u201ceverybody\u201d, management is contributing to its seemingly unpredictable nature. The truth is innovation is no longer an unpredictable process. The kinks have been worked out. Jobs-to-be-Done Theory and ODI make innovation far more predictable. The Product Oversight Team must recognize this fact and lead the drive towards predictable innovation. After all, only management can make sure the organization has the information it needs to succeed and install the discipline that is needed to ensure only winning products enter the development process. Ensure the organization has the data it needs for innovation All too often companies put products into their development pipeline without cross functional agreement on: (i) who the customer is, (ii) what the customer\u2019s needs are, or (iii) which customer needs are unmet. In most companies, these questions are highly debated and often go unanswered. As a result, when it comes to product innovation, developers struggle to conceptualize winning products and managers struggle to separate the winning product ideas from the losers. In order to devise winning solutions, the product team must agree on these fundamental inputs \u2014 and making the Product Oversight Team responsible for ensuring they have these insights makes good sense. Currently, in most companies, nobody is responsible for ensuring product teams have a common understanding of the problems (jobs-to-be-done) they are trying to solve. In fact, it is often accepted as an unavoidable business practice that sales, marketing, development and R&D will never be on the same page. This has to change. A common understanding of the customer and alignment on the customer\u2019s needs can be accomplished by ensuring each product team invests in applying Jobs-to-be-Done Theory and Outcome-Driven Innovation to its markets. This may require both governance and funding from the Product Oversight Team. The Product Oversight Team should recommended that each product team: Learn the fundamentals of Jobs-to-be-Done Theory and the ODI process. Participate in a facilitated qualitative research discussions designed to obtain the customer\u2019s desired outcome statements (see Inventing the Perfect Customer Need Statement). Conduct quantitative research to determine which outcomes are under/over-served, and by how much (see Reinventing Market Research to put Jobs Theory into Practice). Secure cross-functional agreement on what the customer\u2019s needs are and which are unmet. Use their newfound insights to conceptualize and refine products and services that address the customer\u2019s underserved outcomes and get the \u201cjob\u201d done better and/or more cheaply. Evaluate their best ideas against the desired outcome statements to quantify just how much better they get the job done and their likelihood of winning in the marketplace. Use the data to justify to the Product Oversight Team why they should approve the proposed product/service for development. Each product team will be far more likely to create winning product concepts when applying this discipline. Determine what ideas have the best chance of winning in the marketplace The Product Oversight Team can use the same insights used by the product team to help evaluate the product concepts that are submitted for approval. In other words, the Product Oversight Team can enforce discipline by asking those who submit product concepts for development to quantify just how much better and/or more cheaply they enable customers to get the job done. Then they can apply a rule set that helps guide their investment decisions. For example, they may decide to: Only invest in new products and services that will help customers get a job done at least 20% better. Only invest in sustaining products that will help customers get a job done at least 5% better. Seek out products that will help customers get the job done both significantly better and cheaper. Avoid investing in disruptive solutions targeted at underserved market segments. Avoid investing in differentiated, higher cost solutions targeted at overserved market segments. With the right benchmarks in place \u2014 and the data required to ensure the benchmarks have been met \u2014 the Product Oversight Team, and the company as a whole, will be much more effective at ensuring only winning products enter the product development process. This will dramatically cut waste in product development and lead to significant time and cost savings. Learn more about Jobs-to-be-Done and Outcome-Driven Innovation.","title":"Management"},{"location":"projects/","text":"Projects General Page \u00b6","title":"Projects General Page"},{"location":"projects/#projects-general-page","text":"","title":"Projects General Page"},{"location":"projects/Imak/","text":"Imak Project Pages \u00b6","title":"Imak Project Pages"},{"location":"projects/Imak/#imak-project-pages","text":"","title":"Imak Project Pages"},{"location":"projects/ayni/","text":"Ayni Project Pages \u00b6","title":"Ayni Project Pages"},{"location":"projects/ayni/#ayni-project-pages","text":"","title":"Ayni Project Pages"},{"location":"projects/cannor/","text":"Cannor Project Pages \u00b6","title":"Cannor Project Pages"},{"location":"projects/cannor/#cannor-project-pages","text":"","title":"Cannor Project Pages"},{"location":"reference/abbreviations/","text":"Abbreviations \u00b6 Technical documentation often incurs the usage of a lot of acronyms, which may need additional explanation, especially for new user of your project. For these matters, Material for MkDocs uses a combination of Markdown extensions to enable site-wide glossaries. Usage \u00b6 Adding abbreviations (On-Spot) \u00b6 Abbreviations can be defined with a special syntax similar to URLs and footnotes at any point in the Markdown document. Example : The HTML specification is maintained by the W3C. *[HTML]: Hyper Text Markup Language *[W3C]: World Wide Web Consortium Result : The HTML specification is maintained by the W3C . Adding a glossary \u00b6 Sometimes, it is especially useful to include abbreviations from a central file \u2013 a glossary \u2013 and embed them into the page that you are working. The result will be exactly the same as if you are using specific \"on-spot\" abbreviations. Example : The following example had to be written with the set of back-colons `` to avoid triggering the snippet. After copying the example, don't forget to delete the back-colons before the snippet and after the snippet. docs/your_page.md The HTML specification is maintained by the W3C. `--8<-- \"include/abbreviations-list.md\"` include/abbreviations-list.md *[HTML]: Hyper Text Markup Language *[W3C]: World Wide Web Consortium Result : The HTML specification is maintained by the W3C . Remember to update the Markdown file (includes/abbreviations.md) located outside of the docs folder to add the relevant abbreviations. This file contains the definitions for the abbreviation snippets.","title":"Abbreviations"},{"location":"reference/abbreviations/#abbreviations","text":"Technical documentation often incurs the usage of a lot of acronyms, which may need additional explanation, especially for new user of your project. For these matters, Material for MkDocs uses a combination of Markdown extensions to enable site-wide glossaries.","title":"Abbreviations"},{"location":"reference/abbreviations/#usage","text":"","title":"Usage"},{"location":"reference/abbreviations/#adding-abbreviations-on-spot","text":"Abbreviations can be defined with a special syntax similar to URLs and footnotes at any point in the Markdown document. Example : The HTML specification is maintained by the W3C. *[HTML]: Hyper Text Markup Language *[W3C]: World Wide Web Consortium Result : The HTML specification is maintained by the W3C .","title":"Adding abbreviations (On-Spot)"},{"location":"reference/abbreviations/#adding-a-glossary","text":"Sometimes, it is especially useful to include abbreviations from a central file \u2013 a glossary \u2013 and embed them into the page that you are working. The result will be exactly the same as if you are using specific \"on-spot\" abbreviations. Example : The following example had to be written with the set of back-colons `` to avoid triggering the snippet. After copying the example, don't forget to delete the back-colons before the snippet and after the snippet. docs/your_page.md The HTML specification is maintained by the W3C. `--8<-- \"include/abbreviations-list.md\"` include/abbreviations-list.md *[HTML]: Hyper Text Markup Language *[W3C]: World Wide Web Consortium Result : The HTML specification is maintained by the W3C . Remember to update the Markdown file (includes/abbreviations.md) located outside of the docs folder to add the relevant abbreviations. This file contains the definitions for the abbreviation snippets.","title":"Adding a glossary"},{"location":"reference/awesome/","text":"Customizing Navigation \u00b6 By customizing navigation, there is a way to have detailed control by using a small configuration file directly placed in the relevant directory of the documentation. How does it work? \u00b6 By creating a YAML file named .pages in a directory and using the nav attribute to customize the navigation on that level. Files and subdirectories can be listed in the order that they should appear in the navigation. nav : - subdirectory - page1.md - page2.md Rest \u00b6 Pages or sections that are not mentioned in the list will not appear in the navigation. However, a ... entry you may be included to specify where all remaining items should be inserted. nav : - introduction.md - ... - summary.md Furthermore, it is possible to filter the remaining items using glob patterns or regular expressions. For example to match only the Markdown files starting with introduction- . nav : - ... | introduction-*.md - ... - summary.md Note The pattern is checked against the basename (folder- / filename) of remaining items - not their whole path. For more details refer to the Rest Filter Patterns section below. Titles \u00b6 A title for the navigation entry can be optionally specified. nav : - ... - First page : page1.md Note Specifying a title for a directory containing a .pages file that defines a title has no effect. Links \u00b6 Additional external links can also be used the nav attribute. nav : - ... - Link Title : https://lukasgeiter.com Changing the Sort Order \u00b6 By creating a YAML file named .pages in a directory and setting the order attribute to asc or desc , the order of navigation items can be changed. order : desc Note Unlike the default order, this does not distinguish between files and directories. Therefore pages and sections might get mixed. Collapsing Single Nested Pages \u00b6 With directories that only contain a single page, \"collapsing\" them is possible, so the folder doesn't show up in the navigation. For example, with the following file structure: docs/ \u251c\u2500 section1/ \u2502 \u251c\u2500 img/ \u2502 \u2502 \u251c\u2500 image1.png \u2502 \u2502 \u2514\u2500 image2.png \u2502 \u2514\u2500 index.md # Section 1 \u2514\u2500 section2/ \u2514\u2500 index.md # Section 2 The pages will appear in the navigation at the root level: Section 1 Section 2 Instead of how they would be displayed by default: Section 1 index.md # Section 1 Section 2 index.md # Section 2 For a sub-section \u00b6 To collapse certain pages, a YAML file called .pages can be created in the directory, and the collapse_single_pages can be set to true : collapse_single_pages : true You may also enable collapsing globally using the plugin option and then use the .pages file to prevent certain sub-sections from being collapsed by setting collapse_single_pages to false . Note This feature works recursively. That means it will also collapse multiple levels of single pages. For a single page \u00b6 To enable or disable collapsing of a single page, without applying the setting recursively, a YAML file called .pages can be created in the directory, and the collapse attribute can be set to true or false : collapse : true Hiding a Directory \u00b6 By creating a YAML file named .pages in a directory, and setting the hide attribute to true the directory is hidden, including all sub-pages and sub-sections, from the navigation: hide : true Note This option only hides the section from the navigation. It will still be included in the build and can be accessed under its URL. Setting a Directory Title \u00b6 By creating a YAML file named .pages in a directory, and setting the title attribute, the title of that directory in the navigation is overridden: title : Page Title Rest Filter Patterns \u00b6 In all places where the rest entry ( ... ) is allowed, a glob pattern or regular expression can be included to filter the items to be displayed. nav : - ... | page-*.md - ... | regex=page-[0-9]+.md The filter only operates on remaining items. This means it will not include items that are explicitly listed in the navigation or items that are matched by another filter that appears earlier in the configuration. You may also include a rest entry without filter to act as a catch-all, inserting everything that is not matched by a filter. Syntax Details \u00b6 Unless the filter starts with regex= it is interpreted as glob pattern, however you may also explicitly say so using glob= . The spaces around ... are optional but recommended for readability. Note Depending on the characters in your filter, you might also need to use quotes around the whole entry. nav : # equivalent glob entries - ... | page-*.md - ... | glob=page-*.md - ...|page-*.md - '... | page-*.md' # equivalent regex entries - ... | regex=page-[0-9]+.md - ...|regex=page-[0-9]+.md - '... | regex=page-[0-9]+.md'","title":"Customizing Navigation"},{"location":"reference/awesome/#customizing-navigation","text":"By customizing navigation, there is a way to have detailed control by using a small configuration file directly placed in the relevant directory of the documentation.","title":"Customizing Navigation"},{"location":"reference/awesome/#how-does-it-work","text":"By creating a YAML file named .pages in a directory and using the nav attribute to customize the navigation on that level. Files and subdirectories can be listed in the order that they should appear in the navigation. nav : - subdirectory - page1.md - page2.md","title":"How does it work?"},{"location":"reference/awesome/#rest","text":"Pages or sections that are not mentioned in the list will not appear in the navigation. However, a ... entry you may be included to specify where all remaining items should be inserted. nav : - introduction.md - ... - summary.md Furthermore, it is possible to filter the remaining items using glob patterns or regular expressions. For example to match only the Markdown files starting with introduction- . nav : - ... | introduction-*.md - ... - summary.md Note The pattern is checked against the basename (folder- / filename) of remaining items - not their whole path. For more details refer to the Rest Filter Patterns section below.","title":"Rest"},{"location":"reference/awesome/#titles","text":"A title for the navigation entry can be optionally specified. nav : - ... - First page : page1.md Note Specifying a title for a directory containing a .pages file that defines a title has no effect.","title":"Titles"},{"location":"reference/awesome/#links","text":"Additional external links can also be used the nav attribute. nav : - ... - Link Title : https://lukasgeiter.com","title":"Links"},{"location":"reference/awesome/#changing-the-sort-order","text":"By creating a YAML file named .pages in a directory and setting the order attribute to asc or desc , the order of navigation items can be changed. order : desc Note Unlike the default order, this does not distinguish between files and directories. Therefore pages and sections might get mixed.","title":"Changing the Sort Order"},{"location":"reference/awesome/#collapsing-single-nested-pages","text":"With directories that only contain a single page, \"collapsing\" them is possible, so the folder doesn't show up in the navigation. For example, with the following file structure: docs/ \u251c\u2500 section1/ \u2502 \u251c\u2500 img/ \u2502 \u2502 \u251c\u2500 image1.png \u2502 \u2502 \u2514\u2500 image2.png \u2502 \u2514\u2500 index.md # Section 1 \u2514\u2500 section2/ \u2514\u2500 index.md # Section 2 The pages will appear in the navigation at the root level: Section 1 Section 2 Instead of how they would be displayed by default: Section 1 index.md # Section 1 Section 2 index.md # Section 2","title":"Collapsing Single Nested Pages"},{"location":"reference/awesome/#for-a-sub-section","text":"To collapse certain pages, a YAML file called .pages can be created in the directory, and the collapse_single_pages can be set to true : collapse_single_pages : true You may also enable collapsing globally using the plugin option and then use the .pages file to prevent certain sub-sections from being collapsed by setting collapse_single_pages to false . Note This feature works recursively. That means it will also collapse multiple levels of single pages.","title":"For a sub-section"},{"location":"reference/awesome/#for-a-single-page","text":"To enable or disable collapsing of a single page, without applying the setting recursively, a YAML file called .pages can be created in the directory, and the collapse attribute can be set to true or false : collapse : true","title":"For a single page"},{"location":"reference/awesome/#hiding-a-directory","text":"By creating a YAML file named .pages in a directory, and setting the hide attribute to true the directory is hidden, including all sub-pages and sub-sections, from the navigation: hide : true Note This option only hides the section from the navigation. It will still be included in the build and can be accessed under its URL.","title":"Hiding a Directory"},{"location":"reference/awesome/#setting-a-directory-title","text":"By creating a YAML file named .pages in a directory, and setting the title attribute, the title of that directory in the navigation is overridden: title : Page Title","title":"Setting a Directory Title"},{"location":"reference/awesome/#rest-filter-patterns","text":"In all places where the rest entry ( ... ) is allowed, a glob pattern or regular expression can be included to filter the items to be displayed. nav : - ... | page-*.md - ... | regex=page-[0-9]+.md The filter only operates on remaining items. This means it will not include items that are explicitly listed in the navigation or items that are matched by another filter that appears earlier in the configuration. You may also include a rest entry without filter to act as a catch-all, inserting everything that is not matched by a filter.","title":"Rest Filter Patterns"},{"location":"reference/awesome/#syntax-details","text":"Unless the filter starts with regex= it is interpreted as glob pattern, however you may also explicitly say so using glob= . The spaces around ... are optional but recommended for readability. Note Depending on the characters in your filter, you might also need to use quotes around the whole entry. nav : # equivalent glob entries - ... | page-*.md - ... | glob=page-*.md - ...|page-*.md - '... | page-*.md' # equivalent regex entries - ... | regex=page-[0-9]+.md - ...|regex=page-[0-9]+.md - '... | regex=page-[0-9]+.md'","title":"Syntax Details"},{"location":"reference/basic-markdown/","text":"Basic Markdown Guide \u00b6 Nearly all Markdown applications support the basic syntax outlined in John Gruber\u2019s original design document. There are minor variations and discrepancies between Markdown processors \u2014 those are noted inline wherever possible. This page only describes Basic Markdown. However, Zigar Docs has en extended syntax module that allows for even richer Markdown documents. Please, refer to the other chapters in this Reference Guide to find out all the amazing options. Markdown Formatting \u00b6 Headings \u00b6 To create a heading, add number signs (#) in front of a word or phrase. The number of number signs you use should correspond to the heading level. For example, to create a heading level three (<h3>) , use three number signs (e.g., ### My Header). # This is an <h1> tag ## This is an <h2> tag ### This is an <h3> tag #### This is an <h4> tag ##### This is an <h5> tag ###### This is an <h6> tag Paragraphs \u00b6 To create paragraphs, use a blank line to separate one or more lines of text. Line Breaks \u00b6 You can use two or more spaces (commonly referred to as \u201ctrailing whitespace\u201d) for line breaks in nearly every Markdown application, but it\u2019s controversial. It\u2019s hard to see trailing whitespace in an editor, and many people accidentally or intentionally put two spaces after every sentence. For this reason, you may want to use something other than trailing whitespace for line breaks. Fortunately, there is another option supported by nearly every Markdown application: the <br> HTML tag. For compatibility, use trailing white space or the <br> HTML tag at the end of the line. Emphasis \u00b6 To bold text, add two asterisks or underscores before and after a word or phrase. To bold the middle of a word for emphasis, add two asterisks without spaces around the letters. To italicize text, add one asterisk or underscore before and after a word or phrase. To italicize the middle of a word for emphasis, add one asterisk without spaces around the letters. To emphasize text with bold and italics at the same time, add three asterisks or underscores before and after a word or phrase. To bold and italicize the middle of a word for emphasis, add three asterisks without spaces around the letters. Example : *This text will be italic* _This will also be italic_ **This text will be bold** __This will also be bold__ _You **can** combine them_ Result : This text will be italic This will also be italic This text will be bold This will also be bold You can combine them Lists \u00b6 Example : Inordered: * Milk * Bread * Wholegrain * Butter Result : Milk Bread Wholegrain Butter Ordered: Example : 1. Tidy the kitchen 2. Prepare ingredients 3. Cook delicious things Result : Tidy the kitchen Prepare ingredients Cook delicious things Images \u00b6 To add an image, add an exclamation mark (!), followed by alt text in brackets, and the path or URL to the image asset in parentheses. You can optionally add a title after the URL in the parentheses. ![Alt Text](url) Result: Example : ![m'lady](http://i.imgur.com/v8IVDka.jpg) Result : Linking Images \u00b6 To add a link to an image, enclose the Markdown for the image in brackets, and then add the link in parentheses. [![An old rock in the desert](../assets/shiprock.jpg \"Shiprock, New Mexico by Beau Rogers\")](https://www.flickr.com/photos/beaurogers/31833779864/in/photolist-Qv3rFw-34mt9F-a9Cmfy-5Ha3Zi-9msKdv-o3hgjr-hWpUte-4WMsJ1-KUQ8N-deshUb-vssBD-6CQci6-8AFCiD-zsJWT-nNfsgB-dPDwZJ-bn9JGn-5HtSXY-6CUhAL-a4UTXB-ugPum-KUPSo-fBLNm-6CUmpy-4WMsc9-8a7D3T-83KJev-6CQ2bK-nNusHJ-a78rQH-nw3NvT-7aq2qf-8wwBso-3nNceh-ugSKP-4mh4kh-bbeeqH-a7biME-q3PtTf-brFpgb-cg38zw-bXMZc-nJPELD-f58Lmo-bXMYG-bz8AAi-bxNtNT-bXMYi-bXMY6-bXMYv) The rendered output looks like this: Links \u00b6 To create a link, enclose the link text in brackets (e.g., [Duck Duck Go] ) and then follow it immediately with the URL in parentheses (e.g., (https://duckduckgo.com) ). Example : [This is a link](http://example.com) Result : This is a link Adding Titles \u00b6 You can optionally add a title for a link. This will appear as a tooltip when the user hovers over the link. To add a title, enclose it in parentheses after the URL. Example : My favorite search engine is [Duck Duck Go](https://duckduckgo.com \"The best search engine for privacy\"). Result : My favorite search engine is Duck Duck Go . Blockquotes \u00b6 To create a blockquote, add a > in front of a paragraph. Example : As Kanye West said: > We're living the future so > the present is our past. Result : As Kanye West said: We're living the future so the present is our past. Blockquotes with Multiple Paragraphs \u00b6 > Dorothy followed her through many of the beautiful rooms in her castle. > > The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood. Dorothy followed her through many of the beautiful rooms in her castle. The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood. Blockquotes can contain multiple paragraphs. Add a > on the blank lines between the paragraphs. Blockquotes can also be nested. Add a >> in front of the paragraph you want to nest. Example : > Dorothy followed her through many of the beautiful rooms in her castle. > >> The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood. Result : Dorothy followed her through many of the beautiful rooms in her castle. The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood. Horizontal Rules \u00b6 Example : --- Result : Code Snippets \u00b6 Indenting by 4 spaces will turn an entire paragraph into a code-block. Example : .my-link { text-decoration: underline; } Result : .my-link { text-decoration: underline; } Reference Lists & Titles \u00b6 Example : **The quick brown [fox][1], jumped over the lazy [dog][2].** [1]: https://en.wikipedia.org/wiki/Fox \"Wikipedia: Fox\" [2]: https://en.wikipedia.org/wiki/Dog \"Wikipedia: Dog\" Result : The quick brown fox , jumped over the lazy dog . Escaping \u00b6 Example : \\*literally\\* Result : *literally* Embedding HTML \u00b6 Example : <button class=\"button-save large\">Big Fat Button</button> Result : Big Fat Button Markdown Footnotes \u00b6 Example : Work in Ghost : The quick brown fox[^1] jumped over the lazy dog[^2]. [^1]: Foxes are red [^2]: Dogs are usually not red Result : The quick brown fox 1 jumped over the lazy dog 2 . (Please scroll to the end of the page, and you will see a footnote) GitHub Flavored Markdown \u00b6 Syntax Highlighting \u00b6 Example : ``` javascript function fancyAlert(arg) { if(arg) { $.facebox({div:'#foo'}) } } ``` Result : function fancyAlert ( arg ) { if ( arg ) { $ . facebox ({ div : '#foo' }) } } Task Lists \u00b6 Example : - [x] @mentions, #refs, [links](), **formatting**, and <del>tags</del> supported - [x] list syntax required (any unordered or ordered list supported) - [x] this is a complete item - [ ] this is an incomplete item Result : @mentions , #refs, links , formatting , and tags supported list syntax required (any unordered or ordered list supported) this is a complete item this is an incomplete item Tables \u00b6 You can create tables by assembling a list of words and dividing them with hyphens - (for the first row), and then separating each column with a pipe | : Example : First Header | Second Header ------------ | ------------- Content from cell 1 | Content from cell 2 Content in the first column | Content in the second column Result : First Header Second Header Content from cell 1 Content from cell 2 Content in the first column Content in the second column Username @mention \u00b6 Typing an @ symbol, followed by a username, will notify that person to come and view the comment. This is called an \u201c @mention \u201d, because you\u2019re mentioning the individual. You can also @mention teams within an organization. For example @datahomelab . References \u00b6 http://blog.ghost.org/markdown/ https://guides.github.com/features/mastering-markdown/ Foxes are red \u21a9 Dogs are usually not red \u21a9","title":"Basic Markdown Guide"},{"location":"reference/basic-markdown/#basic-markdown-guide","text":"Nearly all Markdown applications support the basic syntax outlined in John Gruber\u2019s original design document. There are minor variations and discrepancies between Markdown processors \u2014 those are noted inline wherever possible. This page only describes Basic Markdown. However, Zigar Docs has en extended syntax module that allows for even richer Markdown documents. Please, refer to the other chapters in this Reference Guide to find out all the amazing options.","title":"Basic Markdown Guide"},{"location":"reference/basic-markdown/#markdown-formatting","text":"","title":"Markdown Formatting"},{"location":"reference/basic-markdown/#headings","text":"To create a heading, add number signs (#) in front of a word or phrase. The number of number signs you use should correspond to the heading level. For example, to create a heading level three (<h3>) , use three number signs (e.g., ### My Header). # This is an <h1> tag ## This is an <h2> tag ### This is an <h3> tag #### This is an <h4> tag ##### This is an <h5> tag ###### This is an <h6> tag","title":"Headings"},{"location":"reference/basic-markdown/#paragraphs","text":"To create paragraphs, use a blank line to separate one or more lines of text.","title":"Paragraphs"},{"location":"reference/basic-markdown/#line-breaks","text":"You can use two or more spaces (commonly referred to as \u201ctrailing whitespace\u201d) for line breaks in nearly every Markdown application, but it\u2019s controversial. It\u2019s hard to see trailing whitespace in an editor, and many people accidentally or intentionally put two spaces after every sentence. For this reason, you may want to use something other than trailing whitespace for line breaks. Fortunately, there is another option supported by nearly every Markdown application: the <br> HTML tag. For compatibility, use trailing white space or the <br> HTML tag at the end of the line.","title":"Line Breaks"},{"location":"reference/basic-markdown/#emphasis","text":"To bold text, add two asterisks or underscores before and after a word or phrase. To bold the middle of a word for emphasis, add two asterisks without spaces around the letters. To italicize text, add one asterisk or underscore before and after a word or phrase. To italicize the middle of a word for emphasis, add one asterisk without spaces around the letters. To emphasize text with bold and italics at the same time, add three asterisks or underscores before and after a word or phrase. To bold and italicize the middle of a word for emphasis, add three asterisks without spaces around the letters. Example : *This text will be italic* _This will also be italic_ **This text will be bold** __This will also be bold__ _You **can** combine them_ Result : This text will be italic This will also be italic This text will be bold This will also be bold You can combine them","title":"Emphasis"},{"location":"reference/basic-markdown/#lists","text":"Example : Inordered: * Milk * Bread * Wholegrain * Butter Result : Milk Bread Wholegrain Butter Ordered: Example : 1. Tidy the kitchen 2. Prepare ingredients 3. Cook delicious things Result : Tidy the kitchen Prepare ingredients Cook delicious things","title":"Lists"},{"location":"reference/basic-markdown/#images","text":"To add an image, add an exclamation mark (!), followed by alt text in brackets, and the path or URL to the image asset in parentheses. You can optionally add a title after the URL in the parentheses. ![Alt Text](url) Result: Example : ![m'lady](http://i.imgur.com/v8IVDka.jpg) Result :","title":"Images"},{"location":"reference/basic-markdown/#linking-images","text":"To add a link to an image, enclose the Markdown for the image in brackets, and then add the link in parentheses. [![An old rock in the desert](../assets/shiprock.jpg \"Shiprock, New Mexico by Beau Rogers\")](https://www.flickr.com/photos/beaurogers/31833779864/in/photolist-Qv3rFw-34mt9F-a9Cmfy-5Ha3Zi-9msKdv-o3hgjr-hWpUte-4WMsJ1-KUQ8N-deshUb-vssBD-6CQci6-8AFCiD-zsJWT-nNfsgB-dPDwZJ-bn9JGn-5HtSXY-6CUhAL-a4UTXB-ugPum-KUPSo-fBLNm-6CUmpy-4WMsc9-8a7D3T-83KJev-6CQ2bK-nNusHJ-a78rQH-nw3NvT-7aq2qf-8wwBso-3nNceh-ugSKP-4mh4kh-bbeeqH-a7biME-q3PtTf-brFpgb-cg38zw-bXMZc-nJPELD-f58Lmo-bXMYG-bz8AAi-bxNtNT-bXMYi-bXMY6-bXMYv) The rendered output looks like this:","title":"Linking Images"},{"location":"reference/basic-markdown/#links","text":"To create a link, enclose the link text in brackets (e.g., [Duck Duck Go] ) and then follow it immediately with the URL in parentheses (e.g., (https://duckduckgo.com) ). Example : [This is a link](http://example.com) Result : This is a link","title":"Links"},{"location":"reference/basic-markdown/#adding-titles","text":"You can optionally add a title for a link. This will appear as a tooltip when the user hovers over the link. To add a title, enclose it in parentheses after the URL. Example : My favorite search engine is [Duck Duck Go](https://duckduckgo.com \"The best search engine for privacy\"). Result : My favorite search engine is Duck Duck Go .","title":"Adding Titles"},{"location":"reference/basic-markdown/#blockquotes","text":"To create a blockquote, add a > in front of a paragraph. Example : As Kanye West said: > We're living the future so > the present is our past. Result : As Kanye West said: We're living the future so the present is our past.","title":"Blockquotes"},{"location":"reference/basic-markdown/#blockquotes-with-multiple-paragraphs","text":"> Dorothy followed her through many of the beautiful rooms in her castle. > > The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood. Dorothy followed her through many of the beautiful rooms in her castle. The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood. Blockquotes can contain multiple paragraphs. Add a > on the blank lines between the paragraphs. Blockquotes can also be nested. Add a >> in front of the paragraph you want to nest. Example : > Dorothy followed her through many of the beautiful rooms in her castle. > >> The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood. Result : Dorothy followed her through many of the beautiful rooms in her castle. The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood.","title":"Blockquotes with Multiple Paragraphs"},{"location":"reference/basic-markdown/#horizontal-rules","text":"Example : --- Result :","title":"Horizontal Rules"},{"location":"reference/basic-markdown/#code-snippets","text":"Indenting by 4 spaces will turn an entire paragraph into a code-block. Example : .my-link { text-decoration: underline; } Result : .my-link { text-decoration: underline; }","title":"Code Snippets"},{"location":"reference/basic-markdown/#reference-lists-titles","text":"Example : **The quick brown [fox][1], jumped over the lazy [dog][2].** [1]: https://en.wikipedia.org/wiki/Fox \"Wikipedia: Fox\" [2]: https://en.wikipedia.org/wiki/Dog \"Wikipedia: Dog\" Result : The quick brown fox , jumped over the lazy dog .","title":"Reference Lists &amp; Titles"},{"location":"reference/basic-markdown/#escaping","text":"Example : \\*literally\\* Result : *literally*","title":"Escaping"},{"location":"reference/basic-markdown/#embedding-html","text":"Example : <button class=\"button-save large\">Big Fat Button</button> Result : Big Fat Button","title":"Embedding HTML"},{"location":"reference/basic-markdown/#markdown-footnotes","text":"Example : Work in Ghost : The quick brown fox[^1] jumped over the lazy dog[^2]. [^1]: Foxes are red [^2]: Dogs are usually not red Result : The quick brown fox 1 jumped over the lazy dog 2 . (Please scroll to the end of the page, and you will see a footnote)","title":"Markdown Footnotes"},{"location":"reference/basic-markdown/#github-flavored-markdown","text":"","title":"GitHub Flavored Markdown"},{"location":"reference/basic-markdown/#syntax-highlighting","text":"Example : ``` javascript function fancyAlert(arg) { if(arg) { $.facebox({div:'#foo'}) } } ``` Result : function fancyAlert ( arg ) { if ( arg ) { $ . facebox ({ div : '#foo' }) } }","title":"Syntax Highlighting"},{"location":"reference/basic-markdown/#task-lists","text":"Example : - [x] @mentions, #refs, [links](), **formatting**, and <del>tags</del> supported - [x] list syntax required (any unordered or ordered list supported) - [x] this is a complete item - [ ] this is an incomplete item Result : @mentions , #refs, links , formatting , and tags supported list syntax required (any unordered or ordered list supported) this is a complete item this is an incomplete item","title":"Task Lists"},{"location":"reference/basic-markdown/#tables","text":"You can create tables by assembling a list of words and dividing them with hyphens - (for the first row), and then separating each column with a pipe | : Example : First Header | Second Header ------------ | ------------- Content from cell 1 | Content from cell 2 Content in the first column | Content in the second column Result : First Header Second Header Content from cell 1 Content from cell 2 Content in the first column Content in the second column","title":"Tables"},{"location":"reference/basic-markdown/#username-mention","text":"Typing an @ symbol, followed by a username, will notify that person to come and view the comment. This is called an \u201c @mention \u201d, because you\u2019re mentioning the individual. You can also @mention teams within an organization. For example @datahomelab .","title":"Username @mention"},{"location":"reference/basic-markdown/#references","text":"http://blog.ghost.org/markdown/ https://guides.github.com/features/mastering-markdown/ Foxes are red \u21a9 Dogs are usually not red \u21a9","title":"References"},{"location":"reference/buttons/","text":"Buttons \u00b6 Primary and secondary buttons can be added to any link, label or button element. This is especially useful for documents or landing pages with dedicated call-to-actions . Usage \u00b6 Adding buttons \u00b6 Any clickable element can be converted into a button by adding the .md-button CSS class, which will receive the selected primary color. Example : [ Subscribe to our mailing list ]( # ){ .md-button } Result : Subscribe to our mailing list Adding primary buttons \u00b6 If you want to display a filled, primary button add both the .md-button and .md-button--primary CSS classes. Example : [ Subscribe to our mailing list ]( # ){ .md-button .md-button--primary } Result : Subscribe to our mailing list Adding icon buttons \u00b6 Of course, icons can be added to both types of buttons by using the regular icon syntax and referencing a valid path to any icon bundled with the theme . Example : [ Submit :fontawesome-solid-paper-plane: ]( # ){ .md-button .md-button--primary } Result : Submit","title":"Buttons"},{"location":"reference/buttons/#buttons","text":"Primary and secondary buttons can be added to any link, label or button element. This is especially useful for documents or landing pages with dedicated call-to-actions .","title":"Buttons"},{"location":"reference/buttons/#usage","text":"","title":"Usage"},{"location":"reference/buttons/#adding-buttons","text":"Any clickable element can be converted into a button by adding the .md-button CSS class, which will receive the selected primary color. Example : [ Subscribe to our mailing list ]( # ){ .md-button } Result : Subscribe to our mailing list","title":"Adding buttons"},{"location":"reference/buttons/#adding-primary-buttons","text":"If you want to display a filled, primary button add both the .md-button and .md-button--primary CSS classes. Example : [ Subscribe to our mailing list ]( # ){ .md-button .md-button--primary } Result : Subscribe to our mailing list","title":"Adding primary buttons"},{"location":"reference/buttons/#adding-icon-buttons","text":"Of course, icons can be added to both types of buttons by using the regular icon syntax and referencing a valid path to any icon bundled with the theme . Example : [ Submit :fontawesome-solid-paper-plane: ]( # ){ .md-button .md-button--primary } Result : Submit","title":"Adding icon buttons"},{"location":"reference/code-blocks/","text":"Code blocks \u00b6 Code blocks and examples are an essential part of technical project documentation. The examples included in this section can be copy/pasted into your edited page, to facilitate this feature's use. Usage \u00b6 This section discusses how to use different syntax highlighting features. Specifying the language \u00b6 Code blocks must be enclosed with two separate lines containing three backticks. To add code highlighting to those blocks, add the language short name directly after the opening block. See the list of available lexers to find the short name for a given language. Example : ``` python import tensorflow as tf ``` Result : import tensorflow as tf Adding annotations \u00b6 Annotations offer a comfortable and friendly way to attach explanations to arbitrary sections of code blocks by adding simple markers within block/inline comments that refer to items of a list following the code block, i.e. (1) , (2) , etc. Material for MkDocs detaches the list from the flow of the document, injects the content of each list item into a tooltip, and links each list marker to the corresponding tooltip. In order to opt-in to annotation support, a slightly different syntax is required \u2013 just add the respective language short code and the .annotate class, after the three backticks. Note that annotations can be placed anywhere in a code block where a comment for the language can be placed, which for JavaScript is // (1) and /* (2) */ , for Yaml # (3) , etc. Example : ``` { .js .annotate } document$.subscribe(function() { // (1) var tables = document.querySelectorAll /* (2) */ tables.forEach(function(table) { new Tablesort(table) // (3) }) }) ``` 1. ... 2. ... Result : document $ . subscribe ( function () { // (1) var tables = document . querySelectorAll /* (2) */ tables . forEach ( function ( table ) { new Tablesort ( table ) // (3) }) }) Annotations can contain arbitrary content which is shown when the marker is focussed, including any kind of formatting, links, remarks, details, and even diagrams: 1 2 3 4 5 def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Tip: You can use Tab to navigate annotations. Annotations can be placed anywhere in a code block were a comment for the underlying language can be placed. Python # (1) JavaScript // (2) /* (2) */ Lua -- (3) Info Of course, this can be combined with line numbers , highlighting and all other code block related features. Adding line numbers \u00b6 Line numbers can be added to a code block by using the linenums=\"<start>\" option directly after the short name, whereas <start> represents the starting line number. A code block can start from a line number other than 1 , which allows splitting large code blocks for readability. Example : ``` python linenums=\"1\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` Result : 1 2 3 4 5 def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Highlighting specific lines \u00b6 Specific lines can be highlighted by passing the line numbers to the hl_lines argument placed right after the language short name. Note that line counts start at 1 , regardless of the starting line number specified as part of linenums . Example : ``` python hl_lines=\"2 3\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` Result : def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Highlighting inline code blocks \u00b6 Inline code blocks can be highlighted by prefixing them with a shebang-like sequence, i.e. #! , directly followed by the language short name . Example : The `#!python range()` function is used to generate a sequence of numbers. Result : The range () function is used to generate a sequence of numbers. Adding keyboard keys \u00b6 Keyboard keys can be rendered with a simple syntax. Consult the Python Markdown Extensions documentation to learn about all available key codes. Example : ++ctrl+alt+del++ Result : Ctrl + Alt + Del Embedding external files (Snippets) \u00b6 Also known as transcludes or file transclusion in MultiMarkdown . Snippets from other files can be embedded, which is especially useful to reference and embed the contents of source files directly into your project documentation. Example : ``` --8<--\u200b \".browserslistrc\" ``` Result : last 4 years The following is an example of a Javascript file that is in the ./docs/snippets directory, and it is named example.js . The syntax follows the same pattern as the example shown before (i.e. --8<-- followed by the qualified file name) Result : document $ . subscribe ( function () { var tables = document . querySelectorAll ( \"article table\" ) tables . forEach ( function ( table ) { new Tablesort ( table ) }) }) Note that the use of Snippets is not limited to code blocks, but can be used anywhere from a document to move repeating content to separate files.","title":"Code blocks"},{"location":"reference/code-blocks/#code-blocks","text":"Code blocks and examples are an essential part of technical project documentation. The examples included in this section can be copy/pasted into your edited page, to facilitate this feature's use.","title":"Code blocks"},{"location":"reference/code-blocks/#usage","text":"This section discusses how to use different syntax highlighting features.","title":"Usage"},{"location":"reference/code-blocks/#specifying-the-language","text":"Code blocks must be enclosed with two separate lines containing three backticks. To add code highlighting to those blocks, add the language short name directly after the opening block. See the list of available lexers to find the short name for a given language. Example : ``` python import tensorflow as tf ``` Result : import tensorflow as tf","title":"Specifying the language"},{"location":"reference/code-blocks/#adding-annotations","text":"Annotations offer a comfortable and friendly way to attach explanations to arbitrary sections of code blocks by adding simple markers within block/inline comments that refer to items of a list following the code block, i.e. (1) , (2) , etc. Material for MkDocs detaches the list from the flow of the document, injects the content of each list item into a tooltip, and links each list marker to the corresponding tooltip. In order to opt-in to annotation support, a slightly different syntax is required \u2013 just add the respective language short code and the .annotate class, after the three backticks. Note that annotations can be placed anywhere in a code block where a comment for the language can be placed, which for JavaScript is // (1) and /* (2) */ , for Yaml # (3) , etc. Example : ``` { .js .annotate } document$.subscribe(function() { // (1) var tables = document.querySelectorAll /* (2) */ tables.forEach(function(table) { new Tablesort(table) // (3) }) }) ``` 1. ... 2. ... Result : document $ . subscribe ( function () { // (1) var tables = document . querySelectorAll /* (2) */ tables . forEach ( function ( table ) { new Tablesort ( table ) // (3) }) }) Annotations can contain arbitrary content which is shown when the marker is focussed, including any kind of formatting, links, remarks, details, and even diagrams: 1 2 3 4 5 def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Tip: You can use Tab to navigate annotations. Annotations can be placed anywhere in a code block were a comment for the underlying language can be placed. Python # (1) JavaScript // (2) /* (2) */ Lua -- (3) Info Of course, this can be combined with line numbers , highlighting and all other code block related features.","title":"Adding annotations"},{"location":"reference/code-blocks/#adding-line-numbers","text":"Line numbers can be added to a code block by using the linenums=\"<start>\" option directly after the short name, whereas <start> represents the starting line number. A code block can start from a line number other than 1 , which allows splitting large code blocks for readability. Example : ``` python linenums=\"1\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` Result : 1 2 3 4 5 def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ]","title":"Adding line numbers"},{"location":"reference/code-blocks/#highlighting-specific-lines","text":"Specific lines can be highlighted by passing the line numbers to the hl_lines argument placed right after the language short name. Note that line counts start at 1 , regardless of the starting line number specified as part of linenums . Example : ``` python hl_lines=\"2 3\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` Result : def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ]","title":"Highlighting specific lines"},{"location":"reference/code-blocks/#highlighting-inline-code-blocks","text":"Inline code blocks can be highlighted by prefixing them with a shebang-like sequence, i.e. #! , directly followed by the language short name . Example : The `#!python range()` function is used to generate a sequence of numbers. Result : The range () function is used to generate a sequence of numbers.","title":"Highlighting inline code blocks"},{"location":"reference/code-blocks/#adding-keyboard-keys","text":"Keyboard keys can be rendered with a simple syntax. Consult the Python Markdown Extensions documentation to learn about all available key codes. Example : ++ctrl+alt+del++ Result : Ctrl + Alt + Del","title":"Adding keyboard keys"},{"location":"reference/code-blocks/#embedding-external-files-snippets","text":"Also known as transcludes or file transclusion in MultiMarkdown . Snippets from other files can be embedded, which is especially useful to reference and embed the contents of source files directly into your project documentation. Example : ``` --8<--\u200b \".browserslistrc\" ``` Result : last 4 years The following is an example of a Javascript file that is in the ./docs/snippets directory, and it is named example.js . The syntax follows the same pattern as the example shown before (i.e. --8<-- followed by the qualified file name) Result : document $ . subscribe ( function () { var tables = document . querySelectorAll ( \"article table\" ) tables . forEach ( function ( table ) { new Tablesort ( table ) }) }) Note that the use of Snippets is not limited to code blocks, but can be used anywhere from a document to move repeating content to separate files.","title":"Embedding external files (Snippets)"},{"location":"reference/content-tabs/","text":"Content tabs \u00b6 Sometimes, it's desirable to group alternative content under different tabs, e.g. when describing how to access an API from different languages or environments. Using the examples in this page allows for beautiful and functional tabs, grouping code blocks and other content. Usage \u00b6 Grouping code blocks \u00b6 Code blocks are one of the primary targets to be grouped, and can be considered a special case of content tabs, as tabs with a single code block are always rendered without horizontal spacing. Example : === \"C\" ``` c #include <stdio.h> int main(void) { printf(\"Hello world!\\n\"); return 0; } ``` === \"C++\" ``` c++ #include <iostream> int main(void) { std::cout << \"Hello world!\" << std::endl; return 0; } ``` Result : C #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); return 0 ; } C++ #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; } Grouping other content \u00b6 When a content tab contains more than one code block, it is rendered with horizontal spacing. Vertical spacing is never added, but can be achieved by nesting tabs in other blocks. Example : === \"Unordered list\" * Sed sagittis eleifend rutrum * Donec vitae suscipit est * Nulla tempor lobortis orci === \"Ordered list\" 1. Sed sagittis eleifend rutrum 2. Donec vitae suscipit est 3. Nulla tempor lobortis orci Result : Unordered list Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci Ordered list Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci Embedded content \u00b6 Content tabs can contain arbitrary nested content, including further content tabs, and can be nested in other blocks like remarks or blockquotes: Example : !!! example === \"Unordered List\" _Example_ : ``` markdown * Sed sagittis eleifend rutrum * Donec vitae suscipit est * Nulla tempor lobortis orci ``` _Result_: * Sed sagittis eleifend rutrum * Donec vitae suscipit est * Nulla tempor lobortis orci === \"Ordered List\" _Example_: ``` markdown 1. Sed sagittis eleifend rutrum 2. Donec vitae suscipit est 3. Nulla tempor lobortis orci ``` _Result_ : 1. Sed sagittis eleifend rutrum 2. Donec vitae suscipit est 3. Nulla tempor lobortis orci Result : Example Unordered List Example : * Sed sagittis eleifend rutrum * Donec vitae suscipit est * Nulla tempor lobortis orci Result : Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci Ordered List Example : 1. Sed sagittis eleifend rutrum 2. Donec vitae suscipit est 3. Nulla tempor lobortis orci Result : Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci","title":"Content tabs"},{"location":"reference/content-tabs/#content-tabs","text":"Sometimes, it's desirable to group alternative content under different tabs, e.g. when describing how to access an API from different languages or environments. Using the examples in this page allows for beautiful and functional tabs, grouping code blocks and other content.","title":"Content tabs"},{"location":"reference/content-tabs/#usage","text":"","title":"Usage"},{"location":"reference/content-tabs/#grouping-code-blocks","text":"Code blocks are one of the primary targets to be grouped, and can be considered a special case of content tabs, as tabs with a single code block are always rendered without horizontal spacing. Example : === \"C\" ``` c #include <stdio.h> int main(void) { printf(\"Hello world!\\n\"); return 0; } ``` === \"C++\" ``` c++ #include <iostream> int main(void) { std::cout << \"Hello world!\" << std::endl; return 0; } ``` Result : C #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); return 0 ; } C++ #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; }","title":"Grouping code blocks"},{"location":"reference/content-tabs/#grouping-other-content","text":"When a content tab contains more than one code block, it is rendered with horizontal spacing. Vertical spacing is never added, but can be achieved by nesting tabs in other blocks. Example : === \"Unordered list\" * Sed sagittis eleifend rutrum * Donec vitae suscipit est * Nulla tempor lobortis orci === \"Ordered list\" 1. Sed sagittis eleifend rutrum 2. Donec vitae suscipit est 3. Nulla tempor lobortis orci Result : Unordered list Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci Ordered list Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci","title":"Grouping other content"},{"location":"reference/content-tabs/#embedded-content","text":"Content tabs can contain arbitrary nested content, including further content tabs, and can be nested in other blocks like remarks or blockquotes: Example : !!! example === \"Unordered List\" _Example_ : ``` markdown * Sed sagittis eleifend rutrum * Donec vitae suscipit est * Nulla tempor lobortis orci ``` _Result_: * Sed sagittis eleifend rutrum * Donec vitae suscipit est * Nulla tempor lobortis orci === \"Ordered List\" _Example_: ``` markdown 1. Sed sagittis eleifend rutrum 2. Donec vitae suscipit est 3. Nulla tempor lobortis orci ``` _Result_ : 1. Sed sagittis eleifend rutrum 2. Donec vitae suscipit est 3. Nulla tempor lobortis orci Result : Example Unordered List Example : * Sed sagittis eleifend rutrum * Donec vitae suscipit est * Nulla tempor lobortis orci Result : Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci Ordered List Example : 1. Sed sagittis eleifend rutrum 2. Donec vitae suscipit est 3. Nulla tempor lobortis orci Result : Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci","title":"Embedded content"},{"location":"reference/data-tables/","text":"Data tables \u00b6 Data tables is an excellent way of rendering tabular data in project documentation. The data tables are sortable by default, by pressing on the title of the respective column. Usage \u00b6 Using data tables \u00b6 Data tables can be used at any position in your project documentation and can contain arbitrary Markdown, including inline code blocks, as well as icons and emojis . Example : | Method | Description | | ----------- | ------------------------------------ | | `GET` | :material-check: Fetch resource | | `PUT` | :material-check-all: Update resource | | `DELETE` | :material-close: Delete resource | Result : Method Description GET Fetch resource PUT Update resource DELETE Delete resource Column alignment \u00b6 If you want to align a specific column to the left , center or right , you can use the regular Markdown syntax placing : characters at the beginning and/or end of the divider. Left Example : | Method | Description | | :---------- | :----------------------------------- | | `GET` | :material-check: Fetch resource | | `PUT` | :material-check-all: Update resource | | `DELETE` | :material-close: Delete resource | Result : Method Description GET Fetch resource PUT Update resource DELETE Delete resource Center Example : | Method | Description | | :---------: | :----------------------------------: | | `GET` | :material-check: Fetch resource | | `PUT` | :material-check-all: Update resource | | `DELETE` | :material-close: Delete resource | Result : Method Description GET Fetch resource PUT Update resource DELETE Delete resource Right Example : | Method | Description | | ----------: | -----------------------------------: | | `GET` | :material-check: Fetch resource | | `PUT` | :material-check-all: Update resource | | `DELETE` | :material-close: Delete resource | Result : Method Description GET Fetch resource PUT Update resource DELETE Delete resource","title":"Data tables"},{"location":"reference/data-tables/#data-tables","text":"Data tables is an excellent way of rendering tabular data in project documentation. The data tables are sortable by default, by pressing on the title of the respective column.","title":"Data tables"},{"location":"reference/data-tables/#usage","text":"","title":"Usage"},{"location":"reference/data-tables/#using-data-tables","text":"Data tables can be used at any position in your project documentation and can contain arbitrary Markdown, including inline code blocks, as well as icons and emojis . Example : | Method | Description | | ----------- | ------------------------------------ | | `GET` | :material-check: Fetch resource | | `PUT` | :material-check-all: Update resource | | `DELETE` | :material-close: Delete resource | Result : Method Description GET Fetch resource PUT Update resource DELETE Delete resource","title":"Using data tables"},{"location":"reference/data-tables/#column-alignment","text":"If you want to align a specific column to the left , center or right , you can use the regular Markdown syntax placing : characters at the beginning and/or end of the divider. Left Example : | Method | Description | | :---------- | :----------------------------------- | | `GET` | :material-check: Fetch resource | | `PUT` | :material-check-all: Update resource | | `DELETE` | :material-close: Delete resource | Result : Method Description GET Fetch resource PUT Update resource DELETE Delete resource Center Example : | Method | Description | | :---------: | :----------------------------------: | | `GET` | :material-check: Fetch resource | | `PUT` | :material-check-all: Update resource | | `DELETE` | :material-close: Delete resource | Result : Method Description GET Fetch resource PUT Update resource DELETE Delete resource Right Example : | Method | Description | | ----------: | -----------------------------------: | | `GET` | :material-check: Fetch resource | | `PUT` | :material-check-all: Update resource | | `DELETE` | :material-close: Delete resource | Result : Method Description GET Fetch resource PUT Update resource DELETE Delete resource","title":"Column alignment"},{"location":"reference/diagrams/","text":"Diagrams \u00b6 Diagrams help to communicate complex relationships and interconnections between different technical components, and are a great addition to project documentation. This documentation system integrates with Mermaid.js , a very popular and flexible solution for drawing diagrams. Usage \u00b6 Using diagrams \u00b6 Mermaid diagrams are written as code blocks . They must be enclosed with two separate lines containing three backticks: Examples : Horizontal Flowcharts ``` mermaid graph LR A[Start] --> B{Error?}; B -->|Yes| C[Hmm...]; C --> D[Debug]; D --> B; B ---->|No| E[Yay!]; ``` Vertical Flowcharts ```mermaid graph TD A[Hard] -->|Text| B(Round) B --> C{Decision} C -->|One| D[Result 1] C -->|Two| E[Result 2] ``` Sequence Diagrams ```mermaid sequenceDiagram participant Alice participant Bob Alice->>John: Hello John, how are you? loop Healthcheck John->>John: Fight against hypochondria end Note right of John: Rational thoughts <br/>prevail! John-->>Alice: Great! John->>Bob: How about you? Bob-->>John: Jolly good! ``` Class Diagrams ```mermaid classDiagram Class01 <|-- AveryLongClass : Cool Class03 *-- Class04 Class05 o-- Class06 Class07 .. Class08 Class09 --> C2 : Where am i? Class09 --* C3 Class09 --|> Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla Class08 <--> C2: Cool label ``` Entity Relationships ```mermaid erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses ``` State Diagrams ` markdown mermaid stateDiagram [*] \u2192 First First \u2192 Second First \u2192 Third state First { [*] --> fir fir --> [*] } state Second { [*] --> sec sec --> [*] } state Third { [*] --> thi thi --> [*] } ``` ```` Results : Horizontal Flowcharts graph LR A[Start] --> B{Error?}; B -->|Yes| C[Hmm...]; C --> D[Debug]; D --> B; B ---->|No| E[Yay!]; Vertical Flowcharts graph TD A[Hard] -->|Text| B(Round) B --> C{Decision} C -->|One| D[Result 1] C -->|Two| E[Result 2] Sequence Diagrams sequenceDiagram participant Alice participant Bob Alice->>John: Hello John, how are you? loop Healthcheck John->>John: Fight against hypochondria end Note right of John: Rational thoughts <br/>prevail! John-->>Alice: Great! John->>Bob: How about you? Bob-->>John: Jolly good! Class Diagrams classDiagram Class01 <|-- AveryLongClass : Cool Class03 *-- Class04 Class05 o-- Class06 Class07 .. Class08 Class09 --> C2 : Where am i? Class09 --* C3 Class09 --|> Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla Class08 <--> C2: Cool label Entity Relationships erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses State Diagrams stateDiagram [*] --> First First --> Second First --> Third state First { [*] --> fir fir --> [*] } state Second { [*] --> sec sec --> [*] } state Third { [*] --> thi thi --> [*] } See the official documentation to learn about all available diagram types.","title":"Diagrams"},{"location":"reference/diagrams/#diagrams","text":"Diagrams help to communicate complex relationships and interconnections between different technical components, and are a great addition to project documentation. This documentation system integrates with Mermaid.js , a very popular and flexible solution for drawing diagrams.","title":"Diagrams"},{"location":"reference/diagrams/#usage","text":"","title":"Usage"},{"location":"reference/diagrams/#using-diagrams","text":"Mermaid diagrams are written as code blocks . They must be enclosed with two separate lines containing three backticks: Examples : Horizontal Flowcharts ``` mermaid graph LR A[Start] --> B{Error?}; B -->|Yes| C[Hmm...]; C --> D[Debug]; D --> B; B ---->|No| E[Yay!]; ``` Vertical Flowcharts ```mermaid graph TD A[Hard] -->|Text| B(Round) B --> C{Decision} C -->|One| D[Result 1] C -->|Two| E[Result 2] ``` Sequence Diagrams ```mermaid sequenceDiagram participant Alice participant Bob Alice->>John: Hello John, how are you? loop Healthcheck John->>John: Fight against hypochondria end Note right of John: Rational thoughts <br/>prevail! John-->>Alice: Great! John->>Bob: How about you? Bob-->>John: Jolly good! ``` Class Diagrams ```mermaid classDiagram Class01 <|-- AveryLongClass : Cool Class03 *-- Class04 Class05 o-- Class06 Class07 .. Class08 Class09 --> C2 : Where am i? Class09 --* C3 Class09 --|> Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla Class08 <--> C2: Cool label ``` Entity Relationships ```mermaid erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses ``` State Diagrams ` markdown mermaid stateDiagram [*] \u2192 First First \u2192 Second First \u2192 Third state First { [*] --> fir fir --> [*] } state Second { [*] --> sec sec --> [*] } state Third { [*] --> thi thi --> [*] } ``` ```` Results : Horizontal Flowcharts graph LR A[Start] --> B{Error?}; B -->|Yes| C[Hmm...]; C --> D[Debug]; D --> B; B ---->|No| E[Yay!]; Vertical Flowcharts graph TD A[Hard] -->|Text| B(Round) B --> C{Decision} C -->|One| D[Result 1] C -->|Two| E[Result 2] Sequence Diagrams sequenceDiagram participant Alice participant Bob Alice->>John: Hello John, how are you? loop Healthcheck John->>John: Fight against hypochondria end Note right of John: Rational thoughts <br/>prevail! John-->>Alice: Great! John->>Bob: How about you? Bob-->>John: Jolly good! Class Diagrams classDiagram Class01 <|-- AveryLongClass : Cool Class03 *-- Class04 Class05 o-- Class06 Class07 .. Class08 Class09 --> C2 : Where am i? Class09 --* C3 Class09 --|> Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla Class08 <--> C2: Cool label Entity Relationships erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses State Diagrams stateDiagram [*] --> First First --> Second First --> Third state First { [*] --> fir fir --> [*] } state Second { [*] --> sec sec --> [*] } state Third { [*] --> thi thi --> [*] } See the official documentation to learn about all available diagram types.","title":"Using diagrams"},{"location":"reference/footnotes/","text":"Footnotes \u00b6 Footnotes are a great way to add references to supplemental or additional information for a specific section of a document without interrupting the document flow. Using the methods described in this page, you have the ability to insert inline footnotes and render them at the bottom of the page. Usage \u00b6 Adding footnote references \u00b6 A footnote reference must be enclosed in square brackets and must start with a caret ^ , directly followed by an arbitrary identifier, which is similar to the standard Markdown link syntax. Example : Lorem ipsum[^1] dolor sit amet, consectetur adipiscing elit.[^2] Result : Lorem ipsum 1 dolor sit amet, consectetur adipiscing elit. 2 Adding footnote content \u00b6 The footnote content must be declared with the same identifier as the reference. It can be inserted at an arbitrary position in the document and is always rendered at the bottom of the page. Furthermore, a backlink to the footnote reference is automatically added. on a single line \u00b6 Short statements can be written on the same line. Example : [ ^1 ]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Result : Jump to footnote at the bottom of the page on multiple lines \u00b6 Paragraphs can be written on the next line and must be indented by four spaces. Example : [ ^2 ]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result : Jump to footnote at the bottom of the page Lorem ipsum dolor sit amet, consectetur adipiscing elit. \u21a9 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. \u21a9","title":"Footnotes"},{"location":"reference/footnotes/#footnotes","text":"Footnotes are a great way to add references to supplemental or additional information for a specific section of a document without interrupting the document flow. Using the methods described in this page, you have the ability to insert inline footnotes and render them at the bottom of the page.","title":"Footnotes"},{"location":"reference/footnotes/#usage","text":"","title":"Usage"},{"location":"reference/footnotes/#adding-footnote-references","text":"A footnote reference must be enclosed in square brackets and must start with a caret ^ , directly followed by an arbitrary identifier, which is similar to the standard Markdown link syntax. Example : Lorem ipsum[^1] dolor sit amet, consectetur adipiscing elit.[^2] Result : Lorem ipsum 1 dolor sit amet, consectetur adipiscing elit. 2","title":"Adding footnote references"},{"location":"reference/footnotes/#adding-footnote-content","text":"The footnote content must be declared with the same identifier as the reference. It can be inserted at an arbitrary position in the document and is always rendered at the bottom of the page. Furthermore, a backlink to the footnote reference is automatically added.","title":"Adding footnote content"},{"location":"reference/footnotes/#on-a-single-line","text":"Short statements can be written on the same line. Example : [ ^1 ]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Result : Jump to footnote at the bottom of the page","title":"on a single line"},{"location":"reference/footnotes/#on-multiple-lines","text":"Paragraphs can be written on the next line and must be indented by four spaces. Example : [ ^2 ]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result : Jump to footnote at the bottom of the page Lorem ipsum dolor sit amet, consectetur adipiscing elit. \u21a9 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. \u21a9","title":"on multiple lines"},{"location":"reference/formatting/","text":"Formatting \u00b6 There is support for several HTML elements that can be used to highlight sections of a document or apply specific formatting. Additionally, Critic Markup is supported, adding the ability to display suggested changes for a document. Usage \u00b6 Highlighting changes \u00b6 Critic Markup can be used, which adds the ability to highlight suggested changes , as well as add inline comments to a document: Example : Text can be {\u200b--deleted--} and replacement text {\u200b++added++}. This can also be combined into {\u200b~~one~>a single~~} operation. {\u200b==Highlighting==} is also possible {\u200b>>and comments can be added inline<<}. {\u200b== Formatting can also be applied to blocks, by putting the opening and closing tags on separate lines and adding new lines between the tags and the content. ==} Result : Text can be deleted and replacement text added . This can also be combined into one a single operation. Highlighting is also possible and comments can be added inline . Formatting can also be applied to blocks, by putting the opening and closing tags on separate lines and adding new lines between the tags and the content. Highlighting text \u00b6 Text can also be highlighted with a nicer syntax than using the corresponding mark , ins and del HTML tags: Example : - ==This was marked== - ^^This was inserted^^ - ~~This was deleted~~ Result : This was marked This was inserted This was deleted Sub- and superscripts \u00b6 Text can be sub- and superscripted with a nicer syntax than using the corresponding sub and sup HTML tags: Example : - H~2~0 - A^T^A Result : H 2 0 A T A","title":"Formatting"},{"location":"reference/formatting/#formatting","text":"There is support for several HTML elements that can be used to highlight sections of a document or apply specific formatting. Additionally, Critic Markup is supported, adding the ability to display suggested changes for a document.","title":"Formatting"},{"location":"reference/formatting/#usage","text":"","title":"Usage"},{"location":"reference/formatting/#highlighting-changes","text":"Critic Markup can be used, which adds the ability to highlight suggested changes , as well as add inline comments to a document: Example : Text can be {\u200b--deleted--} and replacement text {\u200b++added++}. This can also be combined into {\u200b~~one~>a single~~} operation. {\u200b==Highlighting==} is also possible {\u200b>>and comments can be added inline<<}. {\u200b== Formatting can also be applied to blocks, by putting the opening and closing tags on separate lines and adding new lines between the tags and the content. ==} Result : Text can be deleted and replacement text added . This can also be combined into one a single operation. Highlighting is also possible and comments can be added inline . Formatting can also be applied to blocks, by putting the opening and closing tags on separate lines and adding new lines between the tags and the content.","title":"Highlighting changes"},{"location":"reference/formatting/#highlighting-text","text":"Text can also be highlighted with a nicer syntax than using the corresponding mark , ins and del HTML tags: Example : - ==This was marked== - ^^This was inserted^^ - ~~This was deleted~~ Result : This was marked This was inserted This was deleted","title":"Highlighting text"},{"location":"reference/formatting/#sub-and-superscripts","text":"Text can be sub- and superscripted with a nicer syntax than using the corresponding sub and sup HTML tags: Example : - H~2~0 - A^T^A Result : H 2 0 A T A","title":"Sub- and superscripts"},{"location":"reference/icons-emojis/","text":"Icons + Emojis \u00b6 One of the best features of this documentation system is the possibility to use more than 8.000 icons and thousands of emojis in your project documentation with practically zero additional effort. Search for your perfect icon! \u00b6 Tip: Enter some keywords to find the perfect icon or emoji and click on the shortcode to copy it to your clipboard. The following icon sets are bundled with this package: \u2013 Material Design \u2013 FontAwesome \u2013 Octicons Usage \u00b6 Using emojis \u00b6 Emojis can be integrated in Markdown by putting the shortcode of the emoji between two colons. Example : :smile: Result : Using icons \u00b6 Icons can be used similar to emojis. These shortcodes reference the valid path to the bundled icons, which are located in the .icons directory, and replacing / with - : Example : - :material-account-circle: - :fontawesome-regular-laugh-wink: - :octicons-globe-24: Result : \u2013 .icons/material/account-circle.svg \u2013 .icons/fontawesome/regular/laugh-wink.svg \u2013 .icons/octicons/globe-24.svg with colors \u00b6 Custom CSS classes and attributes can be added to icons by suffixing the icon with a special syntax. While HTML and CSS allow to use inline styles , it's always best to add the CSS class to the additional stylesheet located in the docs/stylesheets directory: . medium { color : #00AB6C ; } . twitter { color : #1DA1F2 ; } . facebook { color : #4267B2 ; } Then, simply add the CSS class to the icon. .medium { color: #00AB6C; } .twitter { color: #1DA1F2; } .facebook { color: #4267B2; } Example : - :fontawesome-brands-medium:{ .medium } \u2013 Medium - :fontawesome-brands-twitter:{ .twitter } \u2013 Twitter - :fontawesome-brands-facebook:{ .facebook } \u2013 Facebook Result : \u2013 Medium \u2013 Twitter \u2013 Facebook with animations \u00b6 Similar to adding colors , it's just as easy to add CSS animations to icons by using the additional stylesheet located in the docs/stylesheets directory, defining a @ keyframes rule and adding the dedicated CSS class to the icon: @ keyframes heart { 0 %, 40 %, 80 %, 100 % { transform : scale ( 1 ); } 20 %, 60 % { transform : scale ( 1.15 ); } } . heart { animation : heart 1000 ms infinite ; } Then, simply add the CSS class to the icon. Example : :octicons-heart-fill-24:{ .heart } Result :","title":"Icons + Emojis"},{"location":"reference/icons-emojis/#icons-emojis","text":"One of the best features of this documentation system is the possibility to use more than 8.000 icons and thousands of emojis in your project documentation with practically zero additional effort.","title":"Icons + Emojis"},{"location":"reference/icons-emojis/#search-for-your-perfect-icon","text":"Tip: Enter some keywords to find the perfect icon or emoji and click on the shortcode to copy it to your clipboard. The following icon sets are bundled with this package: \u2013 Material Design \u2013 FontAwesome \u2013 Octicons","title":"Search for your perfect icon!"},{"location":"reference/icons-emojis/#usage","text":"","title":"Usage"},{"location":"reference/icons-emojis/#using-emojis","text":"Emojis can be integrated in Markdown by putting the shortcode of the emoji between two colons. Example : :smile: Result :","title":"Using emojis"},{"location":"reference/icons-emojis/#using-icons","text":"Icons can be used similar to emojis. These shortcodes reference the valid path to the bundled icons, which are located in the .icons directory, and replacing / with - : Example : - :material-account-circle: - :fontawesome-regular-laugh-wink: - :octicons-globe-24: Result : \u2013 .icons/material/account-circle.svg \u2013 .icons/fontawesome/regular/laugh-wink.svg \u2013 .icons/octicons/globe-24.svg","title":"Using icons"},{"location":"reference/icons-emojis/#with-colors","text":"Custom CSS classes and attributes can be added to icons by suffixing the icon with a special syntax. While HTML and CSS allow to use inline styles , it's always best to add the CSS class to the additional stylesheet located in the docs/stylesheets directory: . medium { color : #00AB6C ; } . twitter { color : #1DA1F2 ; } . facebook { color : #4267B2 ; } Then, simply add the CSS class to the icon. .medium { color: #00AB6C; } .twitter { color: #1DA1F2; } .facebook { color: #4267B2; } Example : - :fontawesome-brands-medium:{ .medium } \u2013 Medium - :fontawesome-brands-twitter:{ .twitter } \u2013 Twitter - :fontawesome-brands-facebook:{ .facebook } \u2013 Facebook Result : \u2013 Medium \u2013 Twitter \u2013 Facebook","title":"with colors"},{"location":"reference/icons-emojis/#with-animations","text":"Similar to adding colors , it's just as easy to add CSS animations to icons by using the additional stylesheet located in the docs/stylesheets directory, defining a @ keyframes rule and adding the dedicated CSS class to the icon: @ keyframes heart { 0 %, 40 %, 80 %, 100 % { transform : scale ( 1 ); } 20 %, 60 % { transform : scale ( 1.15 ); } } . heart { animation : heart 1000 ms infinite ; } Then, simply add the CSS class to the icon. Example : :octicons-heart-fill-24:{ .heart } Result :","title":"with animations"},{"location":"reference/images/","text":"Images \u00b6 While images are first-class citizens of Markdown and part of the core syntax, it can be difficult to work with them. This documentation system makes working with images more comfortable by providing styles for alignment and image captions. Usage \u00b6 Image alignment \u00b6 Images can be aligned by adding the respective alignment directions via the align attribute, i.e. align=left or align=right Left Example : ![ Placeholder ]( https://dummyimage.com/600x400/eee/aaa ){ align=left } Result : Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Center Example : ![ Placeholder ]( https://dummyimage.com/600x400/eee/aaa ){:.center } Result : Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Right Example : ![ Placeholder ]( https://dummyimage.com/600x400/eee/aaa ){ align=right } Result : Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. If there's insufficient space to render the text next to the image, the image will stretch to the full width of the viewport, e.g. on mobile viewports. Image captions \u00b6 Sadly, the Markdown syntax doesn't provide native support for image captions, but it's always possible to resort to HTML. Using figure and figcaption , captions can be added to images. Example : < figure > < img src = \"https://dummyimage.com/600x400/eee/aaa\" width = \"300\" > < figcaption > Image caption </ figcaption > </ figure > Result : Image caption Image lazy-loading \u00b6 Modern browsers provide native support for lazy-loading images through the loading attribute, which degrades to eager-loading in browsers without support. Images can be lazy-loaded by adding loading=lazy . Example : ![ Placeholder ]( https://dummyimage.com/600x400/eee/aaa ){ loading=lazy } Result :","title":"Images"},{"location":"reference/images/#images","text":"While images are first-class citizens of Markdown and part of the core syntax, it can be difficult to work with them. This documentation system makes working with images more comfortable by providing styles for alignment and image captions.","title":"Images"},{"location":"reference/images/#usage","text":"","title":"Usage"},{"location":"reference/images/#image-alignment","text":"Images can be aligned by adding the respective alignment directions via the align attribute, i.e. align=left or align=right Left Example : ![ Placeholder ]( https://dummyimage.com/600x400/eee/aaa ){ align=left } Result : Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Center Example : ![ Placeholder ]( https://dummyimage.com/600x400/eee/aaa ){:.center } Result : Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Right Example : ![ Placeholder ]( https://dummyimage.com/600x400/eee/aaa ){ align=right } Result : Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. If there's insufficient space to render the text next to the image, the image will stretch to the full width of the viewport, e.g. on mobile viewports.","title":"Image alignment"},{"location":"reference/images/#image-captions","text":"Sadly, the Markdown syntax doesn't provide native support for image captions, but it's always possible to resort to HTML. Using figure and figcaption , captions can be added to images. Example : < figure > < img src = \"https://dummyimage.com/600x400/eee/aaa\" width = \"300\" > < figcaption > Image caption </ figcaption > </ figure > Result : Image caption","title":"Image captions"},{"location":"reference/images/#image-lazy-loading","text":"Modern browsers provide native support for lazy-loading images through the loading attribute, which degrades to eager-loading in browsers without support. Images can be lazy-loaded by adding loading=lazy . Example : ![ Placeholder ]( https://dummyimage.com/600x400/eee/aaa ){ loading=lazy } Result :","title":"Image lazy-loading"},{"location":"reference/installation/","text":"Getting Started \u00b6 Introduction \u00b6 Welcome to Zignar Technologies Documentation application. In this application documents can be created, edited and published. The documents in this application are written in simple Markdown language, as it is widely used in many websites around the world. Markdown is easy to use and easy to master. Markdown files with extension .md can be stored in any place inside the /docs folder or in subdirectories of that folder (i.e. /docs/projects ), and the documentation system will automatically parse the new document and create the required links in the menu structure. . \u2514\u2500 docs/ \u251c\u2500 index.md \u251c\u2500projects/ \u251c\u2500 your_page.md \u251c\u2500 some_other_page.md \u2514\u2500 some_other_directory/ Documents and Directories can be directly edited in the wiki GitHub repository by pressing the icon at the top right corner of the page. Also, documents can be edited locally by cloning the git repository. To achieve this the following command can be used: git clone https://github.com/Zignar-Technologies/wiki.git Once the repository has been cloned or pulled, folders and markdown files can be added to the /docs directory structure, and later committed back on GitHub. Previewing as you write \u00b6 Because the documentation system is based on Markdown files, any editor like VSCode or Atom can be used to preview your document as you write. However, the extended syntax that is used which provides better code blocks, content tabs, etc., will not be displayed fully. To achieve this, a live preview server that can also be accessed locally with a Web Browser, so that changes can be previewed as the documentation is written. The server will automatically rebuild the site upon saving your document. This server can be run directly by building a Docker image and running it. Installation \u00b6 with docker \u00b6 To run the local preview server with docker: 1 2 cd wiki docker build -t zignardocs . After the image is built, the server can be started it with the following command: Unix, Powershell, macOS 1 docker run -itd -p 8000 :8000 --name ZignarDocs -v ${ PWD } :/docs zignardocs Windows 1 docker run -itd -p 8000 :8000 --name ZignarDocs -v %cd%:/docs zignardocs Now, the live server can be accessed from a local browser at address localhost:8000 Publishing your changes \u00b6 The great thing about hosting project documentation in a git repository is the ability to deploy it automatically when new changes are committed. As the code is already on GitHub Pages , it's certainly the most convenient way to publish the project documentation and it's free of charge. GitHub Actions \u00b6 A GitHub workflow runs every time that the files in the repository are created or changed, automatically publishing the changes to the docs.zignar.io website. This automates the deployment of the project documentation. When a new commit is pushed to the main branch, the static site is automatically built and deployed.","title":"Installation Guide"},{"location":"reference/installation/#getting-started","text":"","title":"Getting Started"},{"location":"reference/installation/#introduction","text":"Welcome to Zignar Technologies Documentation application. In this application documents can be created, edited and published. The documents in this application are written in simple Markdown language, as it is widely used in many websites around the world. Markdown is easy to use and easy to master. Markdown files with extension .md can be stored in any place inside the /docs folder or in subdirectories of that folder (i.e. /docs/projects ), and the documentation system will automatically parse the new document and create the required links in the menu structure. . \u2514\u2500 docs/ \u251c\u2500 index.md \u251c\u2500projects/ \u251c\u2500 your_page.md \u251c\u2500 some_other_page.md \u2514\u2500 some_other_directory/ Documents and Directories can be directly edited in the wiki GitHub repository by pressing the icon at the top right corner of the page. Also, documents can be edited locally by cloning the git repository. To achieve this the following command can be used: git clone https://github.com/Zignar-Technologies/wiki.git Once the repository has been cloned or pulled, folders and markdown files can be added to the /docs directory structure, and later committed back on GitHub.","title":"Introduction"},{"location":"reference/installation/#previewing-as-you-write","text":"Because the documentation system is based on Markdown files, any editor like VSCode or Atom can be used to preview your document as you write. However, the extended syntax that is used which provides better code blocks, content tabs, etc., will not be displayed fully. To achieve this, a live preview server that can also be accessed locally with a Web Browser, so that changes can be previewed as the documentation is written. The server will automatically rebuild the site upon saving your document. This server can be run directly by building a Docker image and running it.","title":"Previewing as you write"},{"location":"reference/installation/#installation","text":"","title":"Installation"},{"location":"reference/installation/#with-docker","text":"To run the local preview server with docker: 1 2 cd wiki docker build -t zignardocs . After the image is built, the server can be started it with the following command: Unix, Powershell, macOS 1 docker run -itd -p 8000 :8000 --name ZignarDocs -v ${ PWD } :/docs zignardocs Windows 1 docker run -itd -p 8000 :8000 --name ZignarDocs -v %cd%:/docs zignardocs Now, the live server can be accessed from a local browser at address localhost:8000","title":"with docker"},{"location":"reference/installation/#publishing-your-changes","text":"The great thing about hosting project documentation in a git repository is the ability to deploy it automatically when new changes are committed. As the code is already on GitHub Pages , it's certainly the most convenient way to publish the project documentation and it's free of charge.","title":"Publishing your changes"},{"location":"reference/installation/#github-actions","text":"A GitHub workflow runs every time that the files in the repository are created or changed, automatically publishing the changes to the docs.zignar.io website. This automates the deployment of the project documentation. When a new commit is pushed to the main branch, the static site is automatically built and deployed.","title":"GitHub Actions"},{"location":"reference/lists/","text":"Lists \u00b6 We support several flavors of lists that cater to different use cases, including unordered lists and ordered lists , which are supported through standard Markdown, as well as definition lists and task lists , which are supported through extensions. Usage \u00b6 Using unordered lists \u00b6 An unordered list can be written by prefixing a line with a - , * or + list marker, all of which can be used interchangeably. Furthermore, all flavors of lists can be nested inside each other. Example : - Nulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh lacinia sed. Aenean in finibus diam. * Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. * Nam vulputate tincidunt fringilla. * Nullam dignissim ultrices urna non auctor. Result : Nulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh lacinia sed. Aenean in finibus diam. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Using ordered lists \u00b6 An ordered list must start with a number immediately followed by a dot. The numbers do not need to be consecutive and can be all set to 1. , as they will be re-numbered when rendered. Example : 1. Vivamus id mi enim. Integer id turpis sapien. Ut condimentum lobortis sagittis. Aliquam purus tellus, faucibus eget urna at, iaculis venenatis nulla. Vivamus a pharetra leo. 1. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a ultricies libero efficitur sed. 2. Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. 1. Mauris dictum mi lacus 2. Ut sit amet placerat ante 3. Suspendisse ac eros arcu Result : Vivamus id mi enim. Integer id turpis sapien. Ut condimentum lobortis sagittis. Aliquam purus tellus, faucibus eget urna at, iaculis venenatis nulla. Vivamus a pharetra leo. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a ultricies libero efficitur sed. Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Mauris dictum mi lacus Ut sit amet placerat ante Suspendisse ac eros arcu Using definition lists \u00b6 Definition lists are a ideal for describing arbitrary key-value pairs, e.g. the parameters of functions or modules. Example : `Lorem ipsum dolor sit amet` : Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. `Cras arcu libero` : Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Result : Lorem ipsum dolor sit amet Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Cras arcu libero Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Using tasklists \u00b6 Unordered list items can be prefixed with [ ] to render an unchecked or [x] to render a checked checkbox. Example : - [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit - [ ] Vestibulum convallis sit amet nisi a tincidunt * [x] In hac habitasse platea dictumst * [x] In scelerisque nibh non dolor mollis congue sed et metus * [ ] Praesent sed risus massa - [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque Result : Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque","title":"Lists"},{"location":"reference/lists/#lists","text":"We support several flavors of lists that cater to different use cases, including unordered lists and ordered lists , which are supported through standard Markdown, as well as definition lists and task lists , which are supported through extensions.","title":"Lists"},{"location":"reference/lists/#usage","text":"","title":"Usage"},{"location":"reference/lists/#using-unordered-lists","text":"An unordered list can be written by prefixing a line with a - , * or + list marker, all of which can be used interchangeably. Furthermore, all flavors of lists can be nested inside each other. Example : - Nulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh lacinia sed. Aenean in finibus diam. * Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. * Nam vulputate tincidunt fringilla. * Nullam dignissim ultrices urna non auctor. Result : Nulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh lacinia sed. Aenean in finibus diam. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor.","title":"Using unordered lists"},{"location":"reference/lists/#using-ordered-lists","text":"An ordered list must start with a number immediately followed by a dot. The numbers do not need to be consecutive and can be all set to 1. , as they will be re-numbered when rendered. Example : 1. Vivamus id mi enim. Integer id turpis sapien. Ut condimentum lobortis sagittis. Aliquam purus tellus, faucibus eget urna at, iaculis venenatis nulla. Vivamus a pharetra leo. 1. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a ultricies libero efficitur sed. 2. Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. 1. Mauris dictum mi lacus 2. Ut sit amet placerat ante 3. Suspendisse ac eros arcu Result : Vivamus id mi enim. Integer id turpis sapien. Ut condimentum lobortis sagittis. Aliquam purus tellus, faucibus eget urna at, iaculis venenatis nulla. Vivamus a pharetra leo. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a ultricies libero efficitur sed. Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Mauris dictum mi lacus Ut sit amet placerat ante Suspendisse ac eros arcu","title":"Using ordered lists"},{"location":"reference/lists/#using-definition-lists","text":"Definition lists are a ideal for describing arbitrary key-value pairs, e.g. the parameters of functions or modules. Example : `Lorem ipsum dolor sit amet` : Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. `Cras arcu libero` : Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Result : Lorem ipsum dolor sit amet Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Cras arcu libero Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor.","title":"Using definition lists"},{"location":"reference/lists/#using-tasklists","text":"Unordered list items can be prefixed with [ ] to render an unchecked or [x] to render a checked checkbox. Example : - [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit - [ ] Vestibulum convallis sit amet nisi a tincidunt * [x] In hac habitasse platea dictumst * [x] In scelerisque nibh non dolor mollis congue sed et metus * [ ] Praesent sed risus massa - [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque Result : Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque","title":"Using tasklists"},{"location":"reference/mathjax/","text":"MathJax \u00b6 MathJax is a beautiful and accessible way to display mathematical content in the browser, allows for writing formulas in different notations, including LaTeX , MathML and AsciiMath , and can be easily integrated with Material for MkDocs. Usage \u00b6 To allow MathJax formulas loading correctly, the corresponding JavaScript libraries must be loaded before the page is created. Therefore, it is necessary to add the following JavaScript to the top of the page that is being created s: < script src = \"/javascripts/mathjax.js\" async ></ script > Info Once the libraries are loaded on to the page, standard MathJax notation can be used. Using block syntax \u00b6 Blocks must be enclosed in $$ ... $$ or \\[ ... \\] on separate lines: Example : $$ \\operatorname {ker} f = \\{ g \\in G:f ( g )= e_{H} \\} { \\mbox {.}} $$ Result : \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\] Using inline block syntax \u00b6 Inline blocks must be enclosed in $ ... $ or \\( ... \\) : Example : The homomorphism $ f $ is injective if and only if its kernel is only the singleton set $ e_G $ , because otherwise $ \\exists a,b \\in G $ with $ a \\neq b $ such that $ f ( a )= f ( b ) $ . Result : The homomorphism \\(f\\) is injective if and only if its kernel is only the singleton set \\(e_G\\) , because otherwise \\(\\exists a,b\\in G\\) with \\(a\\neq b\\) such that \\(f(a)=f(b)\\) .","title":"MathJax"},{"location":"reference/mathjax/#mathjax","text":"MathJax is a beautiful and accessible way to display mathematical content in the browser, allows for writing formulas in different notations, including LaTeX , MathML and AsciiMath , and can be easily integrated with Material for MkDocs.","title":"MathJax"},{"location":"reference/mathjax/#usage","text":"To allow MathJax formulas loading correctly, the corresponding JavaScript libraries must be loaded before the page is created. Therefore, it is necessary to add the following JavaScript to the top of the page that is being created s: < script src = \"/javascripts/mathjax.js\" async ></ script > Info Once the libraries are loaded on to the page, standard MathJax notation can be used.","title":"Usage"},{"location":"reference/mathjax/#using-block-syntax","text":"Blocks must be enclosed in $$ ... $$ or \\[ ... \\] on separate lines: Example : $$ \\operatorname {ker} f = \\{ g \\in G:f ( g )= e_{H} \\} { \\mbox {.}} $$ Result : \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\]","title":"Using block syntax"},{"location":"reference/mathjax/#using-inline-block-syntax","text":"Inline blocks must be enclosed in $ ... $ or \\( ... \\) : Example : The homomorphism $ f $ is injective if and only if its kernel is only the singleton set $ e_G $ , because otherwise $ \\exists a,b \\in G $ with $ a \\neq b $ such that $ f ( a )= f ( b ) $ . Result : The homomorphism \\(f\\) is injective if and only if its kernel is only the singleton set \\(e_G\\) , because otherwise \\(\\exists a,b\\in G\\) with \\(a\\neq b\\) such that \\(f(a)=f(b)\\) .","title":"Using inline block syntax"},{"location":"reference/pdf/","text":"PDF Files Support \u00b6 Markdown itself doesn't have a mechanism for embedding a PDF. However, Markdown accepts raw HTML in its input and passes it through unaltered. So the question you might want to ask is: How to you embed a PDF in HTML? In other words, what HTML would one use to have a browser display a PDF embedded in an HTML page? You would just include that HTML in your Markdown document: Example : 1 2 3 4 5 < object data = \"../assets/sample.pdf\" type = \"application/pdf\" style = \"min-height:100vh;width:100%\" > < embed src = \"../assets/sample.pdf\" > < p > This browser does not support PDFs. Please download the PDF to view it: < a href = \"../assets/sample.pdf\" > Download PDF </ a > . </ p > </ embed > </ object > Result : This browser does not support PDFs. Please download the PDF to view it: Download PDF .","title":"PDF Files Support"},{"location":"reference/pdf/#pdf-files-support","text":"Markdown itself doesn't have a mechanism for embedding a PDF. However, Markdown accepts raw HTML in its input and passes it through unaltered. So the question you might want to ask is: How to you embed a PDF in HTML? In other words, what HTML would one use to have a browser display a PDF embedded in an HTML page? You would just include that HTML in your Markdown document: Example : 1 2 3 4 5 < object data = \"../assets/sample.pdf\" type = \"application/pdf\" style = \"min-height:100vh;width:100%\" > < embed src = \"../assets/sample.pdf\" > < p > This browser does not support PDFs. Please download the PDF to view it: < a href = \"../assets/sample.pdf\" > Download PDF </ a > . </ p > </ embed > </ object > Result : This browser does not support PDFs. Please download the PDF to view it: Download PDF .","title":"PDF Files Support"},{"location":"reference/progress/","text":"Progress Bar \u00b6 ProgressBar is an extension that adds support for progress/status bars. It can take percentages or fractions, and it can optionally generate classes for percentages at specific value levels. The basic syntax for progress bars is: [= <percentage or fraction> \"optional single or double quoted title\"] . The opening [ can be followed by one or more = characters. After the = char(s) the percentage is specified as either a fraction or percentage and can optionally be followed by a title surrounded in either double quotes or single quotes. Progress Bar Example Output 0% 5% 25% 45% 65% 85% 100% Markdown [=0% \"0%\"] [=5% \"5%\"] [=25% \"25%\"] [=45% \"45%\"] [=65% \"65%\"] [=85% \"85%\"] [=100% \"100%\"] Progress Bar with Attributes Output 85% 100% Markdown [=85% \"85%\"]{: .candystripe} [=100% \"100%\"]{: .candystripe} [=0%]{: .thin} [=5%]{: .thin} [=25%]{: .thin} [=45%]{: .thin} [=65%]{: .thin} [=85%]{: .thin} [=100%]{: .thin}","title":"Progress Bar"},{"location":"reference/progress/#progress-bar","text":"ProgressBar is an extension that adds support for progress/status bars. It can take percentages or fractions, and it can optionally generate classes for percentages at specific value levels. The basic syntax for progress bars is: [= <percentage or fraction> \"optional single or double quoted title\"] . The opening [ can be followed by one or more = characters. After the = char(s) the percentage is specified as either a fraction or percentage and can optionally be followed by a title surrounded in either double quotes or single quotes. Progress Bar Example Output 0% 5% 25% 45% 65% 85% 100% Markdown [=0% \"0%\"] [=5% \"5%\"] [=25% \"25%\"] [=45% \"45%\"] [=65% \"65%\"] [=85% \"85%\"] [=100% \"100%\"] Progress Bar with Attributes Output 85% 100% Markdown [=85% \"85%\"]{: .candystripe} [=100% \"100%\"]{: .candystripe} [=0%]{: .thin} [=5%]{: .thin} [=25%]{: .thin} [=45%]{: .thin} [=65%]{: .thin} [=85%]{: .thin} [=100%]{: .thin}","title":"Progress Bar"},{"location":"reference/remarks/","text":"Remarks \u00b6 Remarks, also known as call-outs , are an excellent choice for including side content without significantly interrupting the document flow. Several different types of remarkss can be used, which also include nesting of arbitrary content. Usage \u00b6 Remarks follow a simple syntax: a block must start with !!! , followed by a single keyword which is used as the type qualifier of the block. The content of the block then follows on the next line, indented by four spaces. Example : !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result : Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Changing the title \u00b6 By default, the title will equal the type qualifier in titlecase. However, it can be changed by adding a quoted string containing valid Markdown (including links, formatting, ...) after the type qualifier. Example : !!! note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result : Phasellus posuere in sem ut cursus Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Removing the title \u00b6 Similar to changing the title , the icon and title can be omitted entirely by adding an empty string directly after the type qualifier. Note that this will not work for collapsible blocks . Example : !!! note \"\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result : Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Embedded content \u00b6 Remarks can contain all kinds of text content, including headlines, lists, paragraphs and other blocks. Example : !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. ``` python def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` Nunc eu odio eleifend, blandit leo a, volutpat sapien. Phasellus posuere in sem ut cursus. Nullam sit amet tincidunt ipsum, sit amet elementum turpis. Etiam ipsum quam, mattis in purus vitae, lacinia fermentum enim. Result : Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Nunc eu odio eleifend, blandit leo a, volutpat sapien. Phasellus posuere in sem ut cursus. Nullam sit amet tincidunt ipsum, sit amet elementum turpis. Etiam ipsum quam, mattis in purus vitae, lacinia fermentum enim. Collapsible blocks \u00b6 Collapsible remark blocks are useful for FAQs or content that is of secondary nature. A details block follows the syntax and semantics of remark blocks, but must start with ??? . Example : ??? note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result : Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Adding a + after ??? will render the block as open on page load: Example : ???+ note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result : Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Inline blocks \u00b6 Remarks can also be rendered as inline blocks (i.e. sidebars), placing them to the right using the inline + end modifiers, or to the left using only the inline modifier. Important : Remarks that use the inline modifiers must be declared prior to the content block you want to place them beside. If there's insufficient space to render the remark next to the block, the remark will stretch to the full width of the viewport, e.g. on mobile viewports. inline end Example / Result : Info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. !!! info inline end Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Use inline end to align to the right (left for rtl languages). inline Example / Result : Info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. !!! info inline Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Use inline to align to the left (right for rtl languages). Supported types \u00b6 Following is a list of type qualifiers provided by Material for MkDocs, whereas the default type, and thus fallback for unknown type qualifiers, is note : note Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. abstract , summary , tldr Abstract Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. info , todo Info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. tip , hint , important Tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. success , check , done Success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. question , help , faq Question Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. warning , caution , attention Warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. failure , fail , missing Failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. danger , error Danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. bug Bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. example Example Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. quote , cite Quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Remarks"},{"location":"reference/remarks/#remarks","text":"Remarks, also known as call-outs , are an excellent choice for including side content without significantly interrupting the document flow. Several different types of remarkss can be used, which also include nesting of arbitrary content.","title":"Remarks"},{"location":"reference/remarks/#usage","text":"Remarks follow a simple syntax: a block must start with !!! , followed by a single keyword which is used as the type qualifier of the block. The content of the block then follows on the next line, indented by four spaces. Example : !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result : Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Usage"},{"location":"reference/remarks/#changing-the-title","text":"By default, the title will equal the type qualifier in titlecase. However, it can be changed by adding a quoted string containing valid Markdown (including links, formatting, ...) after the type qualifier. Example : !!! note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result : Phasellus posuere in sem ut cursus Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Changing the title"},{"location":"reference/remarks/#removing-the-title","text":"Similar to changing the title , the icon and title can be omitted entirely by adding an empty string directly after the type qualifier. Note that this will not work for collapsible blocks . Example : !!! note \"\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result : Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Removing the title"},{"location":"reference/remarks/#embedded-content","text":"Remarks can contain all kinds of text content, including headlines, lists, paragraphs and other blocks. Example : !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. ``` python def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` Nunc eu odio eleifend, blandit leo a, volutpat sapien. Phasellus posuere in sem ut cursus. Nullam sit amet tincidunt ipsum, sit amet elementum turpis. Etiam ipsum quam, mattis in purus vitae, lacinia fermentum enim. Result : Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Nunc eu odio eleifend, blandit leo a, volutpat sapien. Phasellus posuere in sem ut cursus. Nullam sit amet tincidunt ipsum, sit amet elementum turpis. Etiam ipsum quam, mattis in purus vitae, lacinia fermentum enim.","title":"Embedded content"},{"location":"reference/remarks/#collapsible-blocks","text":"Collapsible remark blocks are useful for FAQs or content that is of secondary nature. A details block follows the syntax and semantics of remark blocks, but must start with ??? . Example : ??? note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result : Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Adding a + after ??? will render the block as open on page load: Example : ???+ note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result : Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Collapsible blocks"},{"location":"reference/remarks/#inline-blocks","text":"Remarks can also be rendered as inline blocks (i.e. sidebars), placing them to the right using the inline + end modifiers, or to the left using only the inline modifier. Important : Remarks that use the inline modifiers must be declared prior to the content block you want to place them beside. If there's insufficient space to render the remark next to the block, the remark will stretch to the full width of the viewport, e.g. on mobile viewports. inline end Example / Result : Info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. !!! info inline end Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Use inline end to align to the right (left for rtl languages). inline Example / Result : Info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. !!! info inline Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Use inline to align to the left (right for rtl languages).","title":"Inline blocks"},{"location":"reference/remarks/#supported-types","text":"Following is a list of type qualifiers provided by Material for MkDocs, whereas the default type, and thus fallback for unknown type qualifiers, is note : note Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. abstract , summary , tldr Abstract Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. info , todo Info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. tip , hint , important Tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. success , check , done Success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. question , help , faq Question Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. warning , caution , attention Warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. failure , fail , missing Failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. danger , error Danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. bug Bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. example Example Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. quote , cite Quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Supported types"},{"location":"reference/smartsymbols/","text":"Smart symbols \u00b6 SmartSymbols adds syntax for creating special characters such as trademarks, arrows, fractions, etc. It basically allows for more \"smarty-pants\" like replacements. Markdown Result (tm) \u2122 (c) \u00a9 (r) \u00ae c/o \u2105 +/- \u00b1 --> \u2192 <-- \u2190 <--> \u2194 =/= \u2260 1/4, etc. \u00bc, etc. 1st 2nd etc. 1 st 2 nd etc.","title":"Smart symbols"},{"location":"reference/smartsymbols/#smart-symbols","text":"SmartSymbols adds syntax for creating special characters such as trademarks, arrows, fractions, etc. It basically allows for more \"smarty-pants\" like replacements. Markdown Result (tm) \u2122 (c) \u00a9 (r) \u00ae c/o \u2105 +/- \u00b1 --> \u2192 <-- \u2190 <--> \u2194 =/= \u2260 1/4, etc. \u00bc, etc. 1st 2nd etc. 1 st 2 nd etc.","title":"Smart symbols"},{"location":"reference/stl/","text":"STL Files Support \u00b6 Markdown itself doesn't have a mechanism for embedding an STL File. However, Markdown accepts raw HTML in its input and passes it through unaltered. So the question you might want to ask is: How to you embed an STL in HTML? In other words, what HTML would one use to have a browser display an STL embedded in an HTML page? You would just include that HTML in your Markdown document: Example : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 < script src = \"/javascripts/stl_viewer/stl_viewer.min.js\" ></ script > < div id = \"stl_cont\" style = \"width:500px;height:500px;margin:100 auto;\" ></ div > < script > var stl_viewer = new StlViewer ( document . getElementById ( \"stl_cont\" ), { auto_rotate : true , auto_resize : false , zoom : 4 , bgcolor : \"#20FAAC\" , allow_drag_and_drop : true , models : [ { filename : \"../../reference/assets/sample.stl\" }] } ); </ script > Result : var stl_viewer=new StlViewer ( document.getElementById(\"stl_cont\"), { auto_rotate:true, auto_resize: false, zoom: 4, bgcolor:\"#20FAAC\", allow_drag_and_drop:true, models: [ {filename:\"../../reference/assets/sample.stl\"}] } ); Javascript STL/OBJ 3D files Viewer \u00b6 This Plugin is highly customizable. Further instructions on how to use it can be found here . Reads binary/ASCII STL files; OBJ files Supports multiple 3D files at the same container Set model's size, position, color, rotation and some basic animation Supports user's drag&drop Model click events Model information (size, volume, surface area etc.) Add existing meshes into scene Supports WebGL - falls back to HTML5 Canvas Supports multiple Stl Viewer instances at the same page Easy usage - as much as one line of Javascript code Stand alone code - independent of external services/websites","title":"STL Files Support"},{"location":"reference/stl/#stl-files-support","text":"Markdown itself doesn't have a mechanism for embedding an STL File. However, Markdown accepts raw HTML in its input and passes it through unaltered. So the question you might want to ask is: How to you embed an STL in HTML? In other words, what HTML would one use to have a browser display an STL embedded in an HTML page? You would just include that HTML in your Markdown document: Example : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 < script src = \"/javascripts/stl_viewer/stl_viewer.min.js\" ></ script > < div id = \"stl_cont\" style = \"width:500px;height:500px;margin:100 auto;\" ></ div > < script > var stl_viewer = new StlViewer ( document . getElementById ( \"stl_cont\" ), { auto_rotate : true , auto_resize : false , zoom : 4 , bgcolor : \"#20FAAC\" , allow_drag_and_drop : true , models : [ { filename : \"../../reference/assets/sample.stl\" }] } ); </ script > Result : var stl_viewer=new StlViewer ( document.getElementById(\"stl_cont\"), { auto_rotate:true, auto_resize: false, zoom: 4, bgcolor:\"#20FAAC\", allow_drag_and_drop:true, models: [ {filename:\"../../reference/assets/sample.stl\"}] } );","title":"STL Files Support"},{"location":"reference/stl/#javascript-stlobj-3d-files-viewer","text":"This Plugin is highly customizable. Further instructions on how to use it can be found here . Reads binary/ASCII STL files; OBJ files Supports multiple 3D files at the same container Set model's size, position, color, rotation and some basic animation Supports user's drag&drop Model click events Model information (size, volume, surface area etc.) Add existing meshes into scene Supports WebGL - falls back to HTML5 Canvas Supports multiple Stl Viewer instances at the same page Easy usage - as much as one line of Javascript code Stand alone code - independent of external services/websites","title":"Javascript STL/OBJ 3D files Viewer"}]}